{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bfea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.optim import optimizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdf70d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        return torch.sqrt(torch.mean((input - target) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba157b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUD即期買入</th>\n",
       "      <th>AUD即期賣出</th>\n",
       "      <th>AUD現鈔買入</th>\n",
       "      <th>AUD現鈔賣出</th>\n",
       "      <th>CAD即期買入</th>\n",
       "      <th>CAD即期賣出</th>\n",
       "      <th>CAD現鈔買入</th>\n",
       "      <th>CAD現鈔賣出</th>\n",
       "      <th>EUR即期買入</th>\n",
       "      <th>EUR即期賣出</th>\n",
       "      <th>...</th>\n",
       "      <th>JPY現鈔買入</th>\n",
       "      <th>JPY現鈔賣出</th>\n",
       "      <th>KRW即期買入</th>\n",
       "      <th>KRW即期賣出</th>\n",
       "      <th>KRW現鈔買入</th>\n",
       "      <th>KRW現鈔賣出</th>\n",
       "      <th>USD即期買入</th>\n",
       "      <th>USD即期賣出</th>\n",
       "      <th>USD現鈔買入</th>\n",
       "      <th>USD現鈔賣出</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>23.95</td>\n",
       "      <td>24.15</td>\n",
       "      <td>23.69</td>\n",
       "      <td>24.43</td>\n",
       "      <td>27.41</td>\n",
       "      <td>27.61</td>\n",
       "      <td>27.10</td>\n",
       "      <td>27.90</td>\n",
       "      <td>38.56</td>\n",
       "      <td>38.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03037</td>\n",
       "      <td>0.03508</td>\n",
       "      <td>31.870</td>\n",
       "      <td>31.970</td>\n",
       "      <td>31.570</td>\n",
       "      <td>32.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>24.00</td>\n",
       "      <td>24.20</td>\n",
       "      <td>23.74</td>\n",
       "      <td>24.49</td>\n",
       "      <td>27.52</td>\n",
       "      <td>27.72</td>\n",
       "      <td>27.21</td>\n",
       "      <td>28.01</td>\n",
       "      <td>38.62</td>\n",
       "      <td>39.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.2810</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03022</td>\n",
       "      <td>0.03491</td>\n",
       "      <td>31.930</td>\n",
       "      <td>32.030</td>\n",
       "      <td>31.630</td>\n",
       "      <td>32.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>24.05</td>\n",
       "      <td>24.25</td>\n",
       "      <td>23.79</td>\n",
       "      <td>24.54</td>\n",
       "      <td>27.51</td>\n",
       "      <td>27.71</td>\n",
       "      <td>27.20</td>\n",
       "      <td>28.00</td>\n",
       "      <td>38.73</td>\n",
       "      <td>39.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.2808</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03026</td>\n",
       "      <td>0.03495</td>\n",
       "      <td>32.070</td>\n",
       "      <td>32.170</td>\n",
       "      <td>31.770</td>\n",
       "      <td>32.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3406</th>\n",
       "      <td>23.97</td>\n",
       "      <td>24.17</td>\n",
       "      <td>23.71</td>\n",
       "      <td>24.46</td>\n",
       "      <td>27.32</td>\n",
       "      <td>27.52</td>\n",
       "      <td>27.01</td>\n",
       "      <td>27.80</td>\n",
       "      <td>38.64</td>\n",
       "      <td>39.04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03049</td>\n",
       "      <td>0.03522</td>\n",
       "      <td>32.085</td>\n",
       "      <td>32.185</td>\n",
       "      <td>31.785</td>\n",
       "      <td>32.327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>23.87</td>\n",
       "      <td>24.07</td>\n",
       "      <td>23.61</td>\n",
       "      <td>24.35</td>\n",
       "      <td>27.48</td>\n",
       "      <td>27.68</td>\n",
       "      <td>27.17</td>\n",
       "      <td>27.97</td>\n",
       "      <td>38.61</td>\n",
       "      <td>39.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>0.2807</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03043</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>32.070</td>\n",
       "      <td>32.170</td>\n",
       "      <td>31.770</td>\n",
       "      <td>32.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.00</td>\n",
       "      <td>21.23</td>\n",
       "      <td>20.73</td>\n",
       "      <td>21.51</td>\n",
       "      <td>23.44</td>\n",
       "      <td>23.66</td>\n",
       "      <td>23.05</td>\n",
       "      <td>23.96</td>\n",
       "      <td>34.26</td>\n",
       "      <td>34.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02416</td>\n",
       "      <td>0.02806</td>\n",
       "      <td>31.325</td>\n",
       "      <td>31.425</td>\n",
       "      <td>30.975</td>\n",
       "      <td>31.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.00</td>\n",
       "      <td>21.23</td>\n",
       "      <td>20.73</td>\n",
       "      <td>21.51</td>\n",
       "      <td>23.42</td>\n",
       "      <td>23.64</td>\n",
       "      <td>23.03</td>\n",
       "      <td>23.94</td>\n",
       "      <td>34.18</td>\n",
       "      <td>34.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02411</td>\n",
       "      <td>0.02801</td>\n",
       "      <td>31.370</td>\n",
       "      <td>31.470</td>\n",
       "      <td>31.020</td>\n",
       "      <td>31.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.15</td>\n",
       "      <td>21.38</td>\n",
       "      <td>20.88</td>\n",
       "      <td>21.66</td>\n",
       "      <td>23.44</td>\n",
       "      <td>23.66</td>\n",
       "      <td>23.05</td>\n",
       "      <td>23.96</td>\n",
       "      <td>34.27</td>\n",
       "      <td>34.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2858</td>\n",
       "      <td>0.2986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02428</td>\n",
       "      <td>0.02818</td>\n",
       "      <td>31.300</td>\n",
       "      <td>31.400</td>\n",
       "      <td>30.950</td>\n",
       "      <td>31.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.19</td>\n",
       "      <td>21.42</td>\n",
       "      <td>20.92</td>\n",
       "      <td>21.70</td>\n",
       "      <td>23.56</td>\n",
       "      <td>23.78</td>\n",
       "      <td>23.17</td>\n",
       "      <td>24.08</td>\n",
       "      <td>34.33</td>\n",
       "      <td>34.73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02430</td>\n",
       "      <td>0.02820</td>\n",
       "      <td>31.220</td>\n",
       "      <td>31.320</td>\n",
       "      <td>30.870</td>\n",
       "      <td>31.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.23</td>\n",
       "      <td>21.46</td>\n",
       "      <td>20.96</td>\n",
       "      <td>21.74</td>\n",
       "      <td>23.56</td>\n",
       "      <td>23.78</td>\n",
       "      <td>23.17</td>\n",
       "      <td>24.08</td>\n",
       "      <td>34.32</td>\n",
       "      <td>34.72</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02440</td>\n",
       "      <td>0.02830</td>\n",
       "      <td>31.195</td>\n",
       "      <td>31.295</td>\n",
       "      <td>30.845</td>\n",
       "      <td>31.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3410 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUD即期買入  AUD即期賣出  AUD現鈔買入  AUD現鈔賣出  CAD即期買入  CAD即期賣出  CAD現鈔買入  CAD現鈔賣出  \\\n",
       "3409    23.95    24.15    23.69    24.43    27.41    27.61    27.10    27.90   \n",
       "3408    24.00    24.20    23.74    24.49    27.52    27.72    27.21    28.01   \n",
       "3407    24.05    24.25    23.79    24.54    27.51    27.71    27.20    28.00   \n",
       "3406    23.97    24.17    23.71    24.46    27.32    27.52    27.01    27.80   \n",
       "3405    23.87    24.07    23.61    24.35    27.48    27.68    27.17    27.97   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "4       21.00    21.23    20.73    21.51    23.44    23.66    23.05    23.96   \n",
       "3       21.00    21.23    20.73    21.51    23.42    23.64    23.03    23.94   \n",
       "2       21.15    21.38    20.88    21.66    23.44    23.66    23.05    23.96   \n",
       "1       21.19    21.42    20.92    21.70    23.56    23.78    23.17    24.08   \n",
       "0       21.23    21.46    20.96    21.74    23.56    23.78    23.17    24.08   \n",
       "\n",
       "      EUR即期買入  EUR即期賣出  ...  JPY現鈔買入  JPY現鈔賣出  KRW即期買入  KRW即期賣出  KRW現鈔買入  \\\n",
       "3409    38.56    38.96  ...   0.2706   0.2811        0        0  0.03037   \n",
       "3408    38.62    39.02  ...   0.2705   0.2810        0        0  0.03022   \n",
       "3407    38.73    39.13  ...   0.2703   0.2808        0        0  0.03026   \n",
       "3406    38.64    39.04  ...   0.2702   0.2807        0        0  0.03049   \n",
       "3405    38.61    39.01  ...   0.2702   0.2807        0        0  0.03043   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "4       34.26    34.66  ...   0.2860   0.2988        0        0  0.02416   \n",
       "3       34.18    34.58  ...   0.2872   0.3000        0        0  0.02411   \n",
       "2       34.27    34.67  ...   0.2858   0.2986        0        0  0.02428   \n",
       "1       34.33    34.73  ...   0.2844   0.2972        0        0  0.02430   \n",
       "0       34.32    34.72  ...   0.2828   0.2956        0        0  0.02440   \n",
       "\n",
       "      KRW現鈔賣出  USD即期買入  USD即期賣出  USD現鈔買入  USD現鈔賣出  \n",
       "3409  0.03508   31.870   31.970   31.570   32.112  \n",
       "3408  0.03491   31.930   32.030   31.630   32.172  \n",
       "3407  0.03495   32.070   32.170   31.770   32.312  \n",
       "3406  0.03522   32.085   32.185   31.785   32.327  \n",
       "3405  0.03515   32.070   32.170   31.770   32.312  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "4     0.02806   31.325   31.425   30.975   31.645  \n",
       "3     0.02801   31.370   31.470   31.020   31.690  \n",
       "2     0.02818   31.300   31.400   30.950   31.620  \n",
       "1     0.02820   31.220   31.320   30.870   31.540  \n",
       "0     0.02830   31.195   31.295   30.845   31.515  \n",
       "\n",
       "[3410 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(folder_path):\n",
    "  load_df = pd.DataFrame()\n",
    "  # 遍歷文件夾中的所有文件\n",
    "  name_list=[]\n",
    "  for filename in os.listdir(folder_path):\n",
    "      if filename.endswith(\".csv\"):\n",
    "          file_path = os.path.join(folder_path, filename)\n",
    "          df = pd.read_csv(file_path)\n",
    "          load_df = pd.concat([load_df, df[\"現鈔買入\"], df[\"現鈔賣出\"], df[\"即期買入\"], df[\"即期賣出\"]], axis=1)\n",
    "          filename = filename.replace(\".csv\", \"\")\n",
    "          name_list.extend([f\"{filename}現鈔買入\", f\"{filename}現鈔賣出\", f\"{filename}即期買入\", f\"{filename}即期賣出\"])\n",
    "  load_df.columns = name_list\n",
    "\n",
    "  # 反向排序\n",
    "  load_df = load_df.iloc[::-1]\n",
    "\n",
    "  # 排序column\n",
    "  load_df = load_df.reindex(sorted(load_df.columns), axis=1)\n",
    "\n",
    "  # 處理空值\n",
    "  load_df.replace(\"-\", 0, inplace=True)\n",
    "\n",
    "  return load_df\n",
    "\n",
    "train_df = load_data(\"./train\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a45621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定輸入資料的天數範圍\n",
    "input_date_data_size = 4\n",
    "#要到第幾項\n",
    "power=6\n",
    "# 設定 seed\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f66a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.to_numpy()\n",
    "train_size, feature_size = train.shape\n",
    "# 以一段時間的資料當作輸入，故資料數量要扣掉輸入天數範圍\n",
    "train_size = train_size - input_date_data_size\n",
    "\n",
    "train_x = np.empty([train_size, feature_size * input_date_data_size*power], dtype = float)#乘power讓資料集擴展到次方項\n",
    "train_y = np.empty([train_size, feature_size], dtype = float)\n",
    "\n",
    "for idx in range(train_size):\n",
    "    temp_data = np.array([])\n",
    "    for count in range(input_date_data_size):\n",
    "        temp_data = np.hstack([temp_data, train[idx + count]])#把前幾天的資料合併\n",
    "        for nth_term in range(2,power+1):\n",
    "            temp_data = np.hstack([temp_data, train[idx + count]**nth_term])#把前幾天的資料合併\n",
    "    train_x[idx, :] = temp_data\n",
    "    train_y[idx, :] = train[idx + input_date_data_size]#應該要預測到的實際第幾天資料\n",
    "\n",
    "    # y值只留下現鈔買入\n",
    "filtered_columns = [train_df.columns.get_loc(col) for col in train_df.columns if '現鈔買入' in col]\n",
    "train_y = train_y[:, filtered_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f88646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "mean_x = np.mean(train_x, axis = 0)\n",
    "std_x = np.std(train_x, axis = 0)\n",
    "for i in range(len(train_x)):\n",
    "    for j in range(len(train_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            train_x[i][j] = (train_x[i][j] - mean_x[j]) / std_x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c00866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.2\n",
    "\n",
    "# 計算驗證集的大小\n",
    "val_size = int(train_size * split_ratio)\n",
    "\n",
    "# 隨機生成索引以選擇要包含在驗證集中的樣本\n",
    "indices = np.random.permutation(train_size)\n",
    "\n",
    "# 使用索引切分數據\n",
    "val_indices = indices[:val_size]\n",
    "train_indices = indices[val_size:]\n",
    "\n",
    "# 創建驗證集\n",
    "val_x = train_x[val_indices]\n",
    "val_y = train_y[val_indices]\n",
    "# 創建訓練集\n",
    "train_x = train_x[train_indices]\n",
    "train_y = train_y[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43970b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#轉為pytorch張量，才可以餵進pytorch中\n",
    "train_x = torch.from_numpy(train_x.astype(np.float32))\n",
    "train_y = torch.from_numpy(train_y.astype(np.float32))\n",
    "val_x = torch.from_numpy(val_x.astype(np.float32))\n",
    "val_y = torch.from_numpy(val_y.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2541db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(feature_size * input_date_data_size*power, 8)\n",
    "\n",
    "best_validation_loss = float('inf')\n",
    "\n",
    "learning_rates =0.01\n",
    "criterion =RMSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rates)\n",
    "patience = 10 \n",
    "counter = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d23adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, train_loss =  28.0058, val_loss =  28.0248\n",
      "epoch: 20, train_loss =  27.9596, val_loss =  27.9778\n",
      "epoch: 30, train_loss =  27.9211, val_loss =  27.9388\n",
      "epoch: 40, train_loss =  27.8887, val_loss =  27.9059\n",
      "epoch: 50, train_loss =  27.8608, val_loss =  27.8776\n",
      "epoch: 60, train_loss =  27.8364, val_loss =  27.8530\n",
      "epoch: 70, train_loss =  27.8146, val_loss =  27.8312\n",
      "epoch: 80, train_loss =  27.7948, val_loss =  27.8115\n",
      "epoch: 90, train_loss =  27.7766, val_loss =  27.7935\n",
      "epoch: 100, train_loss =  27.7595, val_loss =  27.7768\n",
      "epoch: 110, train_loss =  27.7434, val_loss =  27.7611\n",
      "epoch: 120, train_loss =  27.7279, val_loss =  27.7462\n",
      "epoch: 130, train_loss =  27.7130, val_loss =  27.7318\n",
      "epoch: 140, train_loss =  27.6985, val_loss =  27.7180\n",
      "epoch: 150, train_loss =  27.6844, val_loss =  27.7045\n",
      "epoch: 160, train_loss =  27.6705, val_loss =  27.6913\n",
      "epoch: 170, train_loss =  27.6568, val_loss =  27.6783\n",
      "epoch: 180, train_loss =  27.6433, val_loss =  27.6656\n",
      "epoch: 190, train_loss =  27.6299, val_loss =  27.6529\n",
      "epoch: 200, train_loss =  27.6166, val_loss =  27.6404\n",
      "epoch: 210, train_loss =  27.6034, val_loss =  27.6279\n",
      "epoch: 220, train_loss =  27.5902, val_loss =  27.6156\n",
      "epoch: 230, train_loss =  27.5772, val_loss =  27.6032\n",
      "epoch: 240, train_loss =  27.5641, val_loss =  27.5910\n",
      "epoch: 250, train_loss =  27.5511, val_loss =  27.5787\n",
      "epoch: 260, train_loss =  27.5382, val_loss =  27.5665\n",
      "epoch: 270, train_loss =  27.5253, val_loss =  27.5543\n",
      "epoch: 280, train_loss =  27.5124, val_loss =  27.5421\n",
      "epoch: 290, train_loss =  27.4995, val_loss =  27.5299\n",
      "epoch: 300, train_loss =  27.4867, val_loss =  27.5178\n",
      "epoch: 310, train_loss =  27.4738, val_loss =  27.5056\n",
      "epoch: 320, train_loss =  27.4610, val_loss =  27.4934\n",
      "epoch: 330, train_loss =  27.4482, val_loss =  27.4813\n",
      "epoch: 340, train_loss =  27.4355, val_loss =  27.4691\n",
      "epoch: 350, train_loss =  27.4227, val_loss =  27.4569\n",
      "epoch: 360, train_loss =  27.4100, val_loss =  27.4448\n",
      "epoch: 370, train_loss =  27.3972, val_loss =  27.4326\n",
      "epoch: 380, train_loss =  27.3845, val_loss =  27.4204\n",
      "epoch: 390, train_loss =  27.3718, val_loss =  27.4082\n",
      "epoch: 400, train_loss =  27.3591, val_loss =  27.3961\n",
      "epoch: 410, train_loss =  27.3464, val_loss =  27.3839\n",
      "epoch: 420, train_loss =  27.3337, val_loss =  27.3717\n",
      "epoch: 430, train_loss =  27.3210, val_loss =  27.3595\n",
      "epoch: 440, train_loss =  27.3083, val_loss =  27.3472\n",
      "epoch: 450, train_loss =  27.2956, val_loss =  27.3350\n",
      "epoch: 460, train_loss =  27.2830, val_loss =  27.3228\n",
      "epoch: 470, train_loss =  27.2703, val_loss =  27.3106\n",
      "epoch: 480, train_loss =  27.2577, val_loss =  27.2984\n",
      "epoch: 490, train_loss =  27.2450, val_loss =  27.2861\n",
      "epoch: 500, train_loss =  27.2324, val_loss =  27.2739\n",
      "epoch: 510, train_loss =  27.2197, val_loss =  27.2616\n",
      "epoch: 520, train_loss =  27.2071, val_loss =  27.2494\n",
      "epoch: 530, train_loss =  27.1945, val_loss =  27.2371\n",
      "epoch: 540, train_loss =  27.1818, val_loss =  27.2248\n",
      "epoch: 550, train_loss =  27.1692, val_loss =  27.2126\n",
      "epoch: 560, train_loss =  27.1566, val_loss =  27.2003\n",
      "epoch: 570, train_loss =  27.1440, val_loss =  27.1880\n",
      "epoch: 580, train_loss =  27.1314, val_loss =  27.1757\n",
      "epoch: 590, train_loss =  27.1188, val_loss =  27.1635\n",
      "epoch: 600, train_loss =  27.1062, val_loss =  27.1512\n",
      "epoch: 610, train_loss =  27.0936, val_loss =  27.1389\n",
      "epoch: 620, train_loss =  27.0810, val_loss =  27.1266\n",
      "epoch: 630, train_loss =  27.0684, val_loss =  27.1143\n",
      "epoch: 640, train_loss =  27.0558, val_loss =  27.1020\n",
      "epoch: 650, train_loss =  27.0432, val_loss =  27.0896\n",
      "epoch: 660, train_loss =  27.0306, val_loss =  27.0773\n",
      "epoch: 670, train_loss =  27.0180, val_loss =  27.0650\n",
      "epoch: 680, train_loss =  27.0054, val_loss =  27.0527\n",
      "epoch: 690, train_loss =  26.9928, val_loss =  27.0404\n",
      "epoch: 700, train_loss =  26.9802, val_loss =  27.0280\n",
      "epoch: 710, train_loss =  26.9677, val_loss =  27.0157\n",
      "epoch: 720, train_loss =  26.9551, val_loss =  27.0034\n",
      "epoch: 730, train_loss =  26.9425, val_loss =  26.9910\n",
      "epoch: 740, train_loss =  26.9299, val_loss =  26.9787\n",
      "epoch: 750, train_loss =  26.9174, val_loss =  26.9663\n",
      "epoch: 760, train_loss =  26.9048, val_loss =  26.9540\n",
      "epoch: 770, train_loss =  26.8922, val_loss =  26.9416\n",
      "epoch: 780, train_loss =  26.8797, val_loss =  26.9293\n",
      "epoch: 790, train_loss =  26.8671, val_loss =  26.9169\n",
      "epoch: 800, train_loss =  26.8545, val_loss =  26.9045\n",
      "epoch: 810, train_loss =  26.8420, val_loss =  26.8922\n",
      "epoch: 820, train_loss =  26.8294, val_loss =  26.8798\n",
      "epoch: 830, train_loss =  26.8168, val_loss =  26.8675\n",
      "epoch: 840, train_loss =  26.8043, val_loss =  26.8551\n",
      "epoch: 850, train_loss =  26.7917, val_loss =  26.8427\n",
      "epoch: 860, train_loss =  26.7792, val_loss =  26.8303\n",
      "epoch: 870, train_loss =  26.7666, val_loss =  26.8180\n",
      "epoch: 880, train_loss =  26.7541, val_loss =  26.8056\n",
      "epoch: 890, train_loss =  26.7415, val_loss =  26.7932\n",
      "epoch: 900, train_loss =  26.7289, val_loss =  26.7808\n",
      "epoch: 910, train_loss =  26.7164, val_loss =  26.7684\n",
      "epoch: 920, train_loss =  26.7038, val_loss =  26.7561\n",
      "epoch: 930, train_loss =  26.6913, val_loss =  26.7437\n",
      "epoch: 940, train_loss =  26.6787, val_loss =  26.7313\n",
      "epoch: 950, train_loss =  26.6662, val_loss =  26.7189\n",
      "epoch: 960, train_loss =  26.6536, val_loss =  26.7065\n",
      "epoch: 970, train_loss =  26.6411, val_loss =  26.6941\n",
      "epoch: 980, train_loss =  26.6286, val_loss =  26.6817\n",
      "epoch: 990, train_loss =  26.6160, val_loss =  26.6693\n",
      "epoch: 1000, train_loss =  26.6035, val_loss =  26.6569\n",
      "epoch: 1010, train_loss =  26.5909, val_loss =  26.6445\n",
      "epoch: 1020, train_loss =  26.5784, val_loss =  26.6321\n",
      "epoch: 1030, train_loss =  26.5658, val_loss =  26.6197\n",
      "epoch: 1040, train_loss =  26.5533, val_loss =  26.6073\n",
      "epoch: 1050, train_loss =  26.5408, val_loss =  26.5949\n",
      "epoch: 1060, train_loss =  26.5282, val_loss =  26.5825\n",
      "epoch: 1070, train_loss =  26.5157, val_loss =  26.5701\n",
      "epoch: 1080, train_loss =  26.5031, val_loss =  26.5576\n",
      "epoch: 1090, train_loss =  26.4906, val_loss =  26.5452\n",
      "epoch: 1100, train_loss =  26.4781, val_loss =  26.5328\n",
      "epoch: 1110, train_loss =  26.4655, val_loss =  26.5204\n",
      "epoch: 1120, train_loss =  26.4530, val_loss =  26.5080\n",
      "epoch: 1130, train_loss =  26.4405, val_loss =  26.4956\n",
      "epoch: 1140, train_loss =  26.4279, val_loss =  26.4832\n",
      "epoch: 1150, train_loss =  26.4154, val_loss =  26.4707\n",
      "epoch: 1160, train_loss =  26.4029, val_loss =  26.4583\n",
      "epoch: 1170, train_loss =  26.3903, val_loss =  26.4459\n",
      "epoch: 1180, train_loss =  26.3778, val_loss =  26.4335\n",
      "epoch: 1190, train_loss =  26.3653, val_loss =  26.4210\n",
      "epoch: 1200, train_loss =  26.3527, val_loss =  26.4086\n",
      "epoch: 1210, train_loss =  26.3402, val_loss =  26.3962\n",
      "epoch: 1220, train_loss =  26.3277, val_loss =  26.3838\n",
      "epoch: 1230, train_loss =  26.3152, val_loss =  26.3713\n",
      "epoch: 1240, train_loss =  26.3026, val_loss =  26.3589\n",
      "epoch: 1250, train_loss =  26.2901, val_loss =  26.3465\n",
      "epoch: 1260, train_loss =  26.2776, val_loss =  26.3340\n",
      "epoch: 1270, train_loss =  26.2650, val_loss =  26.3216\n",
      "epoch: 1280, train_loss =  26.2525, val_loss =  26.3092\n",
      "epoch: 1290, train_loss =  26.2400, val_loss =  26.2967\n",
      "epoch: 1300, train_loss =  26.2275, val_loss =  26.2843\n",
      "epoch: 1310, train_loss =  26.2149, val_loss =  26.2719\n",
      "epoch: 1320, train_loss =  26.2024, val_loss =  26.2594\n",
      "epoch: 1330, train_loss =  26.1899, val_loss =  26.2470\n",
      "epoch: 1340, train_loss =  26.1774, val_loss =  26.2346\n",
      "epoch: 1350, train_loss =  26.1648, val_loss =  26.2221\n",
      "epoch: 1360, train_loss =  26.1523, val_loss =  26.2097\n",
      "epoch: 1370, train_loss =  26.1398, val_loss =  26.1972\n",
      "epoch: 1380, train_loss =  26.1273, val_loss =  26.1848\n",
      "epoch: 1390, train_loss =  26.1147, val_loss =  26.1724\n",
      "epoch: 1400, train_loss =  26.1022, val_loss =  26.1599\n",
      "epoch: 1410, train_loss =  26.0897, val_loss =  26.1475\n",
      "epoch: 1420, train_loss =  26.0772, val_loss =  26.1350\n",
      "epoch: 1430, train_loss =  26.0647, val_loss =  26.1226\n",
      "epoch: 1440, train_loss =  26.0521, val_loss =  26.1101\n",
      "epoch: 1450, train_loss =  26.0396, val_loss =  26.0977\n",
      "epoch: 1460, train_loss =  26.0271, val_loss =  26.0852\n",
      "epoch: 1470, train_loss =  26.0146, val_loss =  26.0728\n",
      "epoch: 1480, train_loss =  26.0021, val_loss =  26.0603\n",
      "epoch: 1490, train_loss =  25.9895, val_loss =  26.0479\n",
      "epoch: 1500, train_loss =  25.9770, val_loss =  26.0354\n",
      "epoch: 1510, train_loss =  25.9645, val_loss =  26.0230\n",
      "epoch: 1520, train_loss =  25.9520, val_loss =  26.0105\n",
      "epoch: 1530, train_loss =  25.9395, val_loss =  25.9981\n",
      "epoch: 1540, train_loss =  25.9269, val_loss =  25.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1550, train_loss =  25.9144, val_loss =  25.9732\n",
      "epoch: 1560, train_loss =  25.9019, val_loss =  25.9607\n",
      "epoch: 1570, train_loss =  25.8894, val_loss =  25.9483\n",
      "epoch: 1580, train_loss =  25.8769, val_loss =  25.9358\n",
      "epoch: 1590, train_loss =  25.8644, val_loss =  25.9234\n",
      "epoch: 1600, train_loss =  25.8518, val_loss =  25.9109\n",
      "epoch: 1610, train_loss =  25.8393, val_loss =  25.8984\n",
      "epoch: 1620, train_loss =  25.8268, val_loss =  25.8860\n",
      "epoch: 1630, train_loss =  25.8143, val_loss =  25.8735\n",
      "epoch: 1640, train_loss =  25.8018, val_loss =  25.8611\n",
      "epoch: 1650, train_loss =  25.7893, val_loss =  25.8486\n",
      "epoch: 1660, train_loss =  25.7767, val_loss =  25.8361\n",
      "epoch: 1670, train_loss =  25.7642, val_loss =  25.8237\n",
      "epoch: 1680, train_loss =  25.7517, val_loss =  25.8112\n",
      "epoch: 1690, train_loss =  25.7392, val_loss =  25.7988\n",
      "epoch: 1700, train_loss =  25.7267, val_loss =  25.7863\n",
      "epoch: 1710, train_loss =  25.7142, val_loss =  25.7738\n",
      "epoch: 1720, train_loss =  25.7017, val_loss =  25.7614\n",
      "epoch: 1730, train_loss =  25.6891, val_loss =  25.7489\n",
      "epoch: 1740, train_loss =  25.6766, val_loss =  25.7364\n",
      "epoch: 1750, train_loss =  25.6641, val_loss =  25.7240\n",
      "epoch: 1760, train_loss =  25.6516, val_loss =  25.7115\n",
      "epoch: 1770, train_loss =  25.6391, val_loss =  25.6991\n",
      "epoch: 1780, train_loss =  25.6266, val_loss =  25.6866\n",
      "epoch: 1790, train_loss =  25.6141, val_loss =  25.6741\n",
      "epoch: 1800, train_loss =  25.6015, val_loss =  25.6617\n",
      "epoch: 1810, train_loss =  25.5890, val_loss =  25.6492\n",
      "epoch: 1820, train_loss =  25.5765, val_loss =  25.6367\n",
      "epoch: 1830, train_loss =  25.5640, val_loss =  25.6242\n",
      "epoch: 1840, train_loss =  25.5515, val_loss =  25.6118\n",
      "epoch: 1850, train_loss =  25.5390, val_loss =  25.5993\n",
      "epoch: 1860, train_loss =  25.5265, val_loss =  25.5868\n",
      "epoch: 1870, train_loss =  25.5140, val_loss =  25.5744\n",
      "epoch: 1880, train_loss =  25.5014, val_loss =  25.5619\n",
      "epoch: 1890, train_loss =  25.4889, val_loss =  25.5494\n",
      "epoch: 1900, train_loss =  25.4764, val_loss =  25.5370\n",
      "epoch: 1910, train_loss =  25.4639, val_loss =  25.5245\n",
      "epoch: 1920, train_loss =  25.4514, val_loss =  25.5120\n",
      "epoch: 1930, train_loss =  25.4389, val_loss =  25.4995\n",
      "epoch: 1940, train_loss =  25.4264, val_loss =  25.4871\n",
      "epoch: 1950, train_loss =  25.4139, val_loss =  25.4746\n",
      "epoch: 1960, train_loss =  25.4013, val_loss =  25.4621\n",
      "epoch: 1970, train_loss =  25.3888, val_loss =  25.4496\n",
      "epoch: 1980, train_loss =  25.3763, val_loss =  25.4372\n",
      "epoch: 1990, train_loss =  25.3638, val_loss =  25.4247\n",
      "epoch: 2000, train_loss =  25.3513, val_loss =  25.4122\n",
      "epoch: 2010, train_loss =  25.3388, val_loss =  25.3997\n",
      "epoch: 2020, train_loss =  25.3263, val_loss =  25.3873\n",
      "epoch: 2030, train_loss =  25.3138, val_loss =  25.3748\n",
      "epoch: 2040, train_loss =  25.3013, val_loss =  25.3623\n",
      "epoch: 2050, train_loss =  25.2887, val_loss =  25.3498\n",
      "epoch: 2060, train_loss =  25.2762, val_loss =  25.3373\n",
      "epoch: 2070, train_loss =  25.2637, val_loss =  25.3249\n",
      "epoch: 2080, train_loss =  25.2512, val_loss =  25.3124\n",
      "epoch: 2090, train_loss =  25.2387, val_loss =  25.2999\n",
      "epoch: 2100, train_loss =  25.2262, val_loss =  25.2874\n",
      "epoch: 2110, train_loss =  25.2137, val_loss =  25.2750\n",
      "epoch: 2120, train_loss =  25.2012, val_loss =  25.2625\n",
      "epoch: 2130, train_loss =  25.1887, val_loss =  25.2500\n",
      "epoch: 2140, train_loss =  25.1762, val_loss =  25.2375\n",
      "epoch: 2150, train_loss =  25.1636, val_loss =  25.2250\n",
      "epoch: 2160, train_loss =  25.1511, val_loss =  25.2125\n",
      "epoch: 2170, train_loss =  25.1386, val_loss =  25.2001\n",
      "epoch: 2180, train_loss =  25.1261, val_loss =  25.1876\n",
      "epoch: 2190, train_loss =  25.1136, val_loss =  25.1751\n",
      "epoch: 2200, train_loss =  25.1011, val_loss =  25.1626\n",
      "epoch: 2210, train_loss =  25.0886, val_loss =  25.1501\n",
      "epoch: 2220, train_loss =  25.0761, val_loss =  25.1377\n",
      "epoch: 2230, train_loss =  25.0636, val_loss =  25.1252\n",
      "epoch: 2240, train_loss =  25.0511, val_loss =  25.1127\n",
      "epoch: 2250, train_loss =  25.0386, val_loss =  25.1002\n",
      "epoch: 2260, train_loss =  25.0261, val_loss =  25.0877\n",
      "epoch: 2270, train_loss =  25.0135, val_loss =  25.0752\n",
      "epoch: 2280, train_loss =  25.0010, val_loss =  25.0628\n",
      "epoch: 2290, train_loss =  24.9885, val_loss =  25.0503\n",
      "epoch: 2300, train_loss =  24.9760, val_loss =  25.0378\n",
      "epoch: 2310, train_loss =  24.9635, val_loss =  25.0253\n",
      "epoch: 2320, train_loss =  24.9510, val_loss =  25.0128\n",
      "epoch: 2330, train_loss =  24.9385, val_loss =  25.0003\n",
      "epoch: 2340, train_loss =  24.9260, val_loss =  24.9878\n",
      "epoch: 2350, train_loss =  24.9135, val_loss =  24.9754\n",
      "epoch: 2360, train_loss =  24.9010, val_loss =  24.9629\n",
      "epoch: 2370, train_loss =  24.8885, val_loss =  24.9504\n",
      "epoch: 2380, train_loss =  24.8760, val_loss =  24.9379\n",
      "epoch: 2390, train_loss =  24.8635, val_loss =  24.9254\n",
      "epoch: 2400, train_loss =  24.8509, val_loss =  24.9129\n",
      "epoch: 2410, train_loss =  24.8384, val_loss =  24.9004\n",
      "epoch: 2420, train_loss =  24.8259, val_loss =  24.8879\n",
      "epoch: 2430, train_loss =  24.8134, val_loss =  24.8755\n",
      "epoch: 2440, train_loss =  24.8009, val_loss =  24.8630\n",
      "epoch: 2450, train_loss =  24.7884, val_loss =  24.8505\n",
      "epoch: 2460, train_loss =  24.7759, val_loss =  24.8380\n",
      "epoch: 2470, train_loss =  24.7634, val_loss =  24.8255\n",
      "epoch: 2480, train_loss =  24.7509, val_loss =  24.8130\n",
      "epoch: 2490, train_loss =  24.7384, val_loss =  24.8005\n",
      "epoch: 2500, train_loss =  24.7259, val_loss =  24.7880\n",
      "epoch: 2510, train_loss =  24.7134, val_loss =  24.7755\n",
      "epoch: 2520, train_loss =  24.7009, val_loss =  24.7631\n",
      "epoch: 2530, train_loss =  24.6884, val_loss =  24.7506\n",
      "epoch: 2540, train_loss =  24.6758, val_loss =  24.7381\n",
      "epoch: 2550, train_loss =  24.6633, val_loss =  24.7256\n",
      "epoch: 2560, train_loss =  24.6508, val_loss =  24.7131\n",
      "epoch: 2570, train_loss =  24.6383, val_loss =  24.7006\n",
      "epoch: 2580, train_loss =  24.6258, val_loss =  24.6881\n",
      "epoch: 2590, train_loss =  24.6133, val_loss =  24.6756\n",
      "epoch: 2600, train_loss =  24.6008, val_loss =  24.6631\n",
      "epoch: 2610, train_loss =  24.5883, val_loss =  24.6506\n",
      "epoch: 2620, train_loss =  24.5758, val_loss =  24.6382\n",
      "epoch: 2630, train_loss =  24.5633, val_loss =  24.6257\n",
      "epoch: 2640, train_loss =  24.5508, val_loss =  24.6132\n",
      "epoch: 2650, train_loss =  24.5383, val_loss =  24.6007\n",
      "epoch: 2660, train_loss =  24.5258, val_loss =  24.5882\n",
      "epoch: 2670, train_loss =  24.5133, val_loss =  24.5757\n",
      "epoch: 2680, train_loss =  24.5008, val_loss =  24.5632\n",
      "epoch: 2690, train_loss =  24.4883, val_loss =  24.5507\n",
      "epoch: 2700, train_loss =  24.4758, val_loss =  24.5382\n",
      "epoch: 2710, train_loss =  24.4632, val_loss =  24.5257\n",
      "epoch: 2720, train_loss =  24.4507, val_loss =  24.5132\n",
      "epoch: 2730, train_loss =  24.4382, val_loss =  24.5007\n",
      "epoch: 2740, train_loss =  24.4257, val_loss =  24.4882\n",
      "epoch: 2750, train_loss =  24.4132, val_loss =  24.4757\n",
      "epoch: 2760, train_loss =  24.4007, val_loss =  24.4633\n",
      "epoch: 2770, train_loss =  24.3882, val_loss =  24.4508\n",
      "epoch: 2780, train_loss =  24.3757, val_loss =  24.4383\n",
      "epoch: 2790, train_loss =  24.3632, val_loss =  24.4258\n",
      "epoch: 2800, train_loss =  24.3507, val_loss =  24.4133\n",
      "epoch: 2810, train_loss =  24.3382, val_loss =  24.4008\n",
      "epoch: 2820, train_loss =  24.3257, val_loss =  24.3883\n",
      "epoch: 2830, train_loss =  24.3132, val_loss =  24.3758\n",
      "epoch: 2840, train_loss =  24.3007, val_loss =  24.3633\n",
      "epoch: 2850, train_loss =  24.2882, val_loss =  24.3508\n",
      "epoch: 2860, train_loss =  24.2757, val_loss =  24.3383\n",
      "epoch: 2870, train_loss =  24.2632, val_loss =  24.3258\n",
      "epoch: 2880, train_loss =  24.2507, val_loss =  24.3133\n",
      "epoch: 2890, train_loss =  24.2382, val_loss =  24.3008\n",
      "epoch: 2900, train_loss =  24.2257, val_loss =  24.2883\n",
      "epoch: 2910, train_loss =  24.2132, val_loss =  24.2758\n",
      "epoch: 2920, train_loss =  24.2006, val_loss =  24.2633\n",
      "epoch: 2930, train_loss =  24.1881, val_loss =  24.2508\n",
      "epoch: 2940, train_loss =  24.1756, val_loss =  24.2383\n",
      "epoch: 2950, train_loss =  24.1631, val_loss =  24.2258\n",
      "epoch: 2960, train_loss =  24.1506, val_loss =  24.2133\n",
      "epoch: 2970, train_loss =  24.1381, val_loss =  24.2008\n",
      "epoch: 2980, train_loss =  24.1256, val_loss =  24.1884\n",
      "epoch: 2990, train_loss =  24.1131, val_loss =  24.1759\n",
      "epoch: 3000, train_loss =  24.1006, val_loss =  24.1634\n",
      "epoch: 3010, train_loss =  24.0881, val_loss =  24.1509\n",
      "epoch: 3020, train_loss =  24.0756, val_loss =  24.1384\n",
      "epoch: 3030, train_loss =  24.0631, val_loss =  24.1259\n",
      "epoch: 3040, train_loss =  24.0506, val_loss =  24.1134\n",
      "epoch: 3050, train_loss =  24.0381, val_loss =  24.1009\n",
      "epoch: 3060, train_loss =  24.0256, val_loss =  24.0884\n",
      "epoch: 3070, train_loss =  24.0131, val_loss =  24.0759\n",
      "epoch: 3080, train_loss =  24.0006, val_loss =  24.0634\n",
      "epoch: 3090, train_loss =  23.9881, val_loss =  24.0509\n",
      "epoch: 3100, train_loss =  23.9756, val_loss =  24.0384\n",
      "epoch: 3110, train_loss =  23.9631, val_loss =  24.0259\n",
      "epoch: 3120, train_loss =  23.9506, val_loss =  24.0134\n",
      "epoch: 3130, train_loss =  23.9381, val_loss =  24.0009\n",
      "epoch: 3140, train_loss =  23.9256, val_loss =  23.9884\n",
      "epoch: 3150, train_loss =  23.9131, val_loss =  23.9759\n",
      "epoch: 3160, train_loss =  23.9006, val_loss =  23.9634\n",
      "epoch: 3170, train_loss =  23.8881, val_loss =  23.9509\n",
      "epoch: 3180, train_loss =  23.8755, val_loss =  23.9384\n",
      "epoch: 3190, train_loss =  23.8630, val_loss =  23.9259\n",
      "epoch: 3200, train_loss =  23.8505, val_loss =  23.9134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3210, train_loss =  23.8380, val_loss =  23.9009\n",
      "epoch: 3220, train_loss =  23.8255, val_loss =  23.8884\n",
      "epoch: 3230, train_loss =  23.8130, val_loss =  23.8759\n",
      "epoch: 3240, train_loss =  23.8005, val_loss =  23.8634\n",
      "epoch: 3250, train_loss =  23.7880, val_loss =  23.8509\n",
      "epoch: 3260, train_loss =  23.7755, val_loss =  23.8384\n",
      "epoch: 3270, train_loss =  23.7630, val_loss =  23.8259\n",
      "epoch: 3280, train_loss =  23.7505, val_loss =  23.8134\n",
      "epoch: 3290, train_loss =  23.7380, val_loss =  23.8009\n",
      "epoch: 3300, train_loss =  23.7255, val_loss =  23.7884\n",
      "epoch: 3310, train_loss =  23.7130, val_loss =  23.7759\n",
      "epoch: 3320, train_loss =  23.7005, val_loss =  23.7634\n",
      "epoch: 3330, train_loss =  23.6880, val_loss =  23.7509\n",
      "epoch: 3340, train_loss =  23.6755, val_loss =  23.7384\n",
      "epoch: 3350, train_loss =  23.6630, val_loss =  23.7259\n",
      "epoch: 3360, train_loss =  23.6505, val_loss =  23.7134\n",
      "epoch: 3370, train_loss =  23.6380, val_loss =  23.7009\n",
      "epoch: 3380, train_loss =  23.6255, val_loss =  23.6884\n",
      "epoch: 3390, train_loss =  23.6130, val_loss =  23.6759\n",
      "epoch: 3400, train_loss =  23.6005, val_loss =  23.6634\n",
      "epoch: 3410, train_loss =  23.5880, val_loss =  23.6509\n",
      "epoch: 3420, train_loss =  23.5755, val_loss =  23.6384\n",
      "epoch: 3430, train_loss =  23.5630, val_loss =  23.6259\n",
      "epoch: 3440, train_loss =  23.5505, val_loss =  23.6134\n",
      "epoch: 3450, train_loss =  23.5380, val_loss =  23.6009\n",
      "epoch: 3460, train_loss =  23.5255, val_loss =  23.5884\n",
      "epoch: 3470, train_loss =  23.5130, val_loss =  23.5759\n",
      "epoch: 3480, train_loss =  23.5005, val_loss =  23.5634\n",
      "epoch: 3490, train_loss =  23.4880, val_loss =  23.5509\n",
      "epoch: 3500, train_loss =  23.4755, val_loss =  23.5384\n",
      "epoch: 3510, train_loss =  23.4630, val_loss =  23.5259\n",
      "epoch: 3520, train_loss =  23.4505, val_loss =  23.5134\n",
      "epoch: 3530, train_loss =  23.4380, val_loss =  23.5009\n",
      "epoch: 3540, train_loss =  23.4255, val_loss =  23.4884\n",
      "epoch: 3550, train_loss =  23.4130, val_loss =  23.4759\n",
      "epoch: 3560, train_loss =  23.4005, val_loss =  23.4634\n",
      "epoch: 3570, train_loss =  23.3880, val_loss =  23.4509\n",
      "epoch: 3580, train_loss =  23.3754, val_loss =  23.4384\n",
      "epoch: 3590, train_loss =  23.3629, val_loss =  23.4259\n",
      "epoch: 3600, train_loss =  23.3504, val_loss =  23.4134\n",
      "epoch: 3610, train_loss =  23.3379, val_loss =  23.4009\n",
      "epoch: 3620, train_loss =  23.3254, val_loss =  23.3884\n",
      "epoch: 3630, train_loss =  23.3129, val_loss =  23.3759\n",
      "epoch: 3640, train_loss =  23.3004, val_loss =  23.3634\n",
      "epoch: 3650, train_loss =  23.2879, val_loss =  23.3509\n",
      "epoch: 3660, train_loss =  23.2754, val_loss =  23.3384\n",
      "epoch: 3670, train_loss =  23.2629, val_loss =  23.3259\n",
      "epoch: 3680, train_loss =  23.2504, val_loss =  23.3134\n",
      "epoch: 3690, train_loss =  23.2379, val_loss =  23.3009\n",
      "epoch: 3700, train_loss =  23.2254, val_loss =  23.2884\n",
      "epoch: 3710, train_loss =  23.2129, val_loss =  23.2759\n",
      "epoch: 3720, train_loss =  23.2004, val_loss =  23.2634\n",
      "epoch: 3730, train_loss =  23.1879, val_loss =  23.2509\n",
      "epoch: 3740, train_loss =  23.1754, val_loss =  23.2384\n",
      "epoch: 3750, train_loss =  23.1629, val_loss =  23.2259\n",
      "epoch: 3760, train_loss =  23.1504, val_loss =  23.2134\n",
      "epoch: 3770, train_loss =  23.1379, val_loss =  23.2009\n",
      "epoch: 3780, train_loss =  23.1254, val_loss =  23.1884\n",
      "epoch: 3790, train_loss =  23.1129, val_loss =  23.1759\n",
      "epoch: 3800, train_loss =  23.1004, val_loss =  23.1634\n",
      "epoch: 3810, train_loss =  23.0879, val_loss =  23.1509\n",
      "epoch: 3820, train_loss =  23.0754, val_loss =  23.1384\n",
      "epoch: 3830, train_loss =  23.0629, val_loss =  23.1259\n",
      "epoch: 3840, train_loss =  23.0504, val_loss =  23.1134\n",
      "epoch: 3850, train_loss =  23.0379, val_loss =  23.1009\n",
      "epoch: 3860, train_loss =  23.0254, val_loss =  23.0884\n",
      "epoch: 3870, train_loss =  23.0129, val_loss =  23.0759\n",
      "epoch: 3880, train_loss =  23.0004, val_loss =  23.0634\n",
      "epoch: 3890, train_loss =  22.9879, val_loss =  23.0509\n",
      "epoch: 3900, train_loss =  22.9754, val_loss =  23.0384\n",
      "epoch: 3910, train_loss =  22.9629, val_loss =  23.0259\n",
      "epoch: 3920, train_loss =  22.9504, val_loss =  23.0134\n",
      "epoch: 3930, train_loss =  22.9379, val_loss =  23.0009\n",
      "epoch: 3940, train_loss =  22.9254, val_loss =  22.9883\n",
      "epoch: 3950, train_loss =  22.9129, val_loss =  22.9758\n",
      "epoch: 3960, train_loss =  22.9004, val_loss =  22.9633\n",
      "epoch: 3970, train_loss =  22.8879, val_loss =  22.9508\n",
      "epoch: 3980, train_loss =  22.8754, val_loss =  22.9383\n",
      "epoch: 3990, train_loss =  22.8629, val_loss =  22.9258\n",
      "epoch: 4000, train_loss =  22.8504, val_loss =  22.9133\n",
      "epoch: 4010, train_loss =  22.8379, val_loss =  22.9008\n",
      "epoch: 4020, train_loss =  22.8254, val_loss =  22.8883\n",
      "epoch: 4030, train_loss =  22.8129, val_loss =  22.8758\n",
      "epoch: 4040, train_loss =  22.8004, val_loss =  22.8633\n",
      "epoch: 4050, train_loss =  22.7879, val_loss =  22.8508\n",
      "epoch: 4060, train_loss =  22.7754, val_loss =  22.8383\n",
      "epoch: 4070, train_loss =  22.7629, val_loss =  22.8258\n",
      "epoch: 4080, train_loss =  22.7504, val_loss =  22.8133\n",
      "epoch: 4090, train_loss =  22.7379, val_loss =  22.8008\n",
      "epoch: 4100, train_loss =  22.7254, val_loss =  22.7883\n",
      "epoch: 4110, train_loss =  22.7129, val_loss =  22.7758\n",
      "epoch: 4120, train_loss =  22.7004, val_loss =  22.7633\n",
      "epoch: 4130, train_loss =  22.6879, val_loss =  22.7508\n",
      "epoch: 4140, train_loss =  22.6754, val_loss =  22.7383\n",
      "epoch: 4150, train_loss =  22.6629, val_loss =  22.7258\n",
      "epoch: 4160, train_loss =  22.6504, val_loss =  22.7133\n",
      "epoch: 4170, train_loss =  22.6379, val_loss =  22.7008\n",
      "epoch: 4180, train_loss =  22.6254, val_loss =  22.6883\n",
      "epoch: 4190, train_loss =  22.6129, val_loss =  22.6758\n",
      "epoch: 4200, train_loss =  22.6004, val_loss =  22.6633\n",
      "epoch: 4210, train_loss =  22.5879, val_loss =  22.6508\n",
      "epoch: 4220, train_loss =  22.5754, val_loss =  22.6383\n",
      "epoch: 4230, train_loss =  22.5629, val_loss =  22.6258\n",
      "epoch: 4240, train_loss =  22.5504, val_loss =  22.6133\n",
      "epoch: 4250, train_loss =  22.5379, val_loss =  22.6008\n",
      "epoch: 4260, train_loss =  22.5254, val_loss =  22.5883\n",
      "epoch: 4270, train_loss =  22.5129, val_loss =  22.5758\n",
      "epoch: 4280, train_loss =  22.5004, val_loss =  22.5633\n",
      "epoch: 4290, train_loss =  22.4879, val_loss =  22.5508\n",
      "epoch: 4300, train_loss =  22.4755, val_loss =  22.5383\n",
      "epoch: 4310, train_loss =  22.4630, val_loss =  22.5258\n",
      "epoch: 4320, train_loss =  22.4505, val_loss =  22.5133\n",
      "epoch: 4330, train_loss =  22.4380, val_loss =  22.5008\n",
      "epoch: 4340, train_loss =  22.4255, val_loss =  22.4883\n",
      "epoch: 4350, train_loss =  22.4130, val_loss =  22.4757\n",
      "epoch: 4360, train_loss =  22.4005, val_loss =  22.4632\n",
      "epoch: 4370, train_loss =  22.3880, val_loss =  22.4507\n",
      "epoch: 4380, train_loss =  22.3755, val_loss =  22.4382\n",
      "epoch: 4390, train_loss =  22.3630, val_loss =  22.4257\n",
      "epoch: 4400, train_loss =  22.3505, val_loss =  22.4132\n",
      "epoch: 4410, train_loss =  22.3380, val_loss =  22.4007\n",
      "epoch: 4420, train_loss =  22.3255, val_loss =  22.3882\n",
      "epoch: 4430, train_loss =  22.3130, val_loss =  22.3757\n",
      "epoch: 4440, train_loss =  22.3005, val_loss =  22.3632\n",
      "epoch: 4450, train_loss =  22.2880, val_loss =  22.3507\n",
      "epoch: 4460, train_loss =  22.2755, val_loss =  22.3382\n",
      "epoch: 4470, train_loss =  22.2630, val_loss =  22.3257\n",
      "epoch: 4480, train_loss =  22.2505, val_loss =  22.3132\n",
      "epoch: 4490, train_loss =  22.2380, val_loss =  22.3007\n",
      "epoch: 4500, train_loss =  22.2255, val_loss =  22.2882\n",
      "epoch: 4510, train_loss =  22.2130, val_loss =  22.2757\n",
      "epoch: 4520, train_loss =  22.2005, val_loss =  22.2632\n",
      "epoch: 4530, train_loss =  22.1880, val_loss =  22.2507\n",
      "epoch: 4540, train_loss =  22.1755, val_loss =  22.2382\n",
      "epoch: 4550, train_loss =  22.1630, val_loss =  22.2257\n",
      "epoch: 4560, train_loss =  22.1505, val_loss =  22.2132\n",
      "epoch: 4570, train_loss =  22.1380, val_loss =  22.2007\n",
      "epoch: 4580, train_loss =  22.1255, val_loss =  22.1882\n",
      "epoch: 4590, train_loss =  22.1130, val_loss =  22.1757\n",
      "epoch: 4600, train_loss =  22.1005, val_loss =  22.1632\n",
      "epoch: 4610, train_loss =  22.0880, val_loss =  22.1507\n",
      "epoch: 4620, train_loss =  22.0755, val_loss =  22.1382\n",
      "epoch: 4630, train_loss =  22.0630, val_loss =  22.1257\n",
      "epoch: 4640, train_loss =  22.0505, val_loss =  22.1132\n",
      "epoch: 4650, train_loss =  22.0380, val_loss =  22.1007\n",
      "epoch: 4660, train_loss =  22.0255, val_loss =  22.0881\n",
      "epoch: 4670, train_loss =  22.0130, val_loss =  22.0756\n",
      "epoch: 4680, train_loss =  22.0005, val_loss =  22.0631\n",
      "epoch: 4690, train_loss =  21.9880, val_loss =  22.0506\n",
      "epoch: 4700, train_loss =  21.9755, val_loss =  22.0381\n",
      "epoch: 4710, train_loss =  21.9630, val_loss =  22.0256\n",
      "epoch: 4720, train_loss =  21.9505, val_loss =  22.0131\n",
      "epoch: 4730, train_loss =  21.9380, val_loss =  22.0006\n",
      "epoch: 4740, train_loss =  21.9255, val_loss =  21.9881\n",
      "epoch: 4750, train_loss =  21.9130, val_loss =  21.9756\n",
      "epoch: 4760, train_loss =  21.9005, val_loss =  21.9631\n",
      "epoch: 4770, train_loss =  21.8880, val_loss =  21.9506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4780, train_loss =  21.8755, val_loss =  21.9381\n",
      "epoch: 4790, train_loss =  21.8630, val_loss =  21.9256\n",
      "epoch: 4800, train_loss =  21.8505, val_loss =  21.9131\n",
      "epoch: 4810, train_loss =  21.8380, val_loss =  21.9006\n",
      "epoch: 4820, train_loss =  21.8255, val_loss =  21.8881\n",
      "epoch: 4830, train_loss =  21.8130, val_loss =  21.8756\n",
      "epoch: 4840, train_loss =  21.8005, val_loss =  21.8631\n",
      "epoch: 4850, train_loss =  21.7881, val_loss =  21.8506\n",
      "epoch: 4860, train_loss =  21.7756, val_loss =  21.8381\n",
      "epoch: 4870, train_loss =  21.7631, val_loss =  21.8256\n",
      "epoch: 4880, train_loss =  21.7506, val_loss =  21.8131\n",
      "epoch: 4890, train_loss =  21.7381, val_loss =  21.8006\n",
      "epoch: 4900, train_loss =  21.7256, val_loss =  21.7881\n",
      "epoch: 4910, train_loss =  21.7131, val_loss =  21.7756\n",
      "epoch: 4920, train_loss =  21.7006, val_loss =  21.7631\n",
      "epoch: 4930, train_loss =  21.6881, val_loss =  21.7505\n",
      "epoch: 4940, train_loss =  21.6756, val_loss =  21.7380\n",
      "epoch: 4950, train_loss =  21.6631, val_loss =  21.7255\n",
      "epoch: 4960, train_loss =  21.6506, val_loss =  21.7130\n",
      "epoch: 4970, train_loss =  21.6381, val_loss =  21.7005\n",
      "epoch: 4980, train_loss =  21.6256, val_loss =  21.6880\n",
      "epoch: 4990, train_loss =  21.6131, val_loss =  21.6755\n",
      "epoch: 5000, train_loss =  21.6006, val_loss =  21.6630\n",
      "epoch: 5010, train_loss =  21.5881, val_loss =  21.6505\n",
      "epoch: 5020, train_loss =  21.5756, val_loss =  21.6380\n",
      "epoch: 5030, train_loss =  21.5631, val_loss =  21.6255\n",
      "epoch: 5040, train_loss =  21.5506, val_loss =  21.6130\n",
      "epoch: 5050, train_loss =  21.5381, val_loss =  21.6005\n",
      "epoch: 5060, train_loss =  21.5256, val_loss =  21.5880\n",
      "epoch: 5070, train_loss =  21.5131, val_loss =  21.5755\n",
      "epoch: 5080, train_loss =  21.5006, val_loss =  21.5630\n",
      "epoch: 5090, train_loss =  21.4881, val_loss =  21.5505\n",
      "epoch: 5100, train_loss =  21.4756, val_loss =  21.5380\n",
      "epoch: 5110, train_loss =  21.4631, val_loss =  21.5255\n",
      "epoch: 5120, train_loss =  21.4506, val_loss =  21.5130\n",
      "epoch: 5130, train_loss =  21.4381, val_loss =  21.5005\n",
      "epoch: 5140, train_loss =  21.4256, val_loss =  21.4880\n",
      "epoch: 5150, train_loss =  21.4131, val_loss =  21.4755\n",
      "epoch: 5160, train_loss =  21.4006, val_loss =  21.4630\n",
      "epoch: 5170, train_loss =  21.3881, val_loss =  21.4504\n",
      "epoch: 5180, train_loss =  21.3756, val_loss =  21.4379\n",
      "epoch: 5190, train_loss =  21.3631, val_loss =  21.4254\n",
      "epoch: 5200, train_loss =  21.3506, val_loss =  21.4129\n",
      "epoch: 5210, train_loss =  21.3382, val_loss =  21.4004\n",
      "epoch: 5220, train_loss =  21.3257, val_loss =  21.3879\n",
      "epoch: 5230, train_loss =  21.3132, val_loss =  21.3754\n",
      "epoch: 5240, train_loss =  21.3007, val_loss =  21.3629\n",
      "epoch: 5250, train_loss =  21.2882, val_loss =  21.3504\n",
      "epoch: 5260, train_loss =  21.2757, val_loss =  21.3379\n",
      "epoch: 5270, train_loss =  21.2632, val_loss =  21.3254\n",
      "epoch: 5280, train_loss =  21.2507, val_loss =  21.3129\n",
      "epoch: 5290, train_loss =  21.2382, val_loss =  21.3004\n",
      "epoch: 5300, train_loss =  21.2257, val_loss =  21.2879\n",
      "epoch: 5310, train_loss =  21.2132, val_loss =  21.2754\n",
      "epoch: 5320, train_loss =  21.2007, val_loss =  21.2629\n",
      "epoch: 5330, train_loss =  21.1882, val_loss =  21.2504\n",
      "epoch: 5340, train_loss =  21.1757, val_loss =  21.2379\n",
      "epoch: 5350, train_loss =  21.1632, val_loss =  21.2254\n",
      "epoch: 5360, train_loss =  21.1507, val_loss =  21.2129\n",
      "epoch: 5370, train_loss =  21.1382, val_loss =  21.2004\n",
      "epoch: 5380, train_loss =  21.1257, val_loss =  21.1879\n",
      "epoch: 5390, train_loss =  21.1132, val_loss =  21.1754\n",
      "epoch: 5400, train_loss =  21.1007, val_loss =  21.1628\n",
      "epoch: 5410, train_loss =  21.0882, val_loss =  21.1503\n",
      "epoch: 5420, train_loss =  21.0757, val_loss =  21.1378\n",
      "epoch: 5430, train_loss =  21.0632, val_loss =  21.1253\n",
      "epoch: 5440, train_loss =  21.0507, val_loss =  21.1128\n",
      "epoch: 5450, train_loss =  21.0382, val_loss =  21.1003\n",
      "epoch: 5460, train_loss =  21.0257, val_loss =  21.0878\n",
      "epoch: 5470, train_loss =  21.0132, val_loss =  21.0753\n",
      "epoch: 5480, train_loss =  21.0007, val_loss =  21.0628\n",
      "epoch: 5490, train_loss =  20.9882, val_loss =  21.0503\n",
      "epoch: 5500, train_loss =  20.9757, val_loss =  21.0378\n",
      "epoch: 5510, train_loss =  20.9633, val_loss =  21.0253\n",
      "epoch: 5520, train_loss =  20.9508, val_loss =  21.0128\n",
      "epoch: 5530, train_loss =  20.9383, val_loss =  21.0003\n",
      "epoch: 5540, train_loss =  20.9258, val_loss =  20.9878\n",
      "epoch: 5550, train_loss =  20.9133, val_loss =  20.9753\n",
      "epoch: 5560, train_loss =  20.9008, val_loss =  20.9628\n",
      "epoch: 5570, train_loss =  20.8883, val_loss =  20.9503\n",
      "epoch: 5580, train_loss =  20.8758, val_loss =  20.9378\n",
      "epoch: 5590, train_loss =  20.8633, val_loss =  20.9253\n",
      "epoch: 5600, train_loss =  20.8508, val_loss =  20.9128\n",
      "epoch: 5610, train_loss =  20.8383, val_loss =  20.9002\n",
      "epoch: 5620, train_loss =  20.8258, val_loss =  20.8877\n",
      "epoch: 5630, train_loss =  20.8133, val_loss =  20.8752\n",
      "epoch: 5640, train_loss =  20.8008, val_loss =  20.8627\n",
      "epoch: 5650, train_loss =  20.7883, val_loss =  20.8502\n",
      "epoch: 5660, train_loss =  20.7758, val_loss =  20.8377\n",
      "epoch: 5670, train_loss =  20.7633, val_loss =  20.8252\n",
      "epoch: 5680, train_loss =  20.7508, val_loss =  20.8127\n",
      "epoch: 5690, train_loss =  20.7383, val_loss =  20.8002\n",
      "epoch: 5700, train_loss =  20.7258, val_loss =  20.7877\n",
      "epoch: 5710, train_loss =  20.7133, val_loss =  20.7752\n",
      "epoch: 5720, train_loss =  20.7008, val_loss =  20.7627\n",
      "epoch: 5730, train_loss =  20.6883, val_loss =  20.7502\n",
      "epoch: 5740, train_loss =  20.6758, val_loss =  20.7377\n",
      "epoch: 5750, train_loss =  20.6633, val_loss =  20.7252\n",
      "epoch: 5760, train_loss =  20.6509, val_loss =  20.7127\n",
      "epoch: 5770, train_loss =  20.6384, val_loss =  20.7002\n",
      "epoch: 5780, train_loss =  20.6259, val_loss =  20.6877\n",
      "epoch: 5790, train_loss =  20.6134, val_loss =  20.6752\n",
      "epoch: 5800, train_loss =  20.6009, val_loss =  20.6626\n",
      "epoch: 5810, train_loss =  20.5884, val_loss =  20.6501\n",
      "epoch: 5820, train_loss =  20.5759, val_loss =  20.6376\n",
      "epoch: 5830, train_loss =  20.5634, val_loss =  20.6251\n",
      "epoch: 5840, train_loss =  20.5509, val_loss =  20.6126\n",
      "epoch: 5850, train_loss =  20.5384, val_loss =  20.6001\n",
      "epoch: 5860, train_loss =  20.5259, val_loss =  20.5876\n",
      "epoch: 5870, train_loss =  20.5134, val_loss =  20.5751\n",
      "epoch: 5880, train_loss =  20.5009, val_loss =  20.5626\n",
      "epoch: 5890, train_loss =  20.4884, val_loss =  20.5501\n",
      "epoch: 5900, train_loss =  20.4759, val_loss =  20.5376\n",
      "epoch: 5910, train_loss =  20.4634, val_loss =  20.5251\n",
      "epoch: 5920, train_loss =  20.4509, val_loss =  20.5126\n",
      "epoch: 5930, train_loss =  20.4384, val_loss =  20.5001\n",
      "epoch: 5940, train_loss =  20.4259, val_loss =  20.4876\n",
      "epoch: 5950, train_loss =  20.4134, val_loss =  20.4751\n",
      "epoch: 5960, train_loss =  20.4009, val_loss =  20.4626\n",
      "epoch: 5970, train_loss =  20.3884, val_loss =  20.4501\n",
      "epoch: 5980, train_loss =  20.3759, val_loss =  20.4376\n",
      "epoch: 5990, train_loss =  20.3634, val_loss =  20.4250\n",
      "epoch: 6000, train_loss =  20.3510, val_loss =  20.4125\n",
      "epoch: 6010, train_loss =  20.3385, val_loss =  20.4000\n",
      "epoch: 6020, train_loss =  20.3260, val_loss =  20.3875\n",
      "epoch: 6030, train_loss =  20.3135, val_loss =  20.3750\n",
      "epoch: 6040, train_loss =  20.3010, val_loss =  20.3625\n",
      "epoch: 6050, train_loss =  20.2885, val_loss =  20.3500\n",
      "epoch: 6060, train_loss =  20.2760, val_loss =  20.3375\n",
      "epoch: 6070, train_loss =  20.2635, val_loss =  20.3250\n",
      "epoch: 6080, train_loss =  20.2510, val_loss =  20.3125\n",
      "epoch: 6090, train_loss =  20.2385, val_loss =  20.3000\n",
      "epoch: 6100, train_loss =  20.2260, val_loss =  20.2875\n",
      "epoch: 6110, train_loss =  20.2135, val_loss =  20.2750\n",
      "epoch: 6120, train_loss =  20.2010, val_loss =  20.2625\n",
      "epoch: 6130, train_loss =  20.1885, val_loss =  20.2500\n",
      "epoch: 6140, train_loss =  20.1760, val_loss =  20.2375\n",
      "epoch: 6150, train_loss =  20.1635, val_loss =  20.2250\n",
      "epoch: 6160, train_loss =  20.1510, val_loss =  20.2125\n",
      "epoch: 6170, train_loss =  20.1385, val_loss =  20.2000\n",
      "epoch: 6180, train_loss =  20.1260, val_loss =  20.1874\n",
      "epoch: 6190, train_loss =  20.1135, val_loss =  20.1749\n",
      "epoch: 6200, train_loss =  20.1010, val_loss =  20.1624\n",
      "epoch: 6210, train_loss =  20.0885, val_loss =  20.1499\n",
      "epoch: 6220, train_loss =  20.0761, val_loss =  20.1374\n",
      "epoch: 6230, train_loss =  20.0636, val_loss =  20.1249\n",
      "epoch: 6240, train_loss =  20.0511, val_loss =  20.1124\n",
      "epoch: 6250, train_loss =  20.0386, val_loss =  20.0999\n",
      "epoch: 6260, train_loss =  20.0261, val_loss =  20.0874\n",
      "epoch: 6270, train_loss =  20.0136, val_loss =  20.0749\n",
      "epoch: 6280, train_loss =  20.0011, val_loss =  20.0624\n",
      "epoch: 6290, train_loss =  19.9886, val_loss =  20.0499\n",
      "epoch: 6300, train_loss =  19.9761, val_loss =  20.0374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6310, train_loss =  19.9636, val_loss =  20.0249\n",
      "epoch: 6320, train_loss =  19.9511, val_loss =  20.0124\n",
      "epoch: 6330, train_loss =  19.9386, val_loss =  19.9999\n",
      "epoch: 6340, train_loss =  19.9261, val_loss =  19.9874\n",
      "epoch: 6350, train_loss =  19.9136, val_loss =  19.9748\n",
      "epoch: 6360, train_loss =  19.9011, val_loss =  19.9623\n",
      "epoch: 6370, train_loss =  19.8886, val_loss =  19.9498\n",
      "epoch: 6380, train_loss =  19.8761, val_loss =  19.9373\n",
      "epoch: 6390, train_loss =  19.8636, val_loss =  19.9248\n",
      "epoch: 6400, train_loss =  19.8511, val_loss =  19.9123\n",
      "epoch: 6410, train_loss =  19.8386, val_loss =  19.8998\n",
      "epoch: 6420, train_loss =  19.8262, val_loss =  19.8873\n",
      "epoch: 6430, train_loss =  19.8137, val_loss =  19.8748\n",
      "epoch: 6440, train_loss =  19.8012, val_loss =  19.8623\n",
      "epoch: 6450, train_loss =  19.7887, val_loss =  19.8498\n",
      "epoch: 6460, train_loss =  19.7762, val_loss =  19.8373\n",
      "epoch: 6470, train_loss =  19.7637, val_loss =  19.8248\n",
      "epoch: 6480, train_loss =  19.7512, val_loss =  19.8123\n",
      "epoch: 6490, train_loss =  19.7387, val_loss =  19.7998\n",
      "epoch: 6500, train_loss =  19.7262, val_loss =  19.7873\n",
      "epoch: 6510, train_loss =  19.7137, val_loss =  19.7748\n",
      "epoch: 6520, train_loss =  19.7012, val_loss =  19.7622\n",
      "epoch: 6530, train_loss =  19.6887, val_loss =  19.7497\n",
      "epoch: 6540, train_loss =  19.6762, val_loss =  19.7372\n",
      "epoch: 6550, train_loss =  19.6637, val_loss =  19.7247\n",
      "epoch: 6560, train_loss =  19.6512, val_loss =  19.7122\n",
      "epoch: 6570, train_loss =  19.6387, val_loss =  19.6997\n",
      "epoch: 6580, train_loss =  19.6262, val_loss =  19.6872\n",
      "epoch: 6590, train_loss =  19.6137, val_loss =  19.6747\n",
      "epoch: 6600, train_loss =  19.6012, val_loss =  19.6622\n",
      "epoch: 6610, train_loss =  19.5887, val_loss =  19.6497\n",
      "epoch: 6620, train_loss =  19.5763, val_loss =  19.6372\n",
      "epoch: 6630, train_loss =  19.5638, val_loss =  19.6247\n",
      "epoch: 6640, train_loss =  19.5513, val_loss =  19.6122\n",
      "epoch: 6650, train_loss =  19.5388, val_loss =  19.5997\n",
      "epoch: 6660, train_loss =  19.5263, val_loss =  19.5872\n",
      "epoch: 6670, train_loss =  19.5138, val_loss =  19.5746\n",
      "epoch: 6680, train_loss =  19.5013, val_loss =  19.5621\n",
      "epoch: 6690, train_loss =  19.4888, val_loss =  19.5496\n",
      "epoch: 6700, train_loss =  19.4763, val_loss =  19.5371\n",
      "epoch: 6710, train_loss =  19.4638, val_loss =  19.5246\n",
      "epoch: 6720, train_loss =  19.4513, val_loss =  19.5121\n",
      "epoch: 6730, train_loss =  19.4388, val_loss =  19.4996\n",
      "epoch: 6740, train_loss =  19.4263, val_loss =  19.4871\n",
      "epoch: 6750, train_loss =  19.4138, val_loss =  19.4746\n",
      "epoch: 6760, train_loss =  19.4013, val_loss =  19.4621\n",
      "epoch: 6770, train_loss =  19.3888, val_loss =  19.4496\n",
      "epoch: 6780, train_loss =  19.3763, val_loss =  19.4371\n",
      "epoch: 6790, train_loss =  19.3638, val_loss =  19.4246\n",
      "epoch: 6800, train_loss =  19.3513, val_loss =  19.4121\n",
      "epoch: 6810, train_loss =  19.3388, val_loss =  19.3996\n",
      "epoch: 6820, train_loss =  19.3263, val_loss =  19.3870\n",
      "epoch: 6830, train_loss =  19.3139, val_loss =  19.3745\n",
      "epoch: 6840, train_loss =  19.3014, val_loss =  19.3620\n",
      "epoch: 6850, train_loss =  19.2889, val_loss =  19.3495\n",
      "epoch: 6860, train_loss =  19.2764, val_loss =  19.3370\n",
      "epoch: 6870, train_loss =  19.2639, val_loss =  19.3245\n",
      "epoch: 6880, train_loss =  19.2514, val_loss =  19.3120\n",
      "epoch: 6890, train_loss =  19.2389, val_loss =  19.2995\n",
      "epoch: 6900, train_loss =  19.2264, val_loss =  19.2870\n",
      "epoch: 6910, train_loss =  19.2139, val_loss =  19.2745\n",
      "epoch: 6920, train_loss =  19.2014, val_loss =  19.2620\n",
      "epoch: 6930, train_loss =  19.1889, val_loss =  19.2495\n",
      "epoch: 6940, train_loss =  19.1764, val_loss =  19.2370\n",
      "epoch: 6950, train_loss =  19.1639, val_loss =  19.2245\n",
      "epoch: 6960, train_loss =  19.1514, val_loss =  19.2120\n",
      "epoch: 6970, train_loss =  19.1389, val_loss =  19.1994\n",
      "epoch: 6980, train_loss =  19.1264, val_loss =  19.1869\n",
      "epoch: 6990, train_loss =  19.1139, val_loss =  19.1744\n",
      "epoch: 7000, train_loss =  19.1014, val_loss =  19.1619\n",
      "epoch: 7010, train_loss =  19.0889, val_loss =  19.1494\n",
      "epoch: 7020, train_loss =  19.0765, val_loss =  19.1369\n",
      "epoch: 7030, train_loss =  19.0640, val_loss =  19.1244\n",
      "epoch: 7040, train_loss =  19.0515, val_loss =  19.1119\n",
      "epoch: 7050, train_loss =  19.0390, val_loss =  19.0994\n",
      "epoch: 7060, train_loss =  19.0265, val_loss =  19.0869\n",
      "epoch: 7070, train_loss =  19.0140, val_loss =  19.0744\n",
      "epoch: 7080, train_loss =  19.0015, val_loss =  19.0619\n",
      "epoch: 7090, train_loss =  18.9890, val_loss =  19.0494\n",
      "epoch: 7100, train_loss =  18.9765, val_loss =  19.0369\n",
      "epoch: 7110, train_loss =  18.9640, val_loss =  19.0244\n",
      "epoch: 7120, train_loss =  18.9515, val_loss =  19.0118\n",
      "epoch: 7130, train_loss =  18.9390, val_loss =  18.9993\n",
      "epoch: 7140, train_loss =  18.9265, val_loss =  18.9868\n",
      "epoch: 7150, train_loss =  18.9140, val_loss =  18.9743\n",
      "epoch: 7160, train_loss =  18.9015, val_loss =  18.9618\n",
      "epoch: 7170, train_loss =  18.8890, val_loss =  18.9493\n",
      "epoch: 7180, train_loss =  18.8766, val_loss =  18.9368\n",
      "epoch: 7190, train_loss =  18.8641, val_loss =  18.9243\n",
      "epoch: 7200, train_loss =  18.8516, val_loss =  18.9118\n",
      "epoch: 7210, train_loss =  18.8391, val_loss =  18.8993\n",
      "epoch: 7220, train_loss =  18.8266, val_loss =  18.8868\n",
      "epoch: 7230, train_loss =  18.8141, val_loss =  18.8743\n",
      "epoch: 7240, train_loss =  18.8016, val_loss =  18.8618\n",
      "epoch: 7250, train_loss =  18.7891, val_loss =  18.8493\n",
      "epoch: 7260, train_loss =  18.7766, val_loss =  18.8368\n",
      "epoch: 7270, train_loss =  18.7641, val_loss =  18.8243\n",
      "epoch: 7280, train_loss =  18.7516, val_loss =  18.8118\n",
      "epoch: 7290, train_loss =  18.7391, val_loss =  18.7992\n",
      "epoch: 7300, train_loss =  18.7266, val_loss =  18.7867\n",
      "epoch: 7310, train_loss =  18.7141, val_loss =  18.7742\n",
      "epoch: 7320, train_loss =  18.7017, val_loss =  18.7617\n",
      "epoch: 7330, train_loss =  18.6892, val_loss =  18.7492\n",
      "epoch: 7340, train_loss =  18.6767, val_loss =  18.7367\n",
      "epoch: 7350, train_loss =  18.6642, val_loss =  18.7242\n",
      "epoch: 7360, train_loss =  18.6517, val_loss =  18.7117\n",
      "epoch: 7370, train_loss =  18.6392, val_loss =  18.6992\n",
      "epoch: 7380, train_loss =  18.6267, val_loss =  18.6867\n",
      "epoch: 7390, train_loss =  18.6142, val_loss =  18.6742\n",
      "epoch: 7400, train_loss =  18.6017, val_loss =  18.6617\n",
      "epoch: 7410, train_loss =  18.5892, val_loss =  18.6492\n",
      "epoch: 7420, train_loss =  18.5767, val_loss =  18.6367\n",
      "epoch: 7430, train_loss =  18.5642, val_loss =  18.6242\n",
      "epoch: 7440, train_loss =  18.5517, val_loss =  18.6117\n",
      "epoch: 7450, train_loss =  18.5392, val_loss =  18.5991\n",
      "epoch: 7460, train_loss =  18.5267, val_loss =  18.5866\n",
      "epoch: 7470, train_loss =  18.5142, val_loss =  18.5741\n",
      "epoch: 7480, train_loss =  18.5018, val_loss =  18.5616\n",
      "epoch: 7490, train_loss =  18.4893, val_loss =  18.5491\n",
      "epoch: 7500, train_loss =  18.4768, val_loss =  18.5366\n",
      "epoch: 7510, train_loss =  18.4643, val_loss =  18.5241\n",
      "epoch: 7520, train_loss =  18.4518, val_loss =  18.5116\n",
      "epoch: 7530, train_loss =  18.4393, val_loss =  18.4991\n",
      "epoch: 7540, train_loss =  18.4268, val_loss =  18.4866\n",
      "epoch: 7550, train_loss =  18.4143, val_loss =  18.4741\n",
      "epoch: 7560, train_loss =  18.4018, val_loss =  18.4615\n",
      "epoch: 7570, train_loss =  18.3893, val_loss =  18.4490\n",
      "epoch: 7580, train_loss =  18.3768, val_loss =  18.4365\n",
      "epoch: 7590, train_loss =  18.3643, val_loss =  18.4240\n",
      "epoch: 7600, train_loss =  18.3518, val_loss =  18.4115\n",
      "epoch: 7610, train_loss =  18.3393, val_loss =  18.3990\n",
      "epoch: 7620, train_loss =  18.3268, val_loss =  18.3865\n",
      "epoch: 7630, train_loss =  18.3143, val_loss =  18.3740\n",
      "epoch: 7640, train_loss =  18.3018, val_loss =  18.3615\n",
      "epoch: 7650, train_loss =  18.2893, val_loss =  18.3490\n",
      "epoch: 7660, train_loss =  18.2768, val_loss =  18.3365\n",
      "epoch: 7670, train_loss =  18.2644, val_loss =  18.3240\n",
      "epoch: 7680, train_loss =  18.2519, val_loss =  18.3114\n",
      "epoch: 7690, train_loss =  18.2394, val_loss =  18.2989\n",
      "epoch: 7700, train_loss =  18.2269, val_loss =  18.2864\n",
      "epoch: 7710, train_loss =  18.2144, val_loss =  18.2739\n",
      "epoch: 7720, train_loss =  18.2019, val_loss =  18.2614\n",
      "epoch: 7730, train_loss =  18.1894, val_loss =  18.2489\n",
      "epoch: 7740, train_loss =  18.1769, val_loss =  18.2364\n",
      "epoch: 7750, train_loss =  18.1644, val_loss =  18.2239\n",
      "epoch: 7760, train_loss =  18.1519, val_loss =  18.2114\n",
      "epoch: 7770, train_loss =  18.1394, val_loss =  18.1989\n",
      "epoch: 7780, train_loss =  18.1269, val_loss =  18.1864\n",
      "epoch: 7790, train_loss =  18.1144, val_loss =  18.1738\n",
      "epoch: 7800, train_loss =  18.1019, val_loss =  18.1613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7810, train_loss =  18.0894, val_loss =  18.1488\n",
      "epoch: 7820, train_loss =  18.0769, val_loss =  18.1363\n",
      "epoch: 7830, train_loss =  18.0644, val_loss =  18.1238\n",
      "epoch: 7840, train_loss =  18.0519, val_loss =  18.1113\n",
      "epoch: 7850, train_loss =  18.0394, val_loss =  18.0988\n",
      "epoch: 7860, train_loss =  18.0269, val_loss =  18.0863\n",
      "epoch: 7870, train_loss =  18.0145, val_loss =  18.0738\n",
      "epoch: 7880, train_loss =  18.0020, val_loss =  18.0613\n",
      "epoch: 7890, train_loss =  17.9895, val_loss =  18.0488\n",
      "epoch: 7900, train_loss =  17.9770, val_loss =  18.0362\n",
      "epoch: 7910, train_loss =  17.9645, val_loss =  18.0237\n",
      "epoch: 7920, train_loss =  17.9520, val_loss =  18.0112\n",
      "epoch: 7930, train_loss =  17.9395, val_loss =  17.9987\n",
      "epoch: 7940, train_loss =  17.9270, val_loss =  17.9862\n",
      "epoch: 7950, train_loss =  17.9145, val_loss =  17.9737\n",
      "epoch: 7960, train_loss =  17.9020, val_loss =  17.9612\n",
      "epoch: 7970, train_loss =  17.8895, val_loss =  17.9487\n",
      "epoch: 7980, train_loss =  17.8770, val_loss =  17.9362\n",
      "epoch: 7990, train_loss =  17.8645, val_loss =  17.9237\n",
      "epoch: 8000, train_loss =  17.8520, val_loss =  17.9112\n",
      "epoch: 8010, train_loss =  17.8395, val_loss =  17.8986\n",
      "epoch: 8020, train_loss =  17.8270, val_loss =  17.8861\n",
      "epoch: 8030, train_loss =  17.8145, val_loss =  17.8736\n",
      "epoch: 8040, train_loss =  17.8020, val_loss =  17.8611\n",
      "epoch: 8050, train_loss =  17.7896, val_loss =  17.8486\n",
      "epoch: 8060, train_loss =  17.7771, val_loss =  17.8361\n",
      "epoch: 8070, train_loss =  17.7646, val_loss =  17.8236\n",
      "epoch: 8080, train_loss =  17.7521, val_loss =  17.8111\n",
      "epoch: 8090, train_loss =  17.7396, val_loss =  17.7986\n",
      "epoch: 8100, train_loss =  17.7271, val_loss =  17.7861\n",
      "epoch: 8110, train_loss =  17.7146, val_loss =  17.7736\n",
      "epoch: 8120, train_loss =  17.7021, val_loss =  17.7610\n",
      "epoch: 8130, train_loss =  17.6896, val_loss =  17.7485\n",
      "epoch: 8140, train_loss =  17.6771, val_loss =  17.7360\n",
      "epoch: 8150, train_loss =  17.6646, val_loss =  17.7235\n",
      "epoch: 8160, train_loss =  17.6521, val_loss =  17.7110\n",
      "epoch: 8170, train_loss =  17.6396, val_loss =  17.6985\n",
      "epoch: 8180, train_loss =  17.6271, val_loss =  17.6860\n",
      "epoch: 8190, train_loss =  17.6146, val_loss =  17.6735\n",
      "epoch: 8200, train_loss =  17.6021, val_loss =  17.6610\n",
      "epoch: 8210, train_loss =  17.5896, val_loss =  17.6485\n",
      "epoch: 8220, train_loss =  17.5771, val_loss =  17.6360\n",
      "epoch: 8230, train_loss =  17.5647, val_loss =  17.6234\n",
      "epoch: 8240, train_loss =  17.5522, val_loss =  17.6109\n",
      "epoch: 8250, train_loss =  17.5397, val_loss =  17.5984\n",
      "epoch: 8260, train_loss =  17.5272, val_loss =  17.5859\n",
      "epoch: 8270, train_loss =  17.5147, val_loss =  17.5734\n",
      "epoch: 8280, train_loss =  17.5022, val_loss =  17.5609\n",
      "epoch: 8290, train_loss =  17.4897, val_loss =  17.5484\n",
      "epoch: 8300, train_loss =  17.4772, val_loss =  17.5359\n",
      "epoch: 8310, train_loss =  17.4647, val_loss =  17.5234\n",
      "epoch: 8320, train_loss =  17.4522, val_loss =  17.5109\n",
      "epoch: 8330, train_loss =  17.4397, val_loss =  17.4983\n",
      "epoch: 8340, train_loss =  17.4272, val_loss =  17.4858\n",
      "epoch: 8350, train_loss =  17.4147, val_loss =  17.4733\n",
      "epoch: 8360, train_loss =  17.4022, val_loss =  17.4608\n",
      "epoch: 8370, train_loss =  17.3897, val_loss =  17.4483\n",
      "epoch: 8380, train_loss =  17.3772, val_loss =  17.4358\n",
      "epoch: 8390, train_loss =  17.3647, val_loss =  17.4233\n",
      "epoch: 8400, train_loss =  17.3523, val_loss =  17.4108\n",
      "epoch: 8410, train_loss =  17.3398, val_loss =  17.3983\n",
      "epoch: 8420, train_loss =  17.3273, val_loss =  17.3858\n",
      "epoch: 8430, train_loss =  17.3148, val_loss =  17.3732\n",
      "epoch: 8440, train_loss =  17.3023, val_loss =  17.3607\n",
      "epoch: 8450, train_loss =  17.2898, val_loss =  17.3482\n",
      "epoch: 8460, train_loss =  17.2773, val_loss =  17.3357\n",
      "epoch: 8470, train_loss =  17.2648, val_loss =  17.3232\n",
      "epoch: 8480, train_loss =  17.2523, val_loss =  17.3107\n",
      "epoch: 8490, train_loss =  17.2398, val_loss =  17.2982\n",
      "epoch: 8500, train_loss =  17.2273, val_loss =  17.2857\n",
      "epoch: 8510, train_loss =  17.2148, val_loss =  17.2732\n",
      "epoch: 8520, train_loss =  17.2023, val_loss =  17.2607\n",
      "epoch: 8530, train_loss =  17.1898, val_loss =  17.2482\n",
      "epoch: 8540, train_loss =  17.1773, val_loss =  17.2356\n",
      "epoch: 8550, train_loss =  17.1648, val_loss =  17.2231\n",
      "epoch: 8560, train_loss =  17.1523, val_loss =  17.2106\n",
      "epoch: 8570, train_loss =  17.1399, val_loss =  17.1981\n",
      "epoch: 8580, train_loss =  17.1274, val_loss =  17.1856\n",
      "epoch: 8590, train_loss =  17.1149, val_loss =  17.1731\n",
      "epoch: 8600, train_loss =  17.1024, val_loss =  17.1606\n",
      "epoch: 8610, train_loss =  17.0899, val_loss =  17.1481\n",
      "epoch: 8620, train_loss =  17.0774, val_loss =  17.1356\n",
      "epoch: 8630, train_loss =  17.0649, val_loss =  17.1231\n",
      "epoch: 8640, train_loss =  17.0524, val_loss =  17.1105\n",
      "epoch: 8650, train_loss =  17.0399, val_loss =  17.0980\n",
      "epoch: 8660, train_loss =  17.0274, val_loss =  17.0855\n",
      "epoch: 8670, train_loss =  17.0149, val_loss =  17.0730\n",
      "epoch: 8680, train_loss =  17.0024, val_loss =  17.0605\n",
      "epoch: 8690, train_loss =  16.9899, val_loss =  17.0480\n",
      "epoch: 8700, train_loss =  16.9774, val_loss =  17.0355\n",
      "epoch: 8710, train_loss =  16.9649, val_loss =  17.0230\n",
      "epoch: 8720, train_loss =  16.9524, val_loss =  17.0105\n",
      "epoch: 8730, train_loss =  16.9400, val_loss =  16.9980\n",
      "epoch: 8740, train_loss =  16.9275, val_loss =  16.9854\n",
      "epoch: 8750, train_loss =  16.9150, val_loss =  16.9729\n",
      "epoch: 8760, train_loss =  16.9025, val_loss =  16.9604\n",
      "epoch: 8770, train_loss =  16.8900, val_loss =  16.9479\n",
      "epoch: 8780, train_loss =  16.8775, val_loss =  16.9354\n",
      "epoch: 8790, train_loss =  16.8650, val_loss =  16.9229\n",
      "epoch: 8800, train_loss =  16.8525, val_loss =  16.9104\n",
      "epoch: 8810, train_loss =  16.8400, val_loss =  16.8979\n",
      "epoch: 8820, train_loss =  16.8275, val_loss =  16.8854\n",
      "epoch: 8830, train_loss =  16.8150, val_loss =  16.8729\n",
      "epoch: 8840, train_loss =  16.8025, val_loss =  16.8603\n",
      "epoch: 8850, train_loss =  16.7900, val_loss =  16.8478\n",
      "epoch: 8860, train_loss =  16.7775, val_loss =  16.8353\n",
      "epoch: 8870, train_loss =  16.7650, val_loss =  16.8228\n",
      "epoch: 8880, train_loss =  16.7525, val_loss =  16.8103\n",
      "epoch: 8890, train_loss =  16.7401, val_loss =  16.7978\n",
      "epoch: 8900, train_loss =  16.7276, val_loss =  16.7853\n",
      "epoch: 8910, train_loss =  16.7151, val_loss =  16.7728\n",
      "epoch: 8920, train_loss =  16.7026, val_loss =  16.7603\n",
      "epoch: 8930, train_loss =  16.6901, val_loss =  16.7478\n",
      "epoch: 8940, train_loss =  16.6776, val_loss =  16.7352\n",
      "epoch: 8950, train_loss =  16.6651, val_loss =  16.7227\n",
      "epoch: 8960, train_loss =  16.6526, val_loss =  16.7102\n",
      "epoch: 8970, train_loss =  16.6401, val_loss =  16.6977\n",
      "epoch: 8980, train_loss =  16.6276, val_loss =  16.6852\n",
      "epoch: 8990, train_loss =  16.6151, val_loss =  16.6727\n",
      "epoch: 9000, train_loss =  16.6026, val_loss =  16.6602\n",
      "epoch: 9010, train_loss =  16.5901, val_loss =  16.6477\n",
      "epoch: 9020, train_loss =  16.5776, val_loss =  16.6352\n",
      "epoch: 9030, train_loss =  16.5651, val_loss =  16.6226\n",
      "epoch: 9040, train_loss =  16.5527, val_loss =  16.6101\n",
      "epoch: 9050, train_loss =  16.5402, val_loss =  16.5976\n",
      "epoch: 9060, train_loss =  16.5277, val_loss =  16.5851\n",
      "epoch: 9070, train_loss =  16.5152, val_loss =  16.5726\n",
      "epoch: 9080, train_loss =  16.5027, val_loss =  16.5601\n",
      "epoch: 9090, train_loss =  16.4902, val_loss =  16.5476\n",
      "epoch: 9100, train_loss =  16.4777, val_loss =  16.5351\n",
      "epoch: 9110, train_loss =  16.4652, val_loss =  16.5226\n",
      "epoch: 9120, train_loss =  16.4527, val_loss =  16.5101\n",
      "epoch: 9130, train_loss =  16.4402, val_loss =  16.4975\n",
      "epoch: 9140, train_loss =  16.4277, val_loss =  16.4850\n",
      "epoch: 9150, train_loss =  16.4152, val_loss =  16.4725\n",
      "epoch: 9160, train_loss =  16.4027, val_loss =  16.4600\n",
      "epoch: 9170, train_loss =  16.3902, val_loss =  16.4475\n",
      "epoch: 9180, train_loss =  16.3778, val_loss =  16.4350\n",
      "epoch: 9190, train_loss =  16.3653, val_loss =  16.4225\n",
      "epoch: 9200, train_loss =  16.3528, val_loss =  16.4100\n",
      "epoch: 9210, train_loss =  16.3403, val_loss =  16.3975\n",
      "epoch: 9220, train_loss =  16.3278, val_loss =  16.3850\n",
      "epoch: 9230, train_loss =  16.3153, val_loss =  16.3725\n",
      "epoch: 9240, train_loss =  16.3028, val_loss =  16.3599\n",
      "epoch: 9250, train_loss =  16.2903, val_loss =  16.3474\n",
      "epoch: 9260, train_loss =  16.2778, val_loss =  16.3349\n",
      "epoch: 9270, train_loss =  16.2653, val_loss =  16.3224\n",
      "epoch: 9280, train_loss =  16.2528, val_loss =  16.3099\n",
      "epoch: 9290, train_loss =  16.2403, val_loss =  16.2974\n",
      "epoch: 9300, train_loss =  16.2279, val_loss =  16.2849\n",
      "epoch: 9310, train_loss =  16.2154, val_loss =  16.2724\n",
      "epoch: 9320, train_loss =  16.2029, val_loss =  16.2599\n",
      "epoch: 9330, train_loss =  16.1904, val_loss =  16.2474\n",
      "epoch: 9340, train_loss =  16.1779, val_loss =  16.2349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9350, train_loss =  16.1654, val_loss =  16.2223\n",
      "epoch: 9360, train_loss =  16.1529, val_loss =  16.2098\n",
      "epoch: 9370, train_loss =  16.1404, val_loss =  16.1973\n",
      "epoch: 9380, train_loss =  16.1279, val_loss =  16.1848\n",
      "epoch: 9390, train_loss =  16.1154, val_loss =  16.1723\n",
      "epoch: 9400, train_loss =  16.1029, val_loss =  16.1598\n",
      "epoch: 9410, train_loss =  16.0905, val_loss =  16.1473\n",
      "epoch: 9420, train_loss =  16.0780, val_loss =  16.1348\n",
      "epoch: 9430, train_loss =  16.0655, val_loss =  16.1223\n",
      "epoch: 9440, train_loss =  16.0530, val_loss =  16.1098\n",
      "epoch: 9450, train_loss =  16.0405, val_loss =  16.0973\n",
      "epoch: 9460, train_loss =  16.0280, val_loss =  16.0847\n",
      "epoch: 9470, train_loss =  16.0155, val_loss =  16.0722\n",
      "epoch: 9480, train_loss =  16.0030, val_loss =  16.0597\n",
      "epoch: 9490, train_loss =  15.9905, val_loss =  16.0472\n",
      "epoch: 9500, train_loss =  15.9780, val_loss =  16.0347\n",
      "epoch: 9510, train_loss =  15.9655, val_loss =  16.0222\n",
      "epoch: 9520, train_loss =  15.9530, val_loss =  16.0097\n",
      "epoch: 9530, train_loss =  15.9406, val_loss =  15.9972\n",
      "epoch: 9540, train_loss =  15.9281, val_loss =  15.9847\n",
      "epoch: 9550, train_loss =  15.9156, val_loss =  15.9722\n",
      "epoch: 9560, train_loss =  15.9031, val_loss =  15.9597\n",
      "epoch: 9570, train_loss =  15.8906, val_loss =  15.9471\n",
      "epoch: 9580, train_loss =  15.8781, val_loss =  15.9346\n",
      "epoch: 9590, train_loss =  15.8656, val_loss =  15.9221\n",
      "epoch: 9600, train_loss =  15.8531, val_loss =  15.9096\n",
      "epoch: 9610, train_loss =  15.8406, val_loss =  15.8971\n",
      "epoch: 9620, train_loss =  15.8281, val_loss =  15.8846\n",
      "epoch: 9630, train_loss =  15.8156, val_loss =  15.8721\n",
      "epoch: 9640, train_loss =  15.8032, val_loss =  15.8596\n",
      "epoch: 9650, train_loss =  15.7907, val_loss =  15.8471\n",
      "epoch: 9660, train_loss =  15.7782, val_loss =  15.8346\n",
      "epoch: 9670, train_loss =  15.7657, val_loss =  15.8221\n",
      "epoch: 9680, train_loss =  15.7532, val_loss =  15.8095\n",
      "epoch: 9690, train_loss =  15.7407, val_loss =  15.7970\n",
      "epoch: 9700, train_loss =  15.7282, val_loss =  15.7845\n",
      "epoch: 9710, train_loss =  15.7157, val_loss =  15.7720\n",
      "epoch: 9720, train_loss =  15.7032, val_loss =  15.7595\n",
      "epoch: 9730, train_loss =  15.6907, val_loss =  15.7470\n",
      "epoch: 9740, train_loss =  15.6782, val_loss =  15.7345\n",
      "epoch: 9750, train_loss =  15.6658, val_loss =  15.7220\n",
      "epoch: 9760, train_loss =  15.6533, val_loss =  15.7095\n",
      "epoch: 9770, train_loss =  15.6408, val_loss =  15.6970\n",
      "epoch: 9780, train_loss =  15.6283, val_loss =  15.6844\n",
      "epoch: 9790, train_loss =  15.6158, val_loss =  15.6719\n",
      "epoch: 9800, train_loss =  15.6033, val_loss =  15.6594\n",
      "epoch: 9810, train_loss =  15.5908, val_loss =  15.6469\n",
      "epoch: 9820, train_loss =  15.5783, val_loss =  15.6344\n",
      "epoch: 9830, train_loss =  15.5658, val_loss =  15.6219\n",
      "epoch: 9840, train_loss =  15.5533, val_loss =  15.6094\n",
      "epoch: 9850, train_loss =  15.5408, val_loss =  15.5969\n",
      "epoch: 9860, train_loss =  15.5284, val_loss =  15.5844\n",
      "epoch: 9870, train_loss =  15.5159, val_loss =  15.5719\n",
      "epoch: 9880, train_loss =  15.5034, val_loss =  15.5594\n",
      "epoch: 9890, train_loss =  15.4909, val_loss =  15.5468\n",
      "epoch: 9900, train_loss =  15.4784, val_loss =  15.5343\n",
      "epoch: 9910, train_loss =  15.4659, val_loss =  15.5218\n",
      "epoch: 9920, train_loss =  15.4534, val_loss =  15.5093\n",
      "epoch: 9930, train_loss =  15.4409, val_loss =  15.4968\n",
      "epoch: 9940, train_loss =  15.4284, val_loss =  15.4843\n",
      "epoch: 9950, train_loss =  15.4159, val_loss =  15.4718\n",
      "epoch: 9960, train_loss =  15.4034, val_loss =  15.4593\n",
      "epoch: 9970, train_loss =  15.3910, val_loss =  15.4468\n",
      "epoch: 9980, train_loss =  15.3785, val_loss =  15.4343\n",
      "epoch: 9990, train_loss =  15.3660, val_loss =  15.4217\n",
      "epoch: 10000, train_loss =  15.3535, val_loss =  15.4092\n",
      "epoch: 10010, train_loss =  15.3410, val_loss =  15.3967\n",
      "epoch: 10020, train_loss =  15.3285, val_loss =  15.3842\n",
      "epoch: 10030, train_loss =  15.3160, val_loss =  15.3717\n",
      "epoch: 10040, train_loss =  15.3035, val_loss =  15.3592\n",
      "epoch: 10050, train_loss =  15.2910, val_loss =  15.3467\n",
      "epoch: 10060, train_loss =  15.2785, val_loss =  15.3342\n",
      "epoch: 10070, train_loss =  15.2661, val_loss =  15.3217\n",
      "epoch: 10080, train_loss =  15.2536, val_loss =  15.3092\n",
      "epoch: 10090, train_loss =  15.2411, val_loss =  15.2966\n",
      "epoch: 10100, train_loss =  15.2286, val_loss =  15.2841\n",
      "epoch: 10110, train_loss =  15.2161, val_loss =  15.2716\n",
      "epoch: 10120, train_loss =  15.2036, val_loss =  15.2591\n",
      "epoch: 10130, train_loss =  15.1911, val_loss =  15.2466\n",
      "epoch: 10140, train_loss =  15.1786, val_loss =  15.2341\n",
      "epoch: 10150, train_loss =  15.1661, val_loss =  15.2216\n",
      "epoch: 10160, train_loss =  15.1536, val_loss =  15.2091\n",
      "epoch: 10170, train_loss =  15.1411, val_loss =  15.1966\n",
      "epoch: 10180, train_loss =  15.1287, val_loss =  15.1841\n",
      "epoch: 10190, train_loss =  15.1162, val_loss =  15.1715\n",
      "epoch: 10200, train_loss =  15.1037, val_loss =  15.1590\n",
      "epoch: 10210, train_loss =  15.0912, val_loss =  15.1465\n",
      "epoch: 10220, train_loss =  15.0787, val_loss =  15.1340\n",
      "epoch: 10230, train_loss =  15.0662, val_loss =  15.1215\n",
      "epoch: 10240, train_loss =  15.0537, val_loss =  15.1090\n",
      "epoch: 10250, train_loss =  15.0412, val_loss =  15.0965\n",
      "epoch: 10260, train_loss =  15.0287, val_loss =  15.0840\n",
      "epoch: 10270, train_loss =  15.0162, val_loss =  15.0715\n",
      "epoch: 10280, train_loss =  15.0037, val_loss =  15.0590\n",
      "epoch: 10290, train_loss =  14.9913, val_loss =  15.0464\n",
      "epoch: 10300, train_loss =  14.9788, val_loss =  15.0339\n",
      "epoch: 10310, train_loss =  14.9663, val_loss =  15.0214\n",
      "epoch: 10320, train_loss =  14.9538, val_loss =  15.0089\n",
      "epoch: 10330, train_loss =  14.9413, val_loss =  14.9964\n",
      "epoch: 10340, train_loss =  14.9288, val_loss =  14.9839\n",
      "epoch: 10350, train_loss =  14.9163, val_loss =  14.9714\n",
      "epoch: 10360, train_loss =  14.9038, val_loss =  14.9589\n",
      "epoch: 10370, train_loss =  14.8913, val_loss =  14.9464\n",
      "epoch: 10380, train_loss =  14.8789, val_loss =  14.9339\n",
      "epoch: 10390, train_loss =  14.8664, val_loss =  14.9214\n",
      "epoch: 10400, train_loss =  14.8539, val_loss =  14.9089\n",
      "epoch: 10410, train_loss =  14.8414, val_loss =  14.8963\n",
      "epoch: 10420, train_loss =  14.8289, val_loss =  14.8838\n",
      "epoch: 10430, train_loss =  14.8164, val_loss =  14.8713\n",
      "epoch: 10440, train_loss =  14.8039, val_loss =  14.8588\n",
      "epoch: 10450, train_loss =  14.7915, val_loss =  14.8463\n",
      "epoch: 10460, train_loss =  14.7790, val_loss =  14.8338\n",
      "epoch: 10470, train_loss =  14.7665, val_loss =  14.8213\n",
      "epoch: 10480, train_loss =  14.7540, val_loss =  14.8088\n",
      "epoch: 10490, train_loss =  14.7415, val_loss =  14.7963\n",
      "epoch: 10500, train_loss =  14.7290, val_loss =  14.7838\n",
      "epoch: 10510, train_loss =  14.7165, val_loss =  14.7713\n",
      "epoch: 10520, train_loss =  14.7040, val_loss =  14.7588\n",
      "epoch: 10530, train_loss =  14.6916, val_loss =  14.7463\n",
      "epoch: 10540, train_loss =  14.6791, val_loss =  14.7338\n",
      "epoch: 10550, train_loss =  14.6666, val_loss =  14.7213\n",
      "epoch: 10560, train_loss =  14.6541, val_loss =  14.7088\n",
      "epoch: 10570, train_loss =  14.6416, val_loss =  14.6962\n",
      "epoch: 10580, train_loss =  14.6291, val_loss =  14.6837\n",
      "epoch: 10590, train_loss =  14.6166, val_loss =  14.6712\n",
      "epoch: 10600, train_loss =  14.6042, val_loss =  14.6587\n",
      "epoch: 10610, train_loss =  14.5917, val_loss =  14.6462\n",
      "epoch: 10620, train_loss =  14.5792, val_loss =  14.6337\n",
      "epoch: 10630, train_loss =  14.5667, val_loss =  14.6212\n",
      "epoch: 10640, train_loss =  14.5542, val_loss =  14.6087\n",
      "epoch: 10650, train_loss =  14.5417, val_loss =  14.5962\n",
      "epoch: 10660, train_loss =  14.5292, val_loss =  14.5837\n",
      "epoch: 10670, train_loss =  14.5168, val_loss =  14.5712\n",
      "epoch: 10680, train_loss =  14.5043, val_loss =  14.5587\n",
      "epoch: 10690, train_loss =  14.4918, val_loss =  14.5462\n",
      "epoch: 10700, train_loss =  14.4793, val_loss =  14.5337\n",
      "epoch: 10710, train_loss =  14.4668, val_loss =  14.5212\n",
      "epoch: 10720, train_loss =  14.4543, val_loss =  14.5087\n",
      "epoch: 10730, train_loss =  14.4418, val_loss =  14.4961\n",
      "epoch: 10740, train_loss =  14.4294, val_loss =  14.4836\n",
      "epoch: 10750, train_loss =  14.4169, val_loss =  14.4711\n",
      "epoch: 10760, train_loss =  14.4044, val_loss =  14.4586\n",
      "epoch: 10770, train_loss =  14.3919, val_loss =  14.4461\n",
      "epoch: 10780, train_loss =  14.3794, val_loss =  14.4336\n",
      "epoch: 10790, train_loss =  14.3669, val_loss =  14.4211\n",
      "epoch: 10800, train_loss =  14.3544, val_loss =  14.4086\n",
      "epoch: 10810, train_loss =  14.3420, val_loss =  14.3961\n",
      "epoch: 10820, train_loss =  14.3295, val_loss =  14.3836\n",
      "epoch: 10830, train_loss =  14.3170, val_loss =  14.3711\n",
      "epoch: 10840, train_loss =  14.3045, val_loss =  14.3586\n",
      "epoch: 10850, train_loss =  14.2920, val_loss =  14.3461\n",
      "epoch: 10860, train_loss =  14.2795, val_loss =  14.3336\n",
      "epoch: 10870, train_loss =  14.2670, val_loss =  14.3210\n",
      "epoch: 10880, train_loss =  14.2545, val_loss =  14.3085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10890, train_loss =  14.2421, val_loss =  14.2960\n",
      "epoch: 10900, train_loss =  14.2296, val_loss =  14.2835\n",
      "epoch: 10910, train_loss =  14.2171, val_loss =  14.2710\n",
      "epoch: 10920, train_loss =  14.2046, val_loss =  14.2585\n",
      "epoch: 10930, train_loss =  14.1921, val_loss =  14.2460\n",
      "epoch: 10940, train_loss =  14.1796, val_loss =  14.2335\n",
      "epoch: 10950, train_loss =  14.1671, val_loss =  14.2210\n",
      "epoch: 10960, train_loss =  14.1547, val_loss =  14.2085\n",
      "epoch: 10970, train_loss =  14.1422, val_loss =  14.1960\n",
      "epoch: 10980, train_loss =  14.1297, val_loss =  14.1835\n",
      "epoch: 10990, train_loss =  14.1172, val_loss =  14.1710\n",
      "epoch: 11000, train_loss =  14.1047, val_loss =  14.1585\n",
      "epoch: 11010, train_loss =  14.0922, val_loss =  14.1460\n",
      "epoch: 11020, train_loss =  14.0797, val_loss =  14.1334\n",
      "epoch: 11030, train_loss =  14.0673, val_loss =  14.1209\n",
      "epoch: 11040, train_loss =  14.0548, val_loss =  14.1084\n",
      "epoch: 11050, train_loss =  14.0423, val_loss =  14.0959\n",
      "epoch: 11060, train_loss =  14.0298, val_loss =  14.0834\n",
      "epoch: 11070, train_loss =  14.0173, val_loss =  14.0709\n",
      "epoch: 11080, train_loss =  14.0048, val_loss =  14.0584\n",
      "epoch: 11090, train_loss =  13.9923, val_loss =  14.0459\n",
      "epoch: 11100, train_loss =  13.9799, val_loss =  14.0334\n",
      "epoch: 11110, train_loss =  13.9674, val_loss =  14.0209\n",
      "epoch: 11120, train_loss =  13.9549, val_loss =  14.0084\n",
      "epoch: 11130, train_loss =  13.9424, val_loss =  13.9959\n",
      "epoch: 11140, train_loss =  13.9299, val_loss =  13.9834\n",
      "epoch: 11150, train_loss =  13.9174, val_loss =  13.9709\n",
      "epoch: 11160, train_loss =  13.9049, val_loss =  13.9583\n",
      "epoch: 11170, train_loss =  13.8925, val_loss =  13.9458\n",
      "epoch: 11180, train_loss =  13.8800, val_loss =  13.9333\n",
      "epoch: 11190, train_loss =  13.8675, val_loss =  13.9208\n",
      "epoch: 11200, train_loss =  13.8550, val_loss =  13.9083\n",
      "epoch: 11210, train_loss =  13.8425, val_loss =  13.8958\n",
      "epoch: 11220, train_loss =  13.8300, val_loss =  13.8833\n",
      "epoch: 11230, train_loss =  13.8175, val_loss =  13.8708\n",
      "epoch: 11240, train_loss =  13.8051, val_loss =  13.8583\n",
      "epoch: 11250, train_loss =  13.7926, val_loss =  13.8458\n",
      "epoch: 11260, train_loss =  13.7801, val_loss =  13.8333\n",
      "epoch: 11270, train_loss =  13.7676, val_loss =  13.8208\n",
      "epoch: 11280, train_loss =  13.7551, val_loss =  13.8083\n",
      "epoch: 11290, train_loss =  13.7426, val_loss =  13.7958\n",
      "epoch: 11300, train_loss =  13.7301, val_loss =  13.7832\n",
      "epoch: 11310, train_loss =  13.7177, val_loss =  13.7707\n",
      "epoch: 11320, train_loss =  13.7052, val_loss =  13.7582\n",
      "epoch: 11330, train_loss =  13.6927, val_loss =  13.7457\n",
      "epoch: 11340, train_loss =  13.6802, val_loss =  13.7332\n",
      "epoch: 11350, train_loss =  13.6677, val_loss =  13.7207\n",
      "epoch: 11360, train_loss =  13.6552, val_loss =  13.7082\n",
      "epoch: 11370, train_loss =  13.6427, val_loss =  13.6957\n",
      "epoch: 11380, train_loss =  13.6303, val_loss =  13.6832\n",
      "epoch: 11390, train_loss =  13.6178, val_loss =  13.6707\n",
      "epoch: 11400, train_loss =  13.6053, val_loss =  13.6582\n",
      "epoch: 11410, train_loss =  13.5928, val_loss =  13.6457\n",
      "epoch: 11420, train_loss =  13.5803, val_loss =  13.6332\n",
      "epoch: 11430, train_loss =  13.5678, val_loss =  13.6206\n",
      "epoch: 11440, train_loss =  13.5553, val_loss =  13.6081\n",
      "epoch: 11450, train_loss =  13.5429, val_loss =  13.5956\n",
      "epoch: 11460, train_loss =  13.5304, val_loss =  13.5831\n",
      "epoch: 11470, train_loss =  13.5179, val_loss =  13.5706\n",
      "epoch: 11480, train_loss =  13.5054, val_loss =  13.5581\n",
      "epoch: 11490, train_loss =  13.4929, val_loss =  13.5456\n",
      "epoch: 11500, train_loss =  13.4804, val_loss =  13.5331\n",
      "epoch: 11510, train_loss =  13.4680, val_loss =  13.5206\n",
      "epoch: 11520, train_loss =  13.4555, val_loss =  13.5081\n",
      "epoch: 11530, train_loss =  13.4430, val_loss =  13.4956\n",
      "epoch: 11540, train_loss =  13.4305, val_loss =  13.4831\n",
      "epoch: 11550, train_loss =  13.4180, val_loss =  13.4706\n",
      "epoch: 11560, train_loss =  13.4055, val_loss =  13.4580\n",
      "epoch: 11570, train_loss =  13.3930, val_loss =  13.4455\n",
      "epoch: 11580, train_loss =  13.3806, val_loss =  13.4330\n",
      "epoch: 11590, train_loss =  13.3681, val_loss =  13.4205\n",
      "epoch: 11600, train_loss =  13.3556, val_loss =  13.4080\n",
      "epoch: 11610, train_loss =  13.3431, val_loss =  13.3955\n",
      "epoch: 11620, train_loss =  13.3306, val_loss =  13.3830\n",
      "epoch: 11630, train_loss =  13.3181, val_loss =  13.3705\n",
      "epoch: 11640, train_loss =  13.3057, val_loss =  13.3580\n",
      "epoch: 11650, train_loss =  13.2932, val_loss =  13.3455\n",
      "epoch: 11660, train_loss =  13.2807, val_loss =  13.3330\n",
      "epoch: 11670, train_loss =  13.2682, val_loss =  13.3205\n",
      "epoch: 11680, train_loss =  13.2557, val_loss =  13.3080\n",
      "epoch: 11690, train_loss =  13.2432, val_loss =  13.2955\n",
      "epoch: 11700, train_loss =  13.2307, val_loss =  13.2830\n",
      "epoch: 11710, train_loss =  13.2183, val_loss =  13.2704\n",
      "epoch: 11720, train_loss =  13.2058, val_loss =  13.2579\n",
      "epoch: 11730, train_loss =  13.1933, val_loss =  13.2454\n",
      "epoch: 11740, train_loss =  13.1808, val_loss =  13.2329\n",
      "epoch: 11750, train_loss =  13.1683, val_loss =  13.2204\n",
      "epoch: 11760, train_loss =  13.1558, val_loss =  13.2079\n",
      "epoch: 11770, train_loss =  13.1434, val_loss =  13.1954\n",
      "epoch: 11780, train_loss =  13.1309, val_loss =  13.1829\n",
      "epoch: 11790, train_loss =  13.1184, val_loss =  13.1704\n",
      "epoch: 11800, train_loss =  13.1059, val_loss =  13.1579\n",
      "epoch: 11810, train_loss =  13.0934, val_loss =  13.1454\n",
      "epoch: 11820, train_loss =  13.0809, val_loss =  13.1329\n",
      "epoch: 11830, train_loss =  13.0685, val_loss =  13.1204\n",
      "epoch: 11840, train_loss =  13.0560, val_loss =  13.1079\n",
      "epoch: 11850, train_loss =  13.0435, val_loss =  13.0954\n",
      "epoch: 11860, train_loss =  13.0310, val_loss =  13.0828\n",
      "epoch: 11870, train_loss =  13.0185, val_loss =  13.0703\n",
      "epoch: 11880, train_loss =  13.0060, val_loss =  13.0578\n",
      "epoch: 11890, train_loss =  12.9936, val_loss =  13.0453\n",
      "epoch: 11900, train_loss =  12.9811, val_loss =  13.0328\n",
      "epoch: 11910, train_loss =  12.9686, val_loss =  13.0203\n",
      "epoch: 11920, train_loss =  12.9561, val_loss =  13.0078\n",
      "epoch: 11930, train_loss =  12.9436, val_loss =  12.9953\n",
      "epoch: 11940, train_loss =  12.9311, val_loss =  12.9828\n",
      "epoch: 11950, train_loss =  12.9186, val_loss =  12.9703\n",
      "epoch: 11960, train_loss =  12.9062, val_loss =  12.9578\n",
      "epoch: 11970, train_loss =  12.8937, val_loss =  12.9453\n",
      "epoch: 11980, train_loss =  12.8812, val_loss =  12.9328\n",
      "epoch: 11990, train_loss =  12.8687, val_loss =  12.9203\n",
      "epoch: 12000, train_loss =  12.8562, val_loss =  12.9077\n",
      "epoch: 12010, train_loss =  12.8437, val_loss =  12.8952\n",
      "epoch: 12020, train_loss =  12.8313, val_loss =  12.8827\n",
      "epoch: 12030, train_loss =  12.8188, val_loss =  12.8702\n",
      "epoch: 12040, train_loss =  12.8063, val_loss =  12.8577\n",
      "epoch: 12050, train_loss =  12.7938, val_loss =  12.8452\n",
      "epoch: 12060, train_loss =  12.7813, val_loss =  12.8327\n",
      "epoch: 12070, train_loss =  12.7688, val_loss =  12.8202\n",
      "epoch: 12080, train_loss =  12.7564, val_loss =  12.8077\n",
      "epoch: 12090, train_loss =  12.7439, val_loss =  12.7952\n",
      "epoch: 12100, train_loss =  12.7314, val_loss =  12.7827\n",
      "epoch: 12110, train_loss =  12.7189, val_loss =  12.7702\n",
      "epoch: 12120, train_loss =  12.7064, val_loss =  12.7577\n",
      "epoch: 12130, train_loss =  12.6939, val_loss =  12.7452\n",
      "epoch: 12140, train_loss =  12.6815, val_loss =  12.7326\n",
      "epoch: 12150, train_loss =  12.6690, val_loss =  12.7201\n",
      "epoch: 12160, train_loss =  12.6565, val_loss =  12.7076\n",
      "epoch: 12170, train_loss =  12.6440, val_loss =  12.6951\n",
      "epoch: 12180, train_loss =  12.6315, val_loss =  12.6826\n",
      "epoch: 12190, train_loss =  12.6190, val_loss =  12.6701\n",
      "epoch: 12200, train_loss =  12.6066, val_loss =  12.6576\n",
      "epoch: 12210, train_loss =  12.5941, val_loss =  12.6451\n",
      "epoch: 12220, train_loss =  12.5816, val_loss =  12.6326\n",
      "epoch: 12230, train_loss =  12.5691, val_loss =  12.6201\n",
      "epoch: 12240, train_loss =  12.5566, val_loss =  12.6076\n",
      "epoch: 12250, train_loss =  12.5441, val_loss =  12.5951\n",
      "epoch: 12260, train_loss =  12.5317, val_loss =  12.5826\n",
      "epoch: 12270, train_loss =  12.5192, val_loss =  12.5701\n",
      "epoch: 12280, train_loss =  12.5067, val_loss =  12.5575\n",
      "epoch: 12290, train_loss =  12.4942, val_loss =  12.5450\n",
      "epoch: 12300, train_loss =  12.4817, val_loss =  12.5325\n",
      "epoch: 12310, train_loss =  12.4692, val_loss =  12.5200\n",
      "epoch: 12320, train_loss =  12.4567, val_loss =  12.5075\n",
      "epoch: 12330, train_loss =  12.4443, val_loss =  12.4950\n",
      "epoch: 12340, train_loss =  12.4318, val_loss =  12.4825\n",
      "epoch: 12350, train_loss =  12.4193, val_loss =  12.4700\n",
      "epoch: 12360, train_loss =  12.4068, val_loss =  12.4575\n",
      "epoch: 12370, train_loss =  12.3943, val_loss =  12.4450\n",
      "epoch: 12380, train_loss =  12.3818, val_loss =  12.4325\n",
      "epoch: 12390, train_loss =  12.3694, val_loss =  12.4200\n",
      "epoch: 12400, train_loss =  12.3569, val_loss =  12.4075\n",
      "epoch: 12410, train_loss =  12.3444, val_loss =  12.3949\n",
      "epoch: 12420, train_loss =  12.3319, val_loss =  12.3824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12430, train_loss =  12.3194, val_loss =  12.3699\n",
      "epoch: 12440, train_loss =  12.3069, val_loss =  12.3574\n",
      "epoch: 12450, train_loss =  12.2945, val_loss =  12.3449\n",
      "epoch: 12460, train_loss =  12.2820, val_loss =  12.3324\n",
      "epoch: 12470, train_loss =  12.2695, val_loss =  12.3199\n",
      "epoch: 12480, train_loss =  12.2570, val_loss =  12.3074\n",
      "epoch: 12490, train_loss =  12.2445, val_loss =  12.2949\n",
      "epoch: 12500, train_loss =  12.2320, val_loss =  12.2824\n",
      "epoch: 12510, train_loss =  12.2196, val_loss =  12.2699\n",
      "epoch: 12520, train_loss =  12.2071, val_loss =  12.2574\n",
      "epoch: 12530, train_loss =  12.1946, val_loss =  12.2449\n",
      "epoch: 12540, train_loss =  12.1821, val_loss =  12.2323\n",
      "epoch: 12550, train_loss =  12.1696, val_loss =  12.2198\n",
      "epoch: 12560, train_loss =  12.1571, val_loss =  12.2073\n",
      "epoch: 12570, train_loss =  12.1447, val_loss =  12.1948\n",
      "epoch: 12580, train_loss =  12.1322, val_loss =  12.1823\n",
      "epoch: 12590, train_loss =  12.1197, val_loss =  12.1698\n",
      "epoch: 12600, train_loss =  12.1072, val_loss =  12.1573\n",
      "epoch: 12610, train_loss =  12.0947, val_loss =  12.1448\n",
      "epoch: 12620, train_loss =  12.0822, val_loss =  12.1323\n",
      "epoch: 12630, train_loss =  12.0698, val_loss =  12.1198\n",
      "epoch: 12640, train_loss =  12.0573, val_loss =  12.1073\n",
      "epoch: 12650, train_loss =  12.0448, val_loss =  12.0948\n",
      "epoch: 12660, train_loss =  12.0323, val_loss =  12.0823\n",
      "epoch: 12670, train_loss =  12.0198, val_loss =  12.0697\n",
      "epoch: 12680, train_loss =  12.0073, val_loss =  12.0572\n",
      "epoch: 12690, train_loss =  11.9949, val_loss =  12.0447\n",
      "epoch: 12700, train_loss =  11.9824, val_loss =  12.0322\n",
      "epoch: 12710, train_loss =  11.9699, val_loss =  12.0197\n",
      "epoch: 12720, train_loss =  11.9574, val_loss =  12.0072\n",
      "epoch: 12730, train_loss =  11.9449, val_loss =  11.9947\n",
      "epoch: 12740, train_loss =  11.9324, val_loss =  11.9822\n",
      "epoch: 12750, train_loss =  11.9200, val_loss =  11.9697\n",
      "epoch: 12760, train_loss =  11.9075, val_loss =  11.9572\n",
      "epoch: 12770, train_loss =  11.8950, val_loss =  11.9447\n",
      "epoch: 12780, train_loss =  11.8825, val_loss =  11.9322\n",
      "epoch: 12790, train_loss =  11.8700, val_loss =  11.9196\n",
      "epoch: 12800, train_loss =  11.8575, val_loss =  11.9071\n",
      "epoch: 12810, train_loss =  11.8451, val_loss =  11.8946\n",
      "epoch: 12820, train_loss =  11.8326, val_loss =  11.8821\n",
      "epoch: 12830, train_loss =  11.8201, val_loss =  11.8696\n",
      "epoch: 12840, train_loss =  11.8076, val_loss =  11.8571\n",
      "epoch: 12850, train_loss =  11.7951, val_loss =  11.8446\n",
      "epoch: 12860, train_loss =  11.7826, val_loss =  11.8321\n",
      "epoch: 12870, train_loss =  11.7702, val_loss =  11.8196\n",
      "epoch: 12880, train_loss =  11.7577, val_loss =  11.8071\n",
      "epoch: 12890, train_loss =  11.7452, val_loss =  11.7946\n",
      "epoch: 12900, train_loss =  11.7327, val_loss =  11.7821\n",
      "epoch: 12910, train_loss =  11.7202, val_loss =  11.7696\n",
      "epoch: 12920, train_loss =  11.7077, val_loss =  11.7570\n",
      "epoch: 12930, train_loss =  11.6953, val_loss =  11.7445\n",
      "epoch: 12940, train_loss =  11.6828, val_loss =  11.7320\n",
      "epoch: 12950, train_loss =  11.6703, val_loss =  11.7195\n",
      "epoch: 12960, train_loss =  11.6578, val_loss =  11.7070\n",
      "epoch: 12970, train_loss =  11.6453, val_loss =  11.6945\n",
      "epoch: 12980, train_loss =  11.6328, val_loss =  11.6820\n",
      "epoch: 12990, train_loss =  11.6204, val_loss =  11.6695\n",
      "epoch: 13000, train_loss =  11.6079, val_loss =  11.6570\n",
      "epoch: 13010, train_loss =  11.5954, val_loss =  11.6445\n",
      "epoch: 13020, train_loss =  11.5829, val_loss =  11.6320\n",
      "epoch: 13030, train_loss =  11.5704, val_loss =  11.6194\n",
      "epoch: 13040, train_loss =  11.5580, val_loss =  11.6069\n",
      "epoch: 13050, train_loss =  11.5455, val_loss =  11.5944\n",
      "epoch: 13060, train_loss =  11.5330, val_loss =  11.5819\n",
      "epoch: 13070, train_loss =  11.5205, val_loss =  11.5694\n",
      "epoch: 13080, train_loss =  11.5080, val_loss =  11.5569\n",
      "epoch: 13090, train_loss =  11.4955, val_loss =  11.5444\n",
      "epoch: 13100, train_loss =  11.4831, val_loss =  11.5319\n",
      "epoch: 13110, train_loss =  11.4706, val_loss =  11.5194\n",
      "epoch: 13120, train_loss =  11.4581, val_loss =  11.5069\n",
      "epoch: 13130, train_loss =  11.4456, val_loss =  11.4944\n",
      "epoch: 13140, train_loss =  11.4331, val_loss =  11.4819\n",
      "epoch: 13150, train_loss =  11.4206, val_loss =  11.4693\n",
      "epoch: 13160, train_loss =  11.4082, val_loss =  11.4568\n",
      "epoch: 13170, train_loss =  11.3957, val_loss =  11.4443\n",
      "epoch: 13180, train_loss =  11.3832, val_loss =  11.4318\n",
      "epoch: 13190, train_loss =  11.3707, val_loss =  11.4193\n",
      "epoch: 13200, train_loss =  11.3582, val_loss =  11.4068\n",
      "epoch: 13210, train_loss =  11.3457, val_loss =  11.3943\n",
      "epoch: 13220, train_loss =  11.3332, val_loss =  11.3818\n",
      "epoch: 13230, train_loss =  11.3208, val_loss =  11.3693\n",
      "epoch: 13240, train_loss =  11.3083, val_loss =  11.3568\n",
      "epoch: 13250, train_loss =  11.2958, val_loss =  11.3442\n",
      "epoch: 13260, train_loss =  11.2833, val_loss =  11.3317\n",
      "epoch: 13270, train_loss =  11.2708, val_loss =  11.3192\n",
      "epoch: 13280, train_loss =  11.2583, val_loss =  11.3067\n",
      "epoch: 13290, train_loss =  11.2459, val_loss =  11.2942\n",
      "epoch: 13300, train_loss =  11.2334, val_loss =  11.2817\n",
      "epoch: 13310, train_loss =  11.2209, val_loss =  11.2692\n",
      "epoch: 13320, train_loss =  11.2084, val_loss =  11.2567\n",
      "epoch: 13330, train_loss =  11.1959, val_loss =  11.2442\n",
      "epoch: 13340, train_loss =  11.1834, val_loss =  11.2317\n",
      "epoch: 13350, train_loss =  11.1710, val_loss =  11.2191\n",
      "epoch: 13360, train_loss =  11.1585, val_loss =  11.2066\n",
      "epoch: 13370, train_loss =  11.1460, val_loss =  11.1941\n",
      "epoch: 13380, train_loss =  11.1335, val_loss =  11.1816\n",
      "epoch: 13390, train_loss =  11.1210, val_loss =  11.1691\n",
      "epoch: 13400, train_loss =  11.1085, val_loss =  11.1566\n",
      "epoch: 13410, train_loss =  11.0961, val_loss =  11.1441\n",
      "epoch: 13420, train_loss =  11.0836, val_loss =  11.1316\n",
      "epoch: 13430, train_loss =  11.0711, val_loss =  11.1191\n",
      "epoch: 13440, train_loss =  11.0586, val_loss =  11.1066\n",
      "epoch: 13450, train_loss =  11.0461, val_loss =  11.0940\n",
      "epoch: 13460, train_loss =  11.0336, val_loss =  11.0815\n",
      "epoch: 13470, train_loss =  11.0211, val_loss =  11.0690\n",
      "epoch: 13480, train_loss =  11.0087, val_loss =  11.0565\n",
      "epoch: 13490, train_loss =  10.9962, val_loss =  11.0440\n",
      "epoch: 13500, train_loss =  10.9837, val_loss =  11.0315\n",
      "epoch: 13510, train_loss =  10.9712, val_loss =  11.0190\n",
      "epoch: 13520, train_loss =  10.9587, val_loss =  11.0065\n",
      "epoch: 13530, train_loss =  10.9462, val_loss =  10.9940\n",
      "epoch: 13540, train_loss =  10.9338, val_loss =  10.9815\n",
      "epoch: 13550, train_loss =  10.9213, val_loss =  10.9689\n",
      "epoch: 13560, train_loss =  10.9088, val_loss =  10.9564\n",
      "epoch: 13570, train_loss =  10.8963, val_loss =  10.9439\n",
      "epoch: 13580, train_loss =  10.8838, val_loss =  10.9314\n",
      "epoch: 13590, train_loss =  10.8713, val_loss =  10.9189\n",
      "epoch: 13600, train_loss =  10.8589, val_loss =  10.9064\n",
      "epoch: 13610, train_loss =  10.8464, val_loss =  10.8939\n",
      "epoch: 13620, train_loss =  10.8339, val_loss =  10.8814\n",
      "epoch: 13630, train_loss =  10.8214, val_loss =  10.8689\n",
      "epoch: 13640, train_loss =  10.8089, val_loss =  10.8563\n",
      "epoch: 13650, train_loss =  10.7964, val_loss =  10.8438\n",
      "epoch: 13660, train_loss =  10.7840, val_loss =  10.8313\n",
      "epoch: 13670, train_loss =  10.7715, val_loss =  10.8188\n",
      "epoch: 13680, train_loss =  10.7590, val_loss =  10.8063\n",
      "epoch: 13690, train_loss =  10.7465, val_loss =  10.7938\n",
      "epoch: 13700, train_loss =  10.7340, val_loss =  10.7813\n",
      "epoch: 13710, train_loss =  10.7215, val_loss =  10.7688\n",
      "epoch: 13720, train_loss =  10.7091, val_loss =  10.7563\n",
      "epoch: 13730, train_loss =  10.6966, val_loss =  10.7438\n",
      "epoch: 13740, train_loss =  10.6841, val_loss =  10.7312\n",
      "epoch: 13750, train_loss =  10.6716, val_loss =  10.7187\n",
      "epoch: 13760, train_loss =  10.6591, val_loss =  10.7062\n",
      "epoch: 13770, train_loss =  10.6466, val_loss =  10.6937\n",
      "epoch: 13780, train_loss =  10.6342, val_loss =  10.6812\n",
      "epoch: 13790, train_loss =  10.6217, val_loss =  10.6687\n",
      "epoch: 13800, train_loss =  10.6092, val_loss =  10.6562\n",
      "epoch: 13810, train_loss =  10.5967, val_loss =  10.6437\n",
      "epoch: 13820, train_loss =  10.5842, val_loss =  10.6312\n",
      "epoch: 13830, train_loss =  10.5717, val_loss =  10.6186\n",
      "epoch: 13840, train_loss =  10.5593, val_loss =  10.6061\n",
      "epoch: 13850, train_loss =  10.5468, val_loss =  10.5936\n",
      "epoch: 13860, train_loss =  10.5343, val_loss =  10.5811\n",
      "epoch: 13870, train_loss =  10.5218, val_loss =  10.5686\n",
      "epoch: 13880, train_loss =  10.5093, val_loss =  10.5561\n",
      "epoch: 13890, train_loss =  10.4968, val_loss =  10.5436\n",
      "epoch: 13900, train_loss =  10.4844, val_loss =  10.5311\n",
      "epoch: 13910, train_loss =  10.4719, val_loss =  10.5186\n",
      "epoch: 13920, train_loss =  10.4594, val_loss =  10.5060\n",
      "epoch: 13930, train_loss =  10.4469, val_loss =  10.4935\n",
      "epoch: 13940, train_loss =  10.4344, val_loss =  10.4810\n",
      "epoch: 13950, train_loss =  10.4219, val_loss =  10.4685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13960, train_loss =  10.4094, val_loss =  10.4560\n",
      "epoch: 13970, train_loss =  10.3970, val_loss =  10.4435\n",
      "epoch: 13980, train_loss =  10.3845, val_loss =  10.4310\n",
      "epoch: 13990, train_loss =  10.3720, val_loss =  10.4185\n",
      "epoch: 14000, train_loss =  10.3595, val_loss =  10.4060\n",
      "epoch: 14010, train_loss =  10.3470, val_loss =  10.3935\n",
      "epoch: 14020, train_loss =  10.3345, val_loss =  10.3809\n",
      "epoch: 14030, train_loss =  10.3221, val_loss =  10.3684\n",
      "epoch: 14040, train_loss =  10.3096, val_loss =  10.3559\n",
      "epoch: 14050, train_loss =  10.2971, val_loss =  10.3434\n",
      "epoch: 14060, train_loss =  10.2846, val_loss =  10.3309\n",
      "epoch: 14070, train_loss =  10.2721, val_loss =  10.3184\n",
      "epoch: 14080, train_loss =  10.2596, val_loss =  10.3059\n",
      "epoch: 14090, train_loss =  10.2472, val_loss =  10.2934\n",
      "epoch: 14100, train_loss =  10.2347, val_loss =  10.2809\n",
      "epoch: 14110, train_loss =  10.2222, val_loss =  10.2683\n",
      "epoch: 14120, train_loss =  10.2097, val_loss =  10.2558\n",
      "epoch: 14130, train_loss =  10.1972, val_loss =  10.2433\n",
      "epoch: 14140, train_loss =  10.1847, val_loss =  10.2308\n",
      "epoch: 14150, train_loss =  10.1723, val_loss =  10.2183\n",
      "epoch: 14160, train_loss =  10.1598, val_loss =  10.2058\n",
      "epoch: 14170, train_loss =  10.1473, val_loss =  10.1933\n",
      "epoch: 14180, train_loss =  10.1348, val_loss =  10.1808\n",
      "epoch: 14190, train_loss =  10.1223, val_loss =  10.1683\n",
      "epoch: 14200, train_loss =  10.1098, val_loss =  10.1557\n",
      "epoch: 14210, train_loss =  10.0974, val_loss =  10.1432\n",
      "epoch: 14220, train_loss =  10.0849, val_loss =  10.1307\n",
      "epoch: 14230, train_loss =  10.0724, val_loss =  10.1182\n",
      "epoch: 14240, train_loss =  10.0599, val_loss =  10.1057\n",
      "epoch: 14250, train_loss =  10.0474, val_loss =  10.0932\n",
      "epoch: 14260, train_loss =  10.0349, val_loss =  10.0807\n",
      "epoch: 14270, train_loss =  10.0225, val_loss =  10.0682\n",
      "epoch: 14280, train_loss =  10.0100, val_loss =  10.0556\n",
      "epoch: 14290, train_loss =  9.9975, val_loss =  10.0431\n",
      "epoch: 14300, train_loss =  9.9850, val_loss =  10.0306\n",
      "epoch: 14310, train_loss =  9.9725, val_loss =  10.0181\n",
      "epoch: 14320, train_loss =  9.9600, val_loss =  10.0056\n",
      "epoch: 14330, train_loss =  9.9476, val_loss =  9.9931\n",
      "epoch: 14340, train_loss =  9.9351, val_loss =  9.9806\n",
      "epoch: 14350, train_loss =  9.9226, val_loss =  9.9681\n",
      "epoch: 14360, train_loss =  9.9101, val_loss =  9.9556\n",
      "epoch: 14370, train_loss =  9.8976, val_loss =  9.9430\n",
      "epoch: 14380, train_loss =  9.8852, val_loss =  9.9305\n",
      "epoch: 14390, train_loss =  9.8727, val_loss =  9.9180\n",
      "epoch: 14400, train_loss =  9.8602, val_loss =  9.9055\n",
      "epoch: 14410, train_loss =  9.8477, val_loss =  9.8930\n",
      "epoch: 14420, train_loss =  9.8352, val_loss =  9.8805\n",
      "epoch: 14430, train_loss =  9.8227, val_loss =  9.8680\n",
      "epoch: 14440, train_loss =  9.8103, val_loss =  9.8555\n",
      "epoch: 14450, train_loss =  9.7978, val_loss =  9.8430\n",
      "epoch: 14460, train_loss =  9.7853, val_loss =  9.8304\n",
      "epoch: 14470, train_loss =  9.7728, val_loss =  9.8179\n",
      "epoch: 14480, train_loss =  9.7603, val_loss =  9.8054\n",
      "epoch: 14490, train_loss =  9.7478, val_loss =  9.7929\n",
      "epoch: 14500, train_loss =  9.7354, val_loss =  9.7804\n",
      "epoch: 14510, train_loss =  9.7229, val_loss =  9.7679\n",
      "epoch: 14520, train_loss =  9.7104, val_loss =  9.7554\n",
      "epoch: 14530, train_loss =  9.6979, val_loss =  9.7429\n",
      "epoch: 14540, train_loss =  9.6854, val_loss =  9.7303\n",
      "epoch: 14550, train_loss =  9.6729, val_loss =  9.7178\n",
      "epoch: 14560, train_loss =  9.6605, val_loss =  9.7053\n",
      "epoch: 14570, train_loss =  9.6480, val_loss =  9.6928\n",
      "epoch: 14580, train_loss =  9.6355, val_loss =  9.6803\n",
      "epoch: 14590, train_loss =  9.6230, val_loss =  9.6678\n",
      "epoch: 14600, train_loss =  9.6105, val_loss =  9.6553\n",
      "epoch: 14610, train_loss =  9.5980, val_loss =  9.6428\n",
      "epoch: 14620, train_loss =  9.5856, val_loss =  9.6303\n",
      "epoch: 14630, train_loss =  9.5731, val_loss =  9.6177\n",
      "epoch: 14640, train_loss =  9.5606, val_loss =  9.6052\n",
      "epoch: 14650, train_loss =  9.5481, val_loss =  9.5927\n",
      "epoch: 14660, train_loss =  9.5356, val_loss =  9.5802\n",
      "epoch: 14670, train_loss =  9.5232, val_loss =  9.5677\n",
      "epoch: 14680, train_loss =  9.5107, val_loss =  9.5552\n",
      "epoch: 14690, train_loss =  9.4982, val_loss =  9.5427\n",
      "epoch: 14700, train_loss =  9.4857, val_loss =  9.5302\n",
      "epoch: 14710, train_loss =  9.4732, val_loss =  9.5177\n",
      "epoch: 14720, train_loss =  9.4607, val_loss =  9.5052\n",
      "epoch: 14730, train_loss =  9.4483, val_loss =  9.4926\n",
      "epoch: 14740, train_loss =  9.4358, val_loss =  9.4801\n",
      "epoch: 14750, train_loss =  9.4233, val_loss =  9.4676\n",
      "epoch: 14760, train_loss =  9.4108, val_loss =  9.4551\n",
      "epoch: 14770, train_loss =  9.3983, val_loss =  9.4426\n",
      "epoch: 14780, train_loss =  9.3859, val_loss =  9.4301\n",
      "epoch: 14790, train_loss =  9.3734, val_loss =  9.4176\n",
      "epoch: 14800, train_loss =  9.3609, val_loss =  9.4051\n",
      "epoch: 14810, train_loss =  9.3484, val_loss =  9.3926\n",
      "epoch: 14820, train_loss =  9.3359, val_loss =  9.3801\n",
      "epoch: 14830, train_loss =  9.3235, val_loss =  9.3675\n",
      "epoch: 14840, train_loss =  9.3110, val_loss =  9.3550\n",
      "epoch: 14850, train_loss =  9.2985, val_loss =  9.3425\n",
      "epoch: 14860, train_loss =  9.2860, val_loss =  9.3300\n",
      "epoch: 14870, train_loss =  9.2735, val_loss =  9.3175\n",
      "epoch: 14880, train_loss =  9.2611, val_loss =  9.3050\n",
      "epoch: 14890, train_loss =  9.2486, val_loss =  9.2925\n",
      "epoch: 14900, train_loss =  9.2361, val_loss =  9.2800\n",
      "epoch: 14910, train_loss =  9.2236, val_loss =  9.2675\n",
      "epoch: 14920, train_loss =  9.2111, val_loss =  9.2550\n",
      "epoch: 14930, train_loss =  9.1987, val_loss =  9.2424\n",
      "epoch: 14940, train_loss =  9.1862, val_loss =  9.2299\n",
      "epoch: 14950, train_loss =  9.1737, val_loss =  9.2174\n",
      "epoch: 14960, train_loss =  9.1612, val_loss =  9.2049\n",
      "epoch: 14970, train_loss =  9.1487, val_loss =  9.1924\n",
      "epoch: 14980, train_loss =  9.1363, val_loss =  9.1799\n",
      "epoch: 14990, train_loss =  9.1238, val_loss =  9.1674\n",
      "epoch: 15000, train_loss =  9.1113, val_loss =  9.1549\n",
      "epoch: 15010, train_loss =  9.0988, val_loss =  9.1424\n",
      "epoch: 15020, train_loss =  9.0863, val_loss =  9.1299\n",
      "epoch: 15030, train_loss =  9.0739, val_loss =  9.1174\n",
      "epoch: 15040, train_loss =  9.0614, val_loss =  9.1048\n",
      "epoch: 15050, train_loss =  9.0489, val_loss =  9.0923\n",
      "epoch: 15060, train_loss =  9.0364, val_loss =  9.0798\n",
      "epoch: 15070, train_loss =  9.0239, val_loss =  9.0673\n",
      "epoch: 15080, train_loss =  9.0115, val_loss =  9.0548\n",
      "epoch: 15090, train_loss =  8.9990, val_loss =  9.0423\n",
      "epoch: 15100, train_loss =  8.9865, val_loss =  9.0298\n",
      "epoch: 15110, train_loss =  8.9740, val_loss =  9.0173\n",
      "epoch: 15120, train_loss =  8.9615, val_loss =  9.0048\n",
      "epoch: 15130, train_loss =  8.9491, val_loss =  8.9922\n",
      "epoch: 15140, train_loss =  8.9366, val_loss =  8.9797\n",
      "epoch: 15150, train_loss =  8.9241, val_loss =  8.9672\n",
      "epoch: 15160, train_loss =  8.9116, val_loss =  8.9547\n",
      "epoch: 15170, train_loss =  8.8991, val_loss =  8.9422\n",
      "epoch: 15180, train_loss =  8.8867, val_loss =  8.9297\n",
      "epoch: 15190, train_loss =  8.8742, val_loss =  8.9172\n",
      "epoch: 15200, train_loss =  8.8617, val_loss =  8.9047\n",
      "epoch: 15210, train_loss =  8.8492, val_loss =  8.8922\n",
      "epoch: 15220, train_loss =  8.8367, val_loss =  8.8797\n",
      "epoch: 15230, train_loss =  8.8243, val_loss =  8.8671\n",
      "epoch: 15240, train_loss =  8.8118, val_loss =  8.8546\n",
      "epoch: 15250, train_loss =  8.7993, val_loss =  8.8421\n",
      "epoch: 15260, train_loss =  8.7868, val_loss =  8.8296\n",
      "epoch: 15270, train_loss =  8.7743, val_loss =  8.8171\n",
      "epoch: 15280, train_loss =  8.7619, val_loss =  8.8046\n",
      "epoch: 15290, train_loss =  8.7494, val_loss =  8.7921\n",
      "epoch: 15300, train_loss =  8.7369, val_loss =  8.7796\n",
      "epoch: 15310, train_loss =  8.7244, val_loss =  8.7671\n",
      "epoch: 15320, train_loss =  8.7119, val_loss =  8.7546\n",
      "epoch: 15330, train_loss =  8.6995, val_loss =  8.7420\n",
      "epoch: 15340, train_loss =  8.6870, val_loss =  8.7295\n",
      "epoch: 15350, train_loss =  8.6745, val_loss =  8.7170\n",
      "epoch: 15360, train_loss =  8.6620, val_loss =  8.7045\n",
      "epoch: 15370, train_loss =  8.6495, val_loss =  8.6920\n",
      "epoch: 15380, train_loss =  8.6371, val_loss =  8.6795\n",
      "epoch: 15390, train_loss =  8.6246, val_loss =  8.6670\n",
      "epoch: 15400, train_loss =  8.6121, val_loss =  8.6545\n",
      "epoch: 15410, train_loss =  8.5996, val_loss =  8.6420\n",
      "epoch: 15420, train_loss =  8.5871, val_loss =  8.6295\n",
      "epoch: 15430, train_loss =  8.5747, val_loss =  8.6169\n",
      "epoch: 15440, train_loss =  8.5622, val_loss =  8.6044\n",
      "epoch: 15450, train_loss =  8.5497, val_loss =  8.5919\n",
      "epoch: 15460, train_loss =  8.5372, val_loss =  8.5794\n",
      "epoch: 15470, train_loss =  8.5247, val_loss =  8.5669\n",
      "epoch: 15480, train_loss =  8.5123, val_loss =  8.5544\n",
      "epoch: 15490, train_loss =  8.4998, val_loss =  8.5419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15500, train_loss =  8.4873, val_loss =  8.5294\n",
      "epoch: 15510, train_loss =  8.4748, val_loss =  8.5169\n",
      "epoch: 15520, train_loss =  8.4623, val_loss =  8.5043\n",
      "epoch: 15530, train_loss =  8.4499, val_loss =  8.4918\n",
      "epoch: 15540, train_loss =  8.4374, val_loss =  8.4793\n",
      "epoch: 15550, train_loss =  8.4249, val_loss =  8.4668\n",
      "epoch: 15560, train_loss =  8.4124, val_loss =  8.4543\n",
      "epoch: 15570, train_loss =  8.4000, val_loss =  8.4418\n",
      "epoch: 15580, train_loss =  8.3875, val_loss =  8.4293\n",
      "epoch: 15590, train_loss =  8.3750, val_loss =  8.4168\n",
      "epoch: 15600, train_loss =  8.3625, val_loss =  8.4043\n",
      "epoch: 15610, train_loss =  8.3500, val_loss =  8.3918\n",
      "epoch: 15620, train_loss =  8.3376, val_loss =  8.3792\n",
      "epoch: 15630, train_loss =  8.3251, val_loss =  8.3667\n",
      "epoch: 15640, train_loss =  8.3126, val_loss =  8.3542\n",
      "epoch: 15650, train_loss =  8.3001, val_loss =  8.3417\n",
      "epoch: 15660, train_loss =  8.2876, val_loss =  8.3292\n",
      "epoch: 15670, train_loss =  8.2752, val_loss =  8.3167\n",
      "epoch: 15680, train_loss =  8.2627, val_loss =  8.3042\n",
      "epoch: 15690, train_loss =  8.2502, val_loss =  8.2917\n",
      "epoch: 15700, train_loss =  8.2377, val_loss =  8.2792\n",
      "epoch: 15710, train_loss =  8.2252, val_loss =  8.2666\n",
      "epoch: 15720, train_loss =  8.2128, val_loss =  8.2541\n",
      "epoch: 15730, train_loss =  8.2003, val_loss =  8.2416\n",
      "epoch: 15740, train_loss =  8.1878, val_loss =  8.2291\n",
      "epoch: 15750, train_loss =  8.1753, val_loss =  8.2166\n",
      "epoch: 15760, train_loss =  8.1628, val_loss =  8.2041\n",
      "epoch: 15770, train_loss =  8.1504, val_loss =  8.1916\n",
      "epoch: 15780, train_loss =  8.1379, val_loss =  8.1791\n",
      "epoch: 15790, train_loss =  8.1254, val_loss =  8.1666\n",
      "epoch: 15800, train_loss =  8.1129, val_loss =  8.1540\n",
      "epoch: 15810, train_loss =  8.1004, val_loss =  8.1415\n",
      "epoch: 15820, train_loss =  8.0880, val_loss =  8.1290\n",
      "epoch: 15830, train_loss =  8.0755, val_loss =  8.1165\n",
      "epoch: 15840, train_loss =  8.0630, val_loss =  8.1040\n",
      "epoch: 15850, train_loss =  8.0505, val_loss =  8.0915\n",
      "epoch: 15860, train_loss =  8.0381, val_loss =  8.0790\n",
      "epoch: 15870, train_loss =  8.0256, val_loss =  8.0665\n",
      "epoch: 15880, train_loss =  8.0131, val_loss =  8.0540\n",
      "epoch: 15890, train_loss =  8.0006, val_loss =  8.0414\n",
      "epoch: 15900, train_loss =  7.9881, val_loss =  8.0289\n",
      "epoch: 15910, train_loss =  7.9757, val_loss =  8.0164\n",
      "epoch: 15920, train_loss =  7.9632, val_loss =  8.0039\n",
      "epoch: 15930, train_loss =  7.9507, val_loss =  7.9914\n",
      "epoch: 15940, train_loss =  7.9382, val_loss =  7.9789\n",
      "epoch: 15950, train_loss =  7.9257, val_loss =  7.9664\n",
      "epoch: 15960, train_loss =  7.9133, val_loss =  7.9539\n",
      "epoch: 15970, train_loss =  7.9008, val_loss =  7.9414\n",
      "epoch: 15980, train_loss =  7.8883, val_loss =  7.9288\n",
      "epoch: 15990, train_loss =  7.8758, val_loss =  7.9163\n",
      "epoch: 16000, train_loss =  7.8633, val_loss =  7.9038\n",
      "epoch: 16010, train_loss =  7.8509, val_loss =  7.8913\n",
      "epoch: 16020, train_loss =  7.8384, val_loss =  7.8788\n",
      "epoch: 16030, train_loss =  7.8259, val_loss =  7.8663\n",
      "epoch: 16040, train_loss =  7.8134, val_loss =  7.8538\n",
      "epoch: 16050, train_loss =  7.8010, val_loss =  7.8413\n",
      "epoch: 16060, train_loss =  7.7885, val_loss =  7.8288\n",
      "epoch: 16070, train_loss =  7.7760, val_loss =  7.8162\n",
      "epoch: 16080, train_loss =  7.7635, val_loss =  7.8037\n",
      "epoch: 16090, train_loss =  7.7510, val_loss =  7.7912\n",
      "epoch: 16100, train_loss =  7.7386, val_loss =  7.7787\n",
      "epoch: 16110, train_loss =  7.7261, val_loss =  7.7662\n",
      "epoch: 16120, train_loss =  7.7136, val_loss =  7.7537\n",
      "epoch: 16130, train_loss =  7.7011, val_loss =  7.7412\n",
      "epoch: 16140, train_loss =  7.6886, val_loss =  7.7287\n",
      "epoch: 16150, train_loss =  7.6762, val_loss =  7.7162\n",
      "epoch: 16160, train_loss =  7.6637, val_loss =  7.7036\n",
      "epoch: 16170, train_loss =  7.6512, val_loss =  7.6911\n",
      "epoch: 16180, train_loss =  7.6387, val_loss =  7.6786\n",
      "epoch: 16190, train_loss =  7.6263, val_loss =  7.6661\n",
      "epoch: 16200, train_loss =  7.6138, val_loss =  7.6536\n",
      "epoch: 16210, train_loss =  7.6013, val_loss =  7.6411\n",
      "epoch: 16220, train_loss =  7.5888, val_loss =  7.6286\n",
      "epoch: 16230, train_loss =  7.5763, val_loss =  7.6161\n",
      "epoch: 16240, train_loss =  7.5639, val_loss =  7.6036\n",
      "epoch: 16250, train_loss =  7.5514, val_loss =  7.5910\n",
      "epoch: 16260, train_loss =  7.5389, val_loss =  7.5785\n",
      "epoch: 16270, train_loss =  7.5264, val_loss =  7.5660\n",
      "epoch: 16280, train_loss =  7.5139, val_loss =  7.5535\n",
      "epoch: 16290, train_loss =  7.5015, val_loss =  7.5410\n",
      "epoch: 16300, train_loss =  7.4890, val_loss =  7.5285\n",
      "epoch: 16310, train_loss =  7.4765, val_loss =  7.5160\n",
      "epoch: 16320, train_loss =  7.4640, val_loss =  7.5035\n",
      "epoch: 16330, train_loss =  7.4516, val_loss =  7.4910\n",
      "epoch: 16340, train_loss =  7.4391, val_loss =  7.4784\n",
      "epoch: 16350, train_loss =  7.4266, val_loss =  7.4659\n",
      "epoch: 16360, train_loss =  7.4141, val_loss =  7.4534\n",
      "epoch: 16370, train_loss =  7.4016, val_loss =  7.4409\n",
      "epoch: 16380, train_loss =  7.3892, val_loss =  7.4284\n",
      "epoch: 16390, train_loss =  7.3767, val_loss =  7.4159\n",
      "epoch: 16400, train_loss =  7.3642, val_loss =  7.4034\n",
      "epoch: 16410, train_loss =  7.3517, val_loss =  7.3909\n",
      "epoch: 16420, train_loss =  7.3392, val_loss =  7.3784\n",
      "epoch: 16430, train_loss =  7.3268, val_loss =  7.3658\n",
      "epoch: 16440, train_loss =  7.3143, val_loss =  7.3533\n",
      "epoch: 16450, train_loss =  7.3018, val_loss =  7.3408\n",
      "epoch: 16460, train_loss =  7.2893, val_loss =  7.3283\n",
      "epoch: 16470, train_loss =  7.2769, val_loss =  7.3158\n",
      "epoch: 16480, train_loss =  7.2644, val_loss =  7.3033\n",
      "epoch: 16490, train_loss =  7.2519, val_loss =  7.2908\n",
      "epoch: 16500, train_loss =  7.2394, val_loss =  7.2783\n",
      "epoch: 16510, train_loss =  7.2269, val_loss =  7.2657\n",
      "epoch: 16520, train_loss =  7.2145, val_loss =  7.2532\n",
      "epoch: 16530, train_loss =  7.2020, val_loss =  7.2407\n",
      "epoch: 16540, train_loss =  7.1895, val_loss =  7.2282\n",
      "epoch: 16550, train_loss =  7.1770, val_loss =  7.2157\n",
      "epoch: 16560, train_loss =  7.1646, val_loss =  7.2032\n",
      "epoch: 16570, train_loss =  7.1521, val_loss =  7.1907\n",
      "epoch: 16580, train_loss =  7.1396, val_loss =  7.1782\n",
      "epoch: 16590, train_loss =  7.1271, val_loss =  7.1657\n",
      "epoch: 16600, train_loss =  7.1146, val_loss =  7.1531\n",
      "epoch: 16610, train_loss =  7.1022, val_loss =  7.1406\n",
      "epoch: 16620, train_loss =  7.0897, val_loss =  7.1281\n",
      "epoch: 16630, train_loss =  7.0772, val_loss =  7.1156\n",
      "epoch: 16640, train_loss =  7.0647, val_loss =  7.1031\n",
      "epoch: 16650, train_loss =  7.0523, val_loss =  7.0906\n",
      "epoch: 16660, train_loss =  7.0398, val_loss =  7.0781\n",
      "epoch: 16670, train_loss =  7.0273, val_loss =  7.0656\n",
      "epoch: 16680, train_loss =  7.0148, val_loss =  7.0531\n",
      "epoch: 16690, train_loss =  7.0023, val_loss =  7.0405\n",
      "epoch: 16700, train_loss =  6.9899, val_loss =  7.0280\n",
      "epoch: 16710, train_loss =  6.9774, val_loss =  7.0155\n",
      "epoch: 16720, train_loss =  6.9649, val_loss =  7.0030\n",
      "epoch: 16730, train_loss =  6.9524, val_loss =  6.9905\n",
      "epoch: 16740, train_loss =  6.9400, val_loss =  6.9780\n",
      "epoch: 16750, train_loss =  6.9275, val_loss =  6.9655\n",
      "epoch: 16760, train_loss =  6.9150, val_loss =  6.9530\n",
      "epoch: 16770, train_loss =  6.9025, val_loss =  6.9404\n",
      "epoch: 16780, train_loss =  6.8900, val_loss =  6.9279\n",
      "epoch: 16790, train_loss =  6.8776, val_loss =  6.9154\n",
      "epoch: 16800, train_loss =  6.8651, val_loss =  6.9029\n",
      "epoch: 16810, train_loss =  6.8526, val_loss =  6.8904\n",
      "epoch: 16820, train_loss =  6.8401, val_loss =  6.8779\n",
      "epoch: 16830, train_loss =  6.8277, val_loss =  6.8654\n",
      "epoch: 16840, train_loss =  6.8152, val_loss =  6.8529\n",
      "epoch: 16850, train_loss =  6.8027, val_loss =  6.8404\n",
      "epoch: 16860, train_loss =  6.7902, val_loss =  6.8278\n",
      "epoch: 16870, train_loss =  6.7778, val_loss =  6.8153\n",
      "epoch: 16880, train_loss =  6.7653, val_loss =  6.8028\n",
      "epoch: 16890, train_loss =  6.7528, val_loss =  6.7903\n",
      "epoch: 16900, train_loss =  6.7403, val_loss =  6.7778\n",
      "epoch: 16910, train_loss =  6.7278, val_loss =  6.7653\n",
      "epoch: 16920, train_loss =  6.7154, val_loss =  6.7528\n",
      "epoch: 16930, train_loss =  6.7029, val_loss =  6.7403\n",
      "epoch: 16940, train_loss =  6.6904, val_loss =  6.7278\n",
      "epoch: 16950, train_loss =  6.6779, val_loss =  6.7152\n",
      "epoch: 16960, train_loss =  6.6655, val_loss =  6.7027\n",
      "epoch: 16970, train_loss =  6.6530, val_loss =  6.6902\n",
      "epoch: 16980, train_loss =  6.6405, val_loss =  6.6777\n",
      "epoch: 16990, train_loss =  6.6280, val_loss =  6.6652\n",
      "epoch: 17000, train_loss =  6.6156, val_loss =  6.6527\n",
      "epoch: 17010, train_loss =  6.6031, val_loss =  6.6402\n",
      "epoch: 17020, train_loss =  6.5906, val_loss =  6.6277\n",
      "epoch: 17030, train_loss =  6.5781, val_loss =  6.6151\n",
      "epoch: 17040, train_loss =  6.5656, val_loss =  6.6026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17050, train_loss =  6.5532, val_loss =  6.5901\n",
      "epoch: 17060, train_loss =  6.5407, val_loss =  6.5776\n",
      "epoch: 17070, train_loss =  6.5282, val_loss =  6.5651\n",
      "epoch: 17080, train_loss =  6.5157, val_loss =  6.5526\n",
      "epoch: 17090, train_loss =  6.5033, val_loss =  6.5401\n",
      "epoch: 17100, train_loss =  6.4908, val_loss =  6.5276\n",
      "epoch: 17110, train_loss =  6.4783, val_loss =  6.5151\n",
      "epoch: 17120, train_loss =  6.4658, val_loss =  6.5025\n",
      "epoch: 17130, train_loss =  6.4534, val_loss =  6.4900\n",
      "epoch: 17140, train_loss =  6.4409, val_loss =  6.4775\n",
      "epoch: 17150, train_loss =  6.4284, val_loss =  6.4650\n",
      "epoch: 17160, train_loss =  6.4159, val_loss =  6.4525\n",
      "epoch: 17170, train_loss =  6.4034, val_loss =  6.4400\n",
      "epoch: 17180, train_loss =  6.3910, val_loss =  6.4275\n",
      "epoch: 17190, train_loss =  6.3785, val_loss =  6.4150\n",
      "epoch: 17200, train_loss =  6.3660, val_loss =  6.4024\n",
      "epoch: 17210, train_loss =  6.3535, val_loss =  6.3899\n",
      "epoch: 17220, train_loss =  6.3411, val_loss =  6.3774\n",
      "epoch: 17230, train_loss =  6.3286, val_loss =  6.3649\n",
      "epoch: 17240, train_loss =  6.3161, val_loss =  6.3524\n",
      "epoch: 17250, train_loss =  6.3036, val_loss =  6.3399\n",
      "epoch: 17260, train_loss =  6.2912, val_loss =  6.3274\n",
      "epoch: 17270, train_loss =  6.2787, val_loss =  6.3149\n",
      "epoch: 17280, train_loss =  6.2662, val_loss =  6.3024\n",
      "epoch: 17290, train_loss =  6.2537, val_loss =  6.2898\n",
      "epoch: 17300, train_loss =  6.2413, val_loss =  6.2773\n",
      "epoch: 17310, train_loss =  6.2288, val_loss =  6.2648\n",
      "epoch: 17320, train_loss =  6.2163, val_loss =  6.2523\n",
      "epoch: 17330, train_loss =  6.2038, val_loss =  6.2398\n",
      "epoch: 17340, train_loss =  6.1914, val_loss =  6.2273\n",
      "epoch: 17350, train_loss =  6.1789, val_loss =  6.2148\n",
      "epoch: 17360, train_loss =  6.1664, val_loss =  6.2023\n",
      "epoch: 17370, train_loss =  6.1539, val_loss =  6.1897\n",
      "epoch: 17380, train_loss =  6.1414, val_loss =  6.1772\n",
      "epoch: 17390, train_loss =  6.1290, val_loss =  6.1647\n",
      "epoch: 17400, train_loss =  6.1165, val_loss =  6.1522\n",
      "epoch: 17410, train_loss =  6.1040, val_loss =  6.1397\n",
      "epoch: 17420, train_loss =  6.0915, val_loss =  6.1272\n",
      "epoch: 17430, train_loss =  6.0791, val_loss =  6.1147\n",
      "epoch: 17440, train_loss =  6.0666, val_loss =  6.1022\n",
      "epoch: 17450, train_loss =  6.0541, val_loss =  6.0896\n",
      "epoch: 17460, train_loss =  6.0416, val_loss =  6.0771\n",
      "epoch: 17470, train_loss =  6.0292, val_loss =  6.0646\n",
      "epoch: 17480, train_loss =  6.0167, val_loss =  6.0521\n",
      "epoch: 17490, train_loss =  6.0042, val_loss =  6.0396\n",
      "epoch: 17500, train_loss =  5.9917, val_loss =  6.0271\n",
      "epoch: 17510, train_loss =  5.9793, val_loss =  6.0146\n",
      "epoch: 17520, train_loss =  5.9668, val_loss =  6.0021\n",
      "epoch: 17530, train_loss =  5.9543, val_loss =  5.9896\n",
      "epoch: 17540, train_loss =  5.9418, val_loss =  5.9770\n",
      "epoch: 17550, train_loss =  5.9294, val_loss =  5.9645\n",
      "epoch: 17560, train_loss =  5.9169, val_loss =  5.9520\n",
      "epoch: 17570, train_loss =  5.9044, val_loss =  5.9395\n",
      "epoch: 17580, train_loss =  5.8919, val_loss =  5.9270\n",
      "epoch: 17590, train_loss =  5.8795, val_loss =  5.9145\n",
      "epoch: 17600, train_loss =  5.8670, val_loss =  5.9020\n",
      "epoch: 17610, train_loss =  5.8545, val_loss =  5.8895\n",
      "epoch: 17620, train_loss =  5.8420, val_loss =  5.8769\n",
      "epoch: 17630, train_loss =  5.8296, val_loss =  5.8644\n",
      "epoch: 17640, train_loss =  5.8171, val_loss =  5.8519\n",
      "epoch: 17650, train_loss =  5.8046, val_loss =  5.8394\n",
      "epoch: 17660, train_loss =  5.7921, val_loss =  5.8269\n",
      "epoch: 17670, train_loss =  5.7797, val_loss =  5.8144\n",
      "epoch: 17680, train_loss =  5.7672, val_loss =  5.8019\n",
      "epoch: 17690, train_loss =  5.7547, val_loss =  5.7894\n",
      "epoch: 17700, train_loss =  5.7422, val_loss =  5.7769\n",
      "epoch: 17710, train_loss =  5.7298, val_loss =  5.7643\n",
      "epoch: 17720, train_loss =  5.7173, val_loss =  5.7518\n",
      "epoch: 17730, train_loss =  5.7048, val_loss =  5.7393\n",
      "epoch: 17740, train_loss =  5.6923, val_loss =  5.7268\n",
      "epoch: 17750, train_loss =  5.6799, val_loss =  5.7143\n",
      "epoch: 17760, train_loss =  5.6674, val_loss =  5.7018\n",
      "epoch: 17770, train_loss =  5.6549, val_loss =  5.6893\n",
      "epoch: 17780, train_loss =  5.6425, val_loss =  5.6768\n",
      "epoch: 17790, train_loss =  5.6300, val_loss =  5.6643\n",
      "epoch: 17800, train_loss =  5.6175, val_loss =  5.6518\n",
      "epoch: 17810, train_loss =  5.6050, val_loss =  5.6393\n",
      "epoch: 17820, train_loss =  5.5926, val_loss =  5.6267\n",
      "epoch: 17830, train_loss =  5.5801, val_loss =  5.6142\n",
      "epoch: 17840, train_loss =  5.5676, val_loss =  5.6017\n",
      "epoch: 17850, train_loss =  5.5552, val_loss =  5.5892\n",
      "epoch: 17860, train_loss =  5.5427, val_loss =  5.5767\n",
      "epoch: 17870, train_loss =  5.5302, val_loss =  5.5642\n",
      "epoch: 17880, train_loss =  5.5178, val_loss =  5.5517\n",
      "epoch: 17890, train_loss =  5.5053, val_loss =  5.5392\n",
      "epoch: 17900, train_loss =  5.4928, val_loss =  5.5267\n",
      "epoch: 17910, train_loss =  5.4803, val_loss =  5.5142\n",
      "epoch: 17920, train_loss =  5.4679, val_loss =  5.5017\n",
      "epoch: 17930, train_loss =  5.4554, val_loss =  5.4892\n",
      "epoch: 17940, train_loss =  5.4429, val_loss =  5.4767\n",
      "epoch: 17950, train_loss =  5.4305, val_loss =  5.4641\n",
      "epoch: 17960, train_loss =  5.4180, val_loss =  5.4516\n",
      "epoch: 17970, train_loss =  5.4055, val_loss =  5.4391\n",
      "epoch: 17980, train_loss =  5.3931, val_loss =  5.4266\n",
      "epoch: 17990, train_loss =  5.3806, val_loss =  5.4141\n",
      "epoch: 18000, train_loss =  5.3681, val_loss =  5.4016\n",
      "epoch: 18010, train_loss =  5.3557, val_loss =  5.3891\n",
      "epoch: 18020, train_loss =  5.3432, val_loss =  5.3766\n",
      "epoch: 18030, train_loss =  5.3307, val_loss =  5.3641\n",
      "epoch: 18040, train_loss =  5.3182, val_loss =  5.3516\n",
      "epoch: 18050, train_loss =  5.3058, val_loss =  5.3391\n",
      "epoch: 18060, train_loss =  5.2933, val_loss =  5.3266\n",
      "epoch: 18070, train_loss =  5.2808, val_loss =  5.3141\n",
      "epoch: 18080, train_loss =  5.2684, val_loss =  5.3016\n",
      "epoch: 18090, train_loss =  5.2559, val_loss =  5.2891\n",
      "epoch: 18100, train_loss =  5.2434, val_loss =  5.2766\n",
      "epoch: 18110, train_loss =  5.2310, val_loss =  5.2641\n",
      "epoch: 18120, train_loss =  5.2185, val_loss =  5.2515\n",
      "epoch: 18130, train_loss =  5.2060, val_loss =  5.2390\n",
      "epoch: 18140, train_loss =  5.1936, val_loss =  5.2265\n",
      "epoch: 18150, train_loss =  5.1811, val_loss =  5.2140\n",
      "epoch: 18160, train_loss =  5.1686, val_loss =  5.2015\n",
      "epoch: 18170, train_loss =  5.1562, val_loss =  5.1890\n",
      "epoch: 18180, train_loss =  5.1437, val_loss =  5.1765\n",
      "epoch: 18190, train_loss =  5.1312, val_loss =  5.1640\n",
      "epoch: 18200, train_loss =  5.1188, val_loss =  5.1515\n",
      "epoch: 18210, train_loss =  5.1063, val_loss =  5.1390\n",
      "epoch: 18220, train_loss =  5.0938, val_loss =  5.1265\n",
      "epoch: 18230, train_loss =  5.0814, val_loss =  5.1140\n",
      "epoch: 18240, train_loss =  5.0689, val_loss =  5.1015\n",
      "epoch: 18250, train_loss =  5.0564, val_loss =  5.0890\n",
      "epoch: 18260, train_loss =  5.0440, val_loss =  5.0765\n",
      "epoch: 18270, train_loss =  5.0315, val_loss =  5.0640\n",
      "epoch: 18280, train_loss =  5.0191, val_loss =  5.0515\n",
      "epoch: 18290, train_loss =  5.0066, val_loss =  5.0390\n",
      "epoch: 18300, train_loss =  4.9941, val_loss =  5.0265\n",
      "epoch: 18310, train_loss =  4.9817, val_loss =  5.0140\n",
      "epoch: 18320, train_loss =  4.9692, val_loss =  5.0014\n",
      "epoch: 18330, train_loss =  4.9567, val_loss =  4.9889\n",
      "epoch: 18340, train_loss =  4.9442, val_loss =  4.9764\n",
      "epoch: 18350, train_loss =  4.9318, val_loss =  4.9639\n",
      "epoch: 18360, train_loss =  4.9193, val_loss =  4.9514\n",
      "epoch: 18370, train_loss =  4.9068, val_loss =  4.9389\n",
      "epoch: 18380, train_loss =  4.8944, val_loss =  4.9264\n",
      "epoch: 18390, train_loss =  4.8819, val_loss =  4.9139\n",
      "epoch: 18400, train_loss =  4.8694, val_loss =  4.9014\n",
      "epoch: 18410, train_loss =  4.8570, val_loss =  4.8889\n",
      "epoch: 18420, train_loss =  4.8445, val_loss =  4.8764\n",
      "epoch: 18430, train_loss =  4.8320, val_loss =  4.8639\n",
      "epoch: 18440, train_loss =  4.8196, val_loss =  4.8514\n",
      "epoch: 18450, train_loss =  4.8071, val_loss =  4.8389\n",
      "epoch: 18460, train_loss =  4.7947, val_loss =  4.8264\n",
      "epoch: 18470, train_loss =  4.7822, val_loss =  4.8139\n",
      "epoch: 18480, train_loss =  4.7697, val_loss =  4.8014\n",
      "epoch: 18490, train_loss =  4.7573, val_loss =  4.7889\n",
      "epoch: 18500, train_loss =  4.7448, val_loss =  4.7764\n",
      "epoch: 18510, train_loss =  4.7324, val_loss =  4.7639\n",
      "epoch: 18520, train_loss =  4.7199, val_loss =  4.7514\n",
      "epoch: 18530, train_loss =  4.7075, val_loss =  4.7389\n",
      "epoch: 18540, train_loss =  4.6950, val_loss =  4.7264\n",
      "epoch: 18550, train_loss =  4.6825, val_loss =  4.7139\n",
      "epoch: 18560, train_loss =  4.6701, val_loss =  4.7014\n",
      "epoch: 18570, train_loss =  4.6576, val_loss =  4.6889\n",
      "epoch: 18580, train_loss =  4.6452, val_loss =  4.6764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18590, train_loss =  4.6327, val_loss =  4.6639\n",
      "epoch: 18600, train_loss =  4.6203, val_loss =  4.6514\n",
      "epoch: 18610, train_loss =  4.6078, val_loss =  4.6389\n",
      "epoch: 18620, train_loss =  4.5953, val_loss =  4.6264\n",
      "epoch: 18630, train_loss =  4.5829, val_loss =  4.6139\n",
      "epoch: 18640, train_loss =  4.5704, val_loss =  4.6014\n",
      "epoch: 18650, train_loss =  4.5580, val_loss =  4.5889\n",
      "epoch: 18660, train_loss =  4.5455, val_loss =  4.5764\n",
      "epoch: 18670, train_loss =  4.5331, val_loss =  4.5639\n",
      "epoch: 18680, train_loss =  4.5206, val_loss =  4.5514\n",
      "epoch: 18690, train_loss =  4.5082, val_loss =  4.5389\n",
      "epoch: 18700, train_loss =  4.4957, val_loss =  4.5265\n",
      "epoch: 18710, train_loss =  4.4833, val_loss =  4.5140\n",
      "epoch: 18720, train_loss =  4.4708, val_loss =  4.5015\n",
      "epoch: 18730, train_loss =  4.4584, val_loss =  4.4890\n",
      "epoch: 18740, train_loss =  4.4459, val_loss =  4.4765\n",
      "epoch: 18750, train_loss =  4.4335, val_loss =  4.4640\n",
      "epoch: 18760, train_loss =  4.4210, val_loss =  4.4515\n",
      "epoch: 18770, train_loss =  4.4086, val_loss =  4.4390\n",
      "epoch: 18780, train_loss =  4.3961, val_loss =  4.4265\n",
      "epoch: 18790, train_loss =  4.3837, val_loss =  4.4140\n",
      "epoch: 18800, train_loss =  4.3712, val_loss =  4.4016\n",
      "epoch: 18810, train_loss =  4.3588, val_loss =  4.3891\n",
      "epoch: 18820, train_loss =  4.3463, val_loss =  4.3766\n",
      "epoch: 18830, train_loss =  4.3339, val_loss =  4.3641\n",
      "epoch: 18840, train_loss =  4.3214, val_loss =  4.3516\n",
      "epoch: 18850, train_loss =  4.3090, val_loss =  4.3391\n",
      "epoch: 18860, train_loss =  4.2965, val_loss =  4.3266\n",
      "epoch: 18870, train_loss =  4.2841, val_loss =  4.3141\n",
      "epoch: 18880, train_loss =  4.2716, val_loss =  4.3016\n",
      "epoch: 18890, train_loss =  4.2592, val_loss =  4.2892\n",
      "epoch: 18900, train_loss =  4.2467, val_loss =  4.2767\n",
      "epoch: 18910, train_loss =  4.2343, val_loss =  4.2642\n",
      "epoch: 18920, train_loss =  4.2218, val_loss =  4.2517\n",
      "epoch: 18930, train_loss =  4.2094, val_loss =  4.2392\n",
      "epoch: 18940, train_loss =  4.1969, val_loss =  4.2267\n",
      "epoch: 18950, train_loss =  4.1845, val_loss =  4.2142\n",
      "epoch: 18960, train_loss =  4.1720, val_loss =  4.2017\n",
      "epoch: 18970, train_loss =  4.1596, val_loss =  4.1892\n",
      "epoch: 18980, train_loss =  4.1471, val_loss =  4.1767\n",
      "epoch: 18990, train_loss =  4.1347, val_loss =  4.1643\n",
      "epoch: 19000, train_loss =  4.1222, val_loss =  4.1518\n",
      "epoch: 19010, train_loss =  4.1098, val_loss =  4.1393\n",
      "epoch: 19020, train_loss =  4.0973, val_loss =  4.1268\n",
      "epoch: 19030, train_loss =  4.0849, val_loss =  4.1143\n",
      "epoch: 19040, train_loss =  4.0725, val_loss =  4.1018\n",
      "epoch: 19050, train_loss =  4.0600, val_loss =  4.0893\n",
      "epoch: 19060, train_loss =  4.0476, val_loss =  4.0768\n",
      "epoch: 19070, train_loss =  4.0351, val_loss =  4.0643\n",
      "epoch: 19080, train_loss =  4.0227, val_loss =  4.0519\n",
      "epoch: 19090, train_loss =  4.0102, val_loss =  4.0394\n",
      "epoch: 19100, train_loss =  3.9978, val_loss =  4.0269\n",
      "epoch: 19110, train_loss =  3.9853, val_loss =  4.0144\n",
      "epoch: 19120, train_loss =  3.9729, val_loss =  4.0019\n",
      "epoch: 19130, train_loss =  3.9604, val_loss =  3.9894\n",
      "epoch: 19140, train_loss =  3.9480, val_loss =  3.9769\n",
      "epoch: 19150, train_loss =  3.9355, val_loss =  3.9644\n",
      "epoch: 19160, train_loss =  3.9231, val_loss =  3.9520\n",
      "epoch: 19170, train_loss =  3.9106, val_loss =  3.9395\n",
      "epoch: 19180, train_loss =  3.8982, val_loss =  3.9270\n",
      "epoch: 19190, train_loss =  3.8858, val_loss =  3.9145\n",
      "epoch: 19200, train_loss =  3.8733, val_loss =  3.9020\n",
      "epoch: 19210, train_loss =  3.8609, val_loss =  3.8895\n",
      "epoch: 19220, train_loss =  3.8484, val_loss =  3.8770\n",
      "epoch: 19230, train_loss =  3.8360, val_loss =  3.8645\n",
      "epoch: 19240, train_loss =  3.8235, val_loss =  3.8520\n",
      "epoch: 19250, train_loss =  3.8111, val_loss =  3.8396\n",
      "epoch: 19260, train_loss =  3.7986, val_loss =  3.8271\n",
      "epoch: 19270, train_loss =  3.7862, val_loss =  3.8146\n",
      "epoch: 19280, train_loss =  3.7738, val_loss =  3.8021\n",
      "epoch: 19290, train_loss =  3.7613, val_loss =  3.7896\n",
      "epoch: 19300, train_loss =  3.7489, val_loss =  3.7771\n",
      "epoch: 19310, train_loss =  3.7364, val_loss =  3.7646\n",
      "epoch: 19320, train_loss =  3.7240, val_loss =  3.7521\n",
      "epoch: 19330, train_loss =  3.7115, val_loss =  3.7397\n",
      "epoch: 19340, train_loss =  3.6991, val_loss =  3.7272\n",
      "epoch: 19350, train_loss =  3.6866, val_loss =  3.7147\n",
      "epoch: 19360, train_loss =  3.6742, val_loss =  3.7022\n",
      "epoch: 19370, train_loss =  3.6618, val_loss =  3.6897\n",
      "epoch: 19380, train_loss =  3.6493, val_loss =  3.6772\n",
      "epoch: 19390, train_loss =  3.6369, val_loss =  3.6647\n",
      "epoch: 19400, train_loss =  3.6244, val_loss =  3.6523\n",
      "epoch: 19410, train_loss =  3.6120, val_loss =  3.6398\n",
      "epoch: 19420, train_loss =  3.5995, val_loss =  3.6273\n",
      "epoch: 19430, train_loss =  3.5871, val_loss =  3.6148\n",
      "epoch: 19440, train_loss =  3.5747, val_loss =  3.6023\n",
      "epoch: 19450, train_loss =  3.5622, val_loss =  3.5898\n",
      "epoch: 19460, train_loss =  3.5498, val_loss =  3.5773\n",
      "epoch: 19470, train_loss =  3.5373, val_loss =  3.5649\n",
      "epoch: 19480, train_loss =  3.5249, val_loss =  3.5524\n",
      "epoch: 19490, train_loss =  3.5125, val_loss =  3.5399\n",
      "epoch: 19500, train_loss =  3.5000, val_loss =  3.5274\n",
      "epoch: 19510, train_loss =  3.4876, val_loss =  3.5149\n",
      "epoch: 19520, train_loss =  3.4751, val_loss =  3.5024\n",
      "epoch: 19530, train_loss =  3.4627, val_loss =  3.4900\n",
      "epoch: 19540, train_loss =  3.4503, val_loss =  3.4775\n",
      "epoch: 19550, train_loss =  3.4378, val_loss =  3.4650\n",
      "epoch: 19560, train_loss =  3.4254, val_loss =  3.4525\n",
      "epoch: 19570, train_loss =  3.4129, val_loss =  3.4400\n",
      "epoch: 19580, train_loss =  3.4005, val_loss =  3.4275\n",
      "epoch: 19590, train_loss =  3.3881, val_loss =  3.4151\n",
      "epoch: 19600, train_loss =  3.3756, val_loss =  3.4026\n",
      "epoch: 19610, train_loss =  3.3632, val_loss =  3.3901\n",
      "epoch: 19620, train_loss =  3.3508, val_loss =  3.3776\n",
      "epoch: 19630, train_loss =  3.3383, val_loss =  3.3651\n",
      "epoch: 19640, train_loss =  3.3259, val_loss =  3.3527\n",
      "epoch: 19650, train_loss =  3.3135, val_loss =  3.3402\n",
      "epoch: 19660, train_loss =  3.3010, val_loss =  3.3277\n",
      "epoch: 19670, train_loss =  3.2886, val_loss =  3.3152\n",
      "epoch: 19680, train_loss =  3.2762, val_loss =  3.3027\n",
      "epoch: 19690, train_loss =  3.2637, val_loss =  3.2903\n",
      "epoch: 19700, train_loss =  3.2513, val_loss =  3.2778\n",
      "epoch: 19710, train_loss =  3.2389, val_loss =  3.2653\n",
      "epoch: 19720, train_loss =  3.2264, val_loss =  3.2528\n",
      "epoch: 19730, train_loss =  3.2140, val_loss =  3.2404\n",
      "epoch: 19740, train_loss =  3.2016, val_loss =  3.2279\n",
      "epoch: 19750, train_loss =  3.1891, val_loss =  3.2154\n",
      "epoch: 19760, train_loss =  3.1767, val_loss =  3.2029\n",
      "epoch: 19770, train_loss =  3.1643, val_loss =  3.1905\n",
      "epoch: 19780, train_loss =  3.1518, val_loss =  3.1780\n",
      "epoch: 19790, train_loss =  3.1394, val_loss =  3.1655\n",
      "epoch: 19800, train_loss =  3.1270, val_loss =  3.1530\n",
      "epoch: 19810, train_loss =  3.1145, val_loss =  3.1406\n",
      "epoch: 19820, train_loss =  3.1021, val_loss =  3.1281\n",
      "epoch: 19830, train_loss =  3.0897, val_loss =  3.1156\n",
      "epoch: 19840, train_loss =  3.0773, val_loss =  3.1031\n",
      "epoch: 19850, train_loss =  3.0648, val_loss =  3.0907\n",
      "epoch: 19860, train_loss =  3.0524, val_loss =  3.0782\n",
      "epoch: 19870, train_loss =  3.0400, val_loss =  3.0657\n",
      "epoch: 19880, train_loss =  3.0276, val_loss =  3.0532\n",
      "epoch: 19890, train_loss =  3.0151, val_loss =  3.0408\n",
      "epoch: 19900, train_loss =  3.0027, val_loss =  3.0283\n",
      "epoch: 19910, train_loss =  2.9903, val_loss =  3.0158\n",
      "epoch: 19920, train_loss =  2.9779, val_loss =  3.0034\n",
      "epoch: 19930, train_loss =  2.9654, val_loss =  2.9909\n",
      "epoch: 19940, train_loss =  2.9530, val_loss =  2.9784\n",
      "epoch: 19950, train_loss =  2.9406, val_loss =  2.9660\n",
      "epoch: 19960, train_loss =  2.9282, val_loss =  2.9535\n",
      "epoch: 19970, train_loss =  2.9158, val_loss =  2.9410\n",
      "epoch: 19980, train_loss =  2.9033, val_loss =  2.9286\n",
      "epoch: 19990, train_loss =  2.8909, val_loss =  2.9161\n",
      "epoch: 20000, train_loss =  2.8785, val_loss =  2.9036\n",
      "epoch: 20010, train_loss =  2.8661, val_loss =  2.8912\n",
      "epoch: 20020, train_loss =  2.8537, val_loss =  2.8787\n",
      "epoch: 20030, train_loss =  2.8413, val_loss =  2.8663\n",
      "epoch: 20040, train_loss =  2.8289, val_loss =  2.8538\n",
      "epoch: 20050, train_loss =  2.8164, val_loss =  2.8413\n",
      "epoch: 20060, train_loss =  2.8040, val_loss =  2.8289\n",
      "epoch: 20070, train_loss =  2.7916, val_loss =  2.8164\n",
      "epoch: 20080, train_loss =  2.7792, val_loss =  2.8040\n",
      "epoch: 20090, train_loss =  2.7668, val_loss =  2.7915\n",
      "epoch: 20100, train_loss =  2.7544, val_loss =  2.7790\n",
      "epoch: 20110, train_loss =  2.7420, val_loss =  2.7666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20120, train_loss =  2.7295, val_loss =  2.7541\n",
      "epoch: 20130, train_loss =  2.7171, val_loss =  2.7416\n",
      "epoch: 20140, train_loss =  2.7047, val_loss =  2.7292\n",
      "epoch: 20150, train_loss =  2.6923, val_loss =  2.7167\n",
      "epoch: 20160, train_loss =  2.6799, val_loss =  2.7043\n",
      "epoch: 20170, train_loss =  2.6675, val_loss =  2.6918\n",
      "epoch: 20180, train_loss =  2.6551, val_loss =  2.6794\n",
      "epoch: 20190, train_loss =  2.6427, val_loss =  2.6669\n",
      "epoch: 20200, train_loss =  2.6303, val_loss =  2.6545\n",
      "epoch: 20210, train_loss =  2.6179, val_loss =  2.6420\n",
      "epoch: 20220, train_loss =  2.6055, val_loss =  2.6296\n",
      "epoch: 20230, train_loss =  2.5931, val_loss =  2.6171\n",
      "epoch: 20240, train_loss =  2.5807, val_loss =  2.6047\n",
      "epoch: 20250, train_loss =  2.5683, val_loss =  2.5922\n",
      "epoch: 20260, train_loss =  2.5559, val_loss =  2.5798\n",
      "epoch: 20270, train_loss =  2.5435, val_loss =  2.5674\n",
      "epoch: 20280, train_loss =  2.5311, val_loss =  2.5549\n",
      "epoch: 20290, train_loss =  2.5187, val_loss =  2.5425\n",
      "epoch: 20300, train_loss =  2.5063, val_loss =  2.5300\n",
      "epoch: 20310, train_loss =  2.4939, val_loss =  2.5176\n",
      "epoch: 20320, train_loss =  2.4815, val_loss =  2.5051\n",
      "epoch: 20330, train_loss =  2.4691, val_loss =  2.4927\n",
      "epoch: 20340, train_loss =  2.4567, val_loss =  2.4802\n",
      "epoch: 20350, train_loss =  2.4443, val_loss =  2.4678\n",
      "epoch: 20360, train_loss =  2.4320, val_loss =  2.4554\n",
      "epoch: 20370, train_loss =  2.4196, val_loss =  2.4429\n",
      "epoch: 20380, train_loss =  2.4072, val_loss =  2.4305\n",
      "epoch: 20390, train_loss =  2.3948, val_loss =  2.4181\n",
      "epoch: 20400, train_loss =  2.3824, val_loss =  2.4056\n",
      "epoch: 20410, train_loss =  2.3700, val_loss =  2.3932\n",
      "epoch: 20420, train_loss =  2.3576, val_loss =  2.3807\n",
      "epoch: 20430, train_loss =  2.3452, val_loss =  2.3683\n",
      "epoch: 20440, train_loss =  2.3328, val_loss =  2.3559\n",
      "epoch: 20450, train_loss =  2.3205, val_loss =  2.3434\n",
      "epoch: 20460, train_loss =  2.3081, val_loss =  2.3310\n",
      "epoch: 20470, train_loss =  2.2957, val_loss =  2.3186\n",
      "epoch: 20480, train_loss =  2.2833, val_loss =  2.3061\n",
      "epoch: 20490, train_loss =  2.2709, val_loss =  2.2937\n",
      "epoch: 20500, train_loss =  2.2586, val_loss =  2.2813\n",
      "epoch: 20510, train_loss =  2.2462, val_loss =  2.2689\n",
      "epoch: 20520, train_loss =  2.2338, val_loss =  2.2564\n",
      "epoch: 20530, train_loss =  2.2214, val_loss =  2.2440\n",
      "epoch: 20540, train_loss =  2.2091, val_loss =  2.2316\n",
      "epoch: 20550, train_loss =  2.1967, val_loss =  2.2192\n",
      "epoch: 20560, train_loss =  2.1843, val_loss =  2.2067\n",
      "epoch: 20570, train_loss =  2.1720, val_loss =  2.1943\n",
      "epoch: 20580, train_loss =  2.1596, val_loss =  2.1819\n",
      "epoch: 20590, train_loss =  2.1472, val_loss =  2.1695\n",
      "epoch: 20600, train_loss =  2.1349, val_loss =  2.1571\n",
      "epoch: 20610, train_loss =  2.1225, val_loss =  2.1447\n",
      "epoch: 20620, train_loss =  2.1101, val_loss =  2.1322\n",
      "epoch: 20630, train_loss =  2.0978, val_loss =  2.1198\n",
      "epoch: 20640, train_loss =  2.0854, val_loss =  2.1074\n",
      "epoch: 20650, train_loss =  2.0731, val_loss =  2.0950\n",
      "epoch: 20660, train_loss =  2.0607, val_loss =  2.0826\n",
      "epoch: 20670, train_loss =  2.0483, val_loss =  2.0702\n",
      "epoch: 20680, train_loss =  2.0360, val_loss =  2.0578\n",
      "epoch: 20690, train_loss =  2.0236, val_loss =  2.0454\n",
      "epoch: 20700, train_loss =  2.0113, val_loss =  2.0330\n",
      "epoch: 20710, train_loss =  1.9989, val_loss =  2.0206\n",
      "epoch: 20720, train_loss =  1.9866, val_loss =  2.0082\n",
      "epoch: 20730, train_loss =  1.9743, val_loss =  1.9958\n",
      "epoch: 20740, train_loss =  1.9619, val_loss =  1.9834\n",
      "epoch: 20750, train_loss =  1.9496, val_loss =  1.9710\n",
      "epoch: 20760, train_loss =  1.9372, val_loss =  1.9586\n",
      "epoch: 20770, train_loss =  1.9249, val_loss =  1.9462\n",
      "epoch: 20780, train_loss =  1.9126, val_loss =  1.9338\n",
      "epoch: 20790, train_loss =  1.9002, val_loss =  1.9214\n",
      "epoch: 20800, train_loss =  1.8879, val_loss =  1.9091\n",
      "epoch: 20810, train_loss =  1.8756, val_loss =  1.8967\n",
      "epoch: 20820, train_loss =  1.8632, val_loss =  1.8843\n",
      "epoch: 20830, train_loss =  1.8509, val_loss =  1.8719\n",
      "epoch: 20840, train_loss =  1.8386, val_loss =  1.8595\n",
      "epoch: 20850, train_loss =  1.8263, val_loss =  1.8472\n",
      "epoch: 20860, train_loss =  1.8139, val_loss =  1.8348\n",
      "epoch: 20870, train_loss =  1.8016, val_loss =  1.8224\n",
      "epoch: 20880, train_loss =  1.7893, val_loss =  1.8100\n",
      "epoch: 20890, train_loss =  1.7770, val_loss =  1.7977\n",
      "epoch: 20900, train_loss =  1.7647, val_loss =  1.7853\n",
      "epoch: 20910, train_loss =  1.7523, val_loss =  1.7729\n",
      "epoch: 20920, train_loss =  1.7400, val_loss =  1.7606\n",
      "epoch: 20930, train_loss =  1.7277, val_loss =  1.7482\n",
      "epoch: 20940, train_loss =  1.7154, val_loss =  1.7358\n",
      "epoch: 20950, train_loss =  1.7031, val_loss =  1.7235\n",
      "epoch: 20960, train_loss =  1.6908, val_loss =  1.7111\n",
      "epoch: 20970, train_loss =  1.6785, val_loss =  1.6988\n",
      "epoch: 20980, train_loss =  1.6663, val_loss =  1.6865\n",
      "epoch: 20990, train_loss =  1.6540, val_loss =  1.6741\n",
      "epoch: 21000, train_loss =  1.6417, val_loss =  1.6618\n",
      "epoch: 21010, train_loss =  1.6294, val_loss =  1.6494\n",
      "epoch: 21020, train_loss =  1.6171, val_loss =  1.6371\n",
      "epoch: 21030, train_loss =  1.6048, val_loss =  1.6248\n",
      "epoch: 21040, train_loss =  1.5926, val_loss =  1.6124\n",
      "epoch: 21050, train_loss =  1.5803, val_loss =  1.6001\n",
      "epoch: 21060, train_loss =  1.5680, val_loss =  1.5878\n",
      "epoch: 21070, train_loss =  1.5557, val_loss =  1.5754\n",
      "epoch: 21080, train_loss =  1.5435, val_loss =  1.5631\n",
      "epoch: 21090, train_loss =  1.5312, val_loss =  1.5508\n",
      "epoch: 21100, train_loss =  1.5190, val_loss =  1.5385\n",
      "epoch: 21110, train_loss =  1.5067, val_loss =  1.5262\n",
      "epoch: 21120, train_loss =  1.4945, val_loss =  1.5139\n",
      "epoch: 21130, train_loss =  1.4822, val_loss =  1.5016\n",
      "epoch: 21140, train_loss =  1.4700, val_loss =  1.4893\n",
      "epoch: 21150, train_loss =  1.4578, val_loss =  1.4770\n",
      "epoch: 21160, train_loss =  1.4455, val_loss =  1.4647\n",
      "epoch: 21170, train_loss =  1.4333, val_loss =  1.4524\n",
      "epoch: 21180, train_loss =  1.4211, val_loss =  1.4401\n",
      "epoch: 21190, train_loss =  1.4088, val_loss =  1.4278\n",
      "epoch: 21200, train_loss =  1.3966, val_loss =  1.4156\n",
      "epoch: 21210, train_loss =  1.3844, val_loss =  1.4033\n",
      "epoch: 21220, train_loss =  1.3722, val_loss =  1.3910\n",
      "epoch: 21230, train_loss =  1.3600, val_loss =  1.3788\n",
      "epoch: 21240, train_loss =  1.3478, val_loss =  1.3665\n",
      "epoch: 21250, train_loss =  1.3356, val_loss =  1.3543\n",
      "epoch: 21260, train_loss =  1.3234, val_loss =  1.3420\n",
      "epoch: 21270, train_loss =  1.3112, val_loss =  1.3298\n",
      "epoch: 21280, train_loss =  1.2991, val_loss =  1.3175\n",
      "epoch: 21290, train_loss =  1.2869, val_loss =  1.3053\n",
      "epoch: 21300, train_loss =  1.2747, val_loss =  1.2931\n",
      "epoch: 21310, train_loss =  1.2626, val_loss =  1.2808\n",
      "epoch: 21320, train_loss =  1.2504, val_loss =  1.2686\n",
      "epoch: 21330, train_loss =  1.2383, val_loss =  1.2564\n",
      "epoch: 21340, train_loss =  1.2261, val_loss =  1.2442\n",
      "epoch: 21350, train_loss =  1.2140, val_loss =  1.2320\n",
      "epoch: 21360, train_loss =  1.2018, val_loss =  1.2198\n",
      "epoch: 21370, train_loss =  1.1897, val_loss =  1.2076\n",
      "epoch: 21380, train_loss =  1.1776, val_loss =  1.1955\n",
      "epoch: 21390, train_loss =  1.1655, val_loss =  1.1833\n",
      "epoch: 21400, train_loss =  1.1534, val_loss =  1.1711\n",
      "epoch: 21410, train_loss =  1.1413, val_loss =  1.1590\n",
      "epoch: 21420, train_loss =  1.1292, val_loss =  1.1468\n",
      "epoch: 21430, train_loss =  1.1171, val_loss =  1.1347\n",
      "epoch: 21440, train_loss =  1.1051, val_loss =  1.1226\n",
      "epoch: 21450, train_loss =  1.0930, val_loss =  1.1104\n",
      "epoch: 21460, train_loss =  1.0810, val_loss =  1.0983\n",
      "epoch: 21470, train_loss =  1.0689, val_loss =  1.0862\n",
      "epoch: 21480, train_loss =  1.0569, val_loss =  1.0741\n",
      "epoch: 21490, train_loss =  1.0449, val_loss =  1.0620\n",
      "epoch: 21500, train_loss =  1.0329, val_loss =  1.0499\n",
      "epoch: 21510, train_loss =  1.0209, val_loss =  1.0379\n",
      "epoch: 21520, train_loss =  1.0089, val_loss =  1.0258\n",
      "epoch: 21530, train_loss =  0.9969, val_loss =  1.0138\n",
      "epoch: 21540, train_loss =  0.9849, val_loss =  1.0017\n",
      "epoch: 21550, train_loss =  0.9730, val_loss =  0.9897\n",
      "epoch: 21560, train_loss =  0.9610, val_loss =  0.9777\n",
      "epoch: 21570, train_loss =  0.9491, val_loss =  0.9657\n",
      "epoch: 21580, train_loss =  0.9372, val_loss =  0.9537\n",
      "epoch: 21590, train_loss =  0.9253, val_loss =  0.9417\n",
      "epoch: 21600, train_loss =  0.9134, val_loss =  0.9298\n",
      "epoch: 21610, train_loss =  0.9015, val_loss =  0.9178\n",
      "epoch: 21620, train_loss =  0.8896, val_loss =  0.9059\n",
      "epoch: 21630, train_loss =  0.8778, val_loss =  0.8940\n",
      "epoch: 21640, train_loss =  0.8660, val_loss =  0.8821\n",
      "epoch: 21650, train_loss =  0.8542, val_loss =  0.8702\n",
      "epoch: 21660, train_loss =  0.8424, val_loss =  0.8584\n",
      "epoch: 21670, train_loss =  0.8306, val_loss =  0.8465\n",
      "epoch: 21680, train_loss =  0.8188, val_loss =  0.8347\n",
      "epoch: 21690, train_loss =  0.8071, val_loss =  0.8229\n",
      "epoch: 21700, train_loss =  0.7954, val_loss =  0.8111\n",
      "epoch: 21710, train_loss =  0.7837, val_loss =  0.7993\n",
      "epoch: 21720, train_loss =  0.7720, val_loss =  0.7876\n",
      "epoch: 21730, train_loss =  0.7604, val_loss =  0.7759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21740, train_loss =  0.7488, val_loss =  0.7642\n",
      "epoch: 21750, train_loss =  0.7372, val_loss =  0.7525\n",
      "epoch: 21760, train_loss =  0.7256, val_loss =  0.7408\n",
      "epoch: 21770, train_loss =  0.7141, val_loss =  0.7292\n",
      "epoch: 21780, train_loss =  0.7025, val_loss =  0.7176\n",
      "epoch: 21790, train_loss =  0.6911, val_loss =  0.7061\n",
      "epoch: 21800, train_loss =  0.6796, val_loss =  0.6945\n",
      "epoch: 21810, train_loss =  0.6682, val_loss =  0.6830\n",
      "epoch: 21820, train_loss =  0.6568, val_loss =  0.6716\n",
      "epoch: 21830, train_loss =  0.6455, val_loss =  0.6601\n",
      "epoch: 21840, train_loss =  0.6342, val_loss =  0.6488\n",
      "epoch: 21850, train_loss =  0.6229, val_loss =  0.6374\n",
      "epoch: 21860, train_loss =  0.6117, val_loss =  0.6261\n",
      "epoch: 21870, train_loss =  0.6005, val_loss =  0.6148\n",
      "epoch: 21880, train_loss =  0.5894, val_loss =  0.6036\n",
      "epoch: 21890, train_loss =  0.5783, val_loss =  0.5924\n",
      "epoch: 21900, train_loss =  0.5673, val_loss =  0.5813\n",
      "epoch: 21910, train_loss =  0.5563, val_loss =  0.5702\n",
      "epoch: 21920, train_loss =  0.5454, val_loss =  0.5592\n",
      "epoch: 21930, train_loss =  0.5345, val_loss =  0.5483\n",
      "epoch: 21940, train_loss =  0.5237, val_loss =  0.5374\n",
      "epoch: 21950, train_loss =  0.5130, val_loss =  0.5265\n",
      "epoch: 21960, train_loss =  0.5023, val_loss =  0.5158\n",
      "epoch: 21970, train_loss =  0.4917, val_loss =  0.5051\n",
      "epoch: 21980, train_loss =  0.4812, val_loss =  0.4945\n",
      "epoch: 21990, train_loss =  0.4708, val_loss =  0.4840\n",
      "epoch: 22000, train_loss =  0.4605, val_loss =  0.4735\n",
      "epoch: 22010, train_loss =  0.4502, val_loss =  0.4631\n",
      "epoch: 22020, train_loss =  0.4401, val_loss =  0.4529\n",
      "epoch: 22030, train_loss =  0.4300, val_loss =  0.4427\n",
      "epoch: 22040, train_loss =  0.4201, val_loss =  0.4327\n",
      "epoch: 22050, train_loss =  0.4103, val_loss =  0.4227\n",
      "epoch: 22060, train_loss =  0.4006, val_loss =  0.4129\n",
      "epoch: 22070, train_loss =  0.3910, val_loss =  0.4032\n",
      "epoch: 22080, train_loss =  0.3816, val_loss =  0.3937\n",
      "epoch: 22090, train_loss =  0.3723, val_loss =  0.3842\n",
      "epoch: 22100, train_loss =  0.3632, val_loss =  0.3750\n",
      "epoch: 22110, train_loss =  0.3542, val_loss =  0.3658\n",
      "epoch: 22120, train_loss =  0.3454, val_loss =  0.3569\n",
      "epoch: 22130, train_loss =  0.3368, val_loss =  0.3481\n",
      "epoch: 22140, train_loss =  0.3284, val_loss =  0.3395\n",
      "epoch: 22150, train_loss =  0.3201, val_loss =  0.3311\n",
      "epoch: 22160, train_loss =  0.3121, val_loss =  0.3229\n",
      "epoch: 22170, train_loss =  0.3043, val_loss =  0.3150\n",
      "epoch: 22180, train_loss =  0.2967, val_loss =  0.3072\n",
      "epoch: 22190, train_loss =  0.2894, val_loss =  0.2997\n",
      "epoch: 22200, train_loss =  0.2823, val_loss =  0.2924\n",
      "epoch: 22210, train_loss =  0.2754, val_loss =  0.2853\n",
      "epoch: 22220, train_loss =  0.2688, val_loss =  0.2785\n",
      "epoch: 22230, train_loss =  0.2625, val_loss =  0.2720\n",
      "epoch: 22240, train_loss =  0.2565, val_loss =  0.2658\n",
      "epoch: 22250, train_loss =  0.2507, val_loss =  0.2598\n",
      "epoch: 22260, train_loss =  0.2453, val_loss =  0.2541\n",
      "epoch: 22270, train_loss =  0.2401, val_loss =  0.2487\n",
      "epoch: 22280, train_loss =  0.2352, val_loss =  0.2435\n",
      "epoch: 22290, train_loss =  0.2305, val_loss =  0.2387\n",
      "epoch: 22300, train_loss =  0.2262, val_loss =  0.2341\n",
      "epoch: 22310, train_loss =  0.2222, val_loss =  0.2298\n",
      "epoch: 22320, train_loss =  0.2184, val_loss =  0.2258\n",
      "epoch: 22330, train_loss =  0.2148, val_loss =  0.2220\n",
      "epoch: 22340, train_loss =  0.2116, val_loss =  0.2185\n",
      "epoch: 22350, train_loss =  0.2086, val_loss =  0.2153\n",
      "epoch: 22360, train_loss =  0.2058, val_loss =  0.2122\n",
      "epoch: 22370, train_loss =  0.2032, val_loss =  0.2094\n",
      "epoch: 22380, train_loss =  0.2008, val_loss =  0.2068\n",
      "epoch: 22390, train_loss =  0.1987, val_loss =  0.2045\n",
      "epoch: 22400, train_loss =  0.1967, val_loss =  0.2023\n",
      "epoch: 22410, train_loss =  0.1949, val_loss =  0.2002\n",
      "epoch: 22420, train_loss =  0.1932, val_loss =  0.1984\n",
      "epoch: 22430, train_loss =  0.1917, val_loss =  0.1967\n",
      "epoch: 22440, train_loss =  0.1903, val_loss =  0.1951\n",
      "epoch: 22450, train_loss =  0.1890, val_loss =  0.1937\n",
      "epoch: 22460, train_loss =  0.1879, val_loss =  0.1923\n",
      "epoch: 22470, train_loss =  0.1868, val_loss =  0.1911\n",
      "epoch: 22480, train_loss =  0.1858, val_loss =  0.1900\n",
      "epoch: 22490, train_loss =  0.1849, val_loss =  0.1889\n",
      "epoch: 22500, train_loss =  0.1843, val_loss =  0.1882\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "val_loss_history = []\n",
    "train_loss_history=[]\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    # forward pass and loss\n",
    "    train_y_predicted = model(train_x)\n",
    "    loss = criterion(train_y_predicted, train_y)\n",
    "    train_loss_history.append(loss.item())\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # update\n",
    "    optimizer.step()\n",
    "    # init optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 驗證資料集\n",
    "    model.eval()\n",
    "    val_y_predicted = model(val_x)\n",
    "    val_loss = criterion(val_y_predicted, val_y)\n",
    "    val_loss_history.append(val_loss.item())\n",
    "    \n",
    "    if val_loss < best_validation_loss:\n",
    "        best_validation_loss = val_loss\n",
    "        counter = 0  # 重置计数器\n",
    "    else:\n",
    "        counter += 1\n",
    "    if counter >= patience:\n",
    "        break\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, train_loss = {loss.item(): .4f}, val_loss = {val_loss.item(): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c49094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919b0796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUD即期買入</th>\n",
       "      <th>AUD即期賣出</th>\n",
       "      <th>AUD現鈔買入</th>\n",
       "      <th>AUD現鈔賣出</th>\n",
       "      <th>CAD即期買入</th>\n",
       "      <th>CAD即期賣出</th>\n",
       "      <th>CAD現鈔買入</th>\n",
       "      <th>CAD現鈔賣出</th>\n",
       "      <th>EUR即期買入</th>\n",
       "      <th>EUR即期賣出</th>\n",
       "      <th>...</th>\n",
       "      <th>JPY現鈔買入</th>\n",
       "      <th>JPY現鈔賣出</th>\n",
       "      <th>KRW即期買入</th>\n",
       "      <th>KRW即期賣出</th>\n",
       "      <th>KRW現鈔買入</th>\n",
       "      <th>KRW現鈔賣出</th>\n",
       "      <th>USD即期買入</th>\n",
       "      <th>USD即期賣出</th>\n",
       "      <th>USD現鈔買入</th>\n",
       "      <th>USD現鈔賣出</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>20.19</td>\n",
       "      <td>20.39</td>\n",
       "      <td>19.90</td>\n",
       "      <td>20.68</td>\n",
       "      <td>22.17</td>\n",
       "      <td>22.37</td>\n",
       "      <td>21.77</td>\n",
       "      <td>22.68</td>\n",
       "      <td>32.68</td>\n",
       "      <td>33.08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2223</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02165</td>\n",
       "      <td>0.02555</td>\n",
       "      <td>30.325</td>\n",
       "      <td>30.425</td>\n",
       "      <td>29.975</td>\n",
       "      <td>30.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>20.21</td>\n",
       "      <td>20.41</td>\n",
       "      <td>19.92</td>\n",
       "      <td>20.70</td>\n",
       "      <td>22.28</td>\n",
       "      <td>22.48</td>\n",
       "      <td>21.88</td>\n",
       "      <td>22.79</td>\n",
       "      <td>32.81</td>\n",
       "      <td>33.21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2215</td>\n",
       "      <td>0.2343</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02164</td>\n",
       "      <td>0.02554</td>\n",
       "      <td>30.405</td>\n",
       "      <td>30.505</td>\n",
       "      <td>30.055</td>\n",
       "      <td>30.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>20.33</td>\n",
       "      <td>20.53</td>\n",
       "      <td>20.04</td>\n",
       "      <td>20.82</td>\n",
       "      <td>22.40</td>\n",
       "      <td>22.60</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.91</td>\n",
       "      <td>32.86</td>\n",
       "      <td>33.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02171</td>\n",
       "      <td>0.02561</td>\n",
       "      <td>30.405</td>\n",
       "      <td>30.505</td>\n",
       "      <td>30.055</td>\n",
       "      <td>30.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>20.23</td>\n",
       "      <td>20.43</td>\n",
       "      <td>19.94</td>\n",
       "      <td>20.72</td>\n",
       "      <td>22.37</td>\n",
       "      <td>22.57</td>\n",
       "      <td>21.97</td>\n",
       "      <td>22.88</td>\n",
       "      <td>32.95</td>\n",
       "      <td>33.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02161</td>\n",
       "      <td>0.02551</td>\n",
       "      <td>30.400</td>\n",
       "      <td>30.500</td>\n",
       "      <td>30.050</td>\n",
       "      <td>30.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>21.04</td>\n",
       "      <td>21.24</td>\n",
       "      <td>20.75</td>\n",
       "      <td>21.53</td>\n",
       "      <td>22.48</td>\n",
       "      <td>22.68</td>\n",
       "      <td>22.08</td>\n",
       "      <td>22.99</td>\n",
       "      <td>33.00</td>\n",
       "      <td>33.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2418</td>\n",
       "      <td>0.2546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02281</td>\n",
       "      <td>0.02671</td>\n",
       "      <td>27.715</td>\n",
       "      <td>27.815</td>\n",
       "      <td>27.365</td>\n",
       "      <td>28.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.08</td>\n",
       "      <td>21.28</td>\n",
       "      <td>20.79</td>\n",
       "      <td>21.57</td>\n",
       "      <td>23.25</td>\n",
       "      <td>23.45</td>\n",
       "      <td>22.85</td>\n",
       "      <td>23.76</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02116</td>\n",
       "      <td>0.02506</td>\n",
       "      <td>29.940</td>\n",
       "      <td>30.040</td>\n",
       "      <td>29.590</td>\n",
       "      <td>30.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.13</td>\n",
       "      <td>21.33</td>\n",
       "      <td>20.84</td>\n",
       "      <td>21.62</td>\n",
       "      <td>22.04</td>\n",
       "      <td>22.24</td>\n",
       "      <td>21.64</td>\n",
       "      <td>22.55</td>\n",
       "      <td>34.15</td>\n",
       "      <td>34.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02432</td>\n",
       "      <td>0.02822</td>\n",
       "      <td>28.740</td>\n",
       "      <td>28.840</td>\n",
       "      <td>28.390</td>\n",
       "      <td>29.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.17</td>\n",
       "      <td>21.37</td>\n",
       "      <td>20.88</td>\n",
       "      <td>21.66</td>\n",
       "      <td>22.08</td>\n",
       "      <td>22.28</td>\n",
       "      <td>21.68</td>\n",
       "      <td>22.59</td>\n",
       "      <td>34.29</td>\n",
       "      <td>34.69</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02428</td>\n",
       "      <td>0.02818</td>\n",
       "      <td>28.760</td>\n",
       "      <td>28.860</td>\n",
       "      <td>28.410</td>\n",
       "      <td>29.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.10</td>\n",
       "      <td>21.30</td>\n",
       "      <td>20.81</td>\n",
       "      <td>21.59</td>\n",
       "      <td>22.13</td>\n",
       "      <td>22.33</td>\n",
       "      <td>21.73</td>\n",
       "      <td>22.64</td>\n",
       "      <td>34.27</td>\n",
       "      <td>34.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>0.2796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02427</td>\n",
       "      <td>0.02817</td>\n",
       "      <td>28.750</td>\n",
       "      <td>28.850</td>\n",
       "      <td>28.400</td>\n",
       "      <td>29.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.12</td>\n",
       "      <td>21.32</td>\n",
       "      <td>20.83</td>\n",
       "      <td>21.61</td>\n",
       "      <td>22.13</td>\n",
       "      <td>22.33</td>\n",
       "      <td>21.73</td>\n",
       "      <td>22.64</td>\n",
       "      <td>34.51</td>\n",
       "      <td>34.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.2785</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02435</td>\n",
       "      <td>0.02825</td>\n",
       "      <td>28.690</td>\n",
       "      <td>28.790</td>\n",
       "      <td>28.340</td>\n",
       "      <td>29.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3984 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AUD即期買入  AUD即期賣出  AUD現鈔買入  AUD現鈔賣出  CAD即期買入  CAD即期賣出  CAD現鈔買入  CAD現鈔賣出  \\\n",
       "3983    20.19    20.39    19.90    20.68    22.17    22.37    21.77    22.68   \n",
       "3982    20.21    20.41    19.92    20.70    22.28    22.48    21.88    22.79   \n",
       "3981    20.33    20.53    20.04    20.82    22.40    22.60    22.00    22.91   \n",
       "3980    20.23    20.43    19.94    20.72    22.37    22.57    21.97    22.88   \n",
       "3979    21.04    21.24    20.75    21.53    22.48    22.68    22.08    22.99   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "4       21.08    21.28    20.79    21.57    23.25    23.45    22.85    23.76   \n",
       "3       21.13    21.33    20.84    21.62    22.04    22.24    21.64    22.55   \n",
       "2       21.17    21.37    20.88    21.66    22.08    22.28    21.68    22.59   \n",
       "1       21.10    21.30    20.81    21.59    22.13    22.33    21.73    22.64   \n",
       "0       21.12    21.32    20.83    21.61    22.13    22.33    21.73    22.64   \n",
       "\n",
       "      EUR即期買入  EUR即期賣出  ...  JPY現鈔買入  JPY現鈔賣出  KRW即期買入  KRW即期賣出  KRW現鈔買入  \\\n",
       "3983    32.68    33.08  ...   0.2223   0.2351        0        0  0.02165   \n",
       "3982    32.81    33.21  ...   0.2215   0.2343        0        0  0.02164   \n",
       "3981    32.86    33.26  ...   0.2207   0.2335        0        0  0.02171   \n",
       "3980    32.95    33.35  ...   0.2195   0.2323        0        0  0.02161   \n",
       "3979    33.00    33.40  ...   0.2418   0.2546        0        0  0.02281   \n",
       "...       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       "4       30.50    30.90  ...   0.2154   0.2282        0        0  0.02116   \n",
       "3       34.15    34.55  ...   0.2675   0.2803        0        0  0.02432   \n",
       "2       34.29    34.69  ...   0.2675   0.2803        0        0  0.02428   \n",
       "1       34.27    34.67  ...   0.2668   0.2796        0        0  0.02427   \n",
       "0       34.51    34.91  ...   0.2657   0.2785        0        0  0.02435   \n",
       "\n",
       "      KRW現鈔賣出  USD即期買入  USD即期賣出  USD現鈔買入  USD現鈔賣出  \n",
       "3983  0.02555   30.325   30.425   29.975   30.645  \n",
       "3982  0.02554   30.405   30.505   30.055   30.725  \n",
       "3981  0.02561   30.405   30.505   30.055   30.725  \n",
       "3980  0.02551   30.400   30.500   30.050   30.720  \n",
       "3979  0.02671   27.715   27.815   27.365   28.035  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "4     0.02506   29.940   30.040   29.590   30.260  \n",
       "3     0.02822   28.740   28.840   28.390   29.060  \n",
       "2     0.02818   28.760   28.860   28.410   29.080  \n",
       "1     0.02817   28.750   28.850   28.400   29.070  \n",
       "0     0.02825   28.690   28.790   28.340   29.010  \n",
       "\n",
       "[3984 rows x 32 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = load_data(\"./test\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d520c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_df.to_numpy()\n",
    "test_size, feature_size = test.shape\n",
    "# 因為 test 資料已經事先切割好範圍，故需要明確切分每段資料\n",
    "test_size = test_size//input_date_data_size\n",
    "test_x = np.empty([test_size, feature_size * input_date_data_size*power], dtype = float)\n",
    "\n",
    "for idx in range(test_size):\n",
    "  temp_data = np.array([])\n",
    "  for count in range(input_date_data_size):\n",
    "    temp_data = np.hstack([temp_data, test[idx * input_date_data_size + count]])\n",
    "    for nth_term in range(2,power+1):\n",
    "        temp_data = np.hstack([temp_data, test[idx * input_date_data_size + count]**nth_term])\n",
    "  test_x[idx, :] = temp_data\n",
    "\n",
    "# test 資料也需要照 training 方式做正規化\n",
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e2f9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.from_numpy(test_x.astype(np.float32))\n",
    "predicted = model(test_x)\n",
    "\n",
    "ids = [x for x in range(len(predicted))]\n",
    "output_df = pd.DataFrame({'id': ids})\n",
    "# 要按照規定順序設定col\n",
    "currency_columns = [\"AUD\", \"CAD\", \"EUR\", \"GBP\", \"HKD\", \"JPY\", \"KRW\", \"USD\"]\n",
    "\n",
    "for i, column_name in enumerate(currency_columns):\n",
    "    output_df[column_name] = [x[i] for x in predicted.tolist()]\n",
    "\n",
    "\n",
    "output_df.to_csv('./submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975975a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
